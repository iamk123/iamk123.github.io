https://www.yuque.com/snailclimb/mbs9wn?密码：nqdq

https://juejin.cn/post/7067322260511522823

## Kafka基础

### kafka是什么？

```
Kafka 是一个分布式流式处理平台。

两大应用场景：
1. 消息队列：建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。
2. 数据处理： 构建实时的流数据处理程序来转换或处理数据流。
```

### 队列模型？

![image-20230821194531482](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/21/19453116926183311692618331573eNDnVF-image-20230821194531482.png)

```
（1）是早期的消息模型
（2）使用队列作为消息通信载体，满足生产者与消费者模式，一条消息只能被一个消费者使用，未被消费的消息在队列中保留知道被消费或超时。
```

存在的问题

```
一条消息只能被一小消费者消费，消息无法分发给多个消费者
```

### Kafka 的消息模型？

![image-20230821194821392](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/21/194821169261850116926185015059MBzaN-image-20230821194821392.png)

```
（1）使用发布-订阅模型
（2）使用「主题（Topic）」作为消息通信载体，类似于广播模式。
```



### kakfa架构

![image-20230821195338597](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/21/19533816926188181692618818707WyqS9r-image-20230821195338597.png)

kafka重要概念

```
（1）Producer（生产者）: 产生消息的一方。
（2）Consumer（消费者）: 消费消息的一方。
（3）Broker（代理）: 可以看作是一个独立的 Kafka 实例。多个 Kafka Broker 组成一个 Kafka Cluster。
```

broker中的重要概念

```
（1）Topic（主题）: Producer 将消息发送到特定的主题，Consumer 通过订阅特定的 Topic(主题) 来消费消息。
（2）Partition（分区）: Partition 属于 Topic 的一部分。一个 Topic 可以有多个 Partition ，并且同一 Topic 下的 Partition 可以分布在不同的 Broker 上，这也就表明一个 Topic 可以横跨多个 Broker 。这正如我上面所画的图一样。
```

Kafka 中的 Partition（分区） 实际上可以对应成为消息队列中的队列。

### 多分区的好处

```
一个Topic可以有多个分区，同一个topic的分区可以分布在不同的topic下（topic2的分区1在broker1，分区2在broker2），这样可以提供更好的并发能力（负载均衡）
```



### 多副本机制 & 好处？

```
副本机制可以理解为集群
分区（partition）会有多个副本（Replica），多个副本之间会有一个leader，其他副本成为follower。
发送消息时会发送到leader副本，然后follower副本才能从leader副本中拉取消息进行同步。
```

优点

```
Partition 可以指定对应的 Replica 数, 这也极大地提高了消息存储的安全性, 提高了容灾能力，leader副本故障时，会从follower副本中选举出一个leader
```

缺点

```
增加了所需要的存储空间。
```





## Kafka 如何保证消息的消费顺序？

业务场景

```
两条消息对应不同的操作
1. 更改用户会员等级。
2. 根据会员等级计算订单价格。
这两条消息的消费顺序不一样造成的最终结果就会截然不同
```

解决办法

```
（1）1 个 Topic 只对应一个 Partition：可以解决问题，但是破坏了 Kafka 的设计初衷。
（2）【推荐】发送消息的时候指定 key/Partition。
Kafka 中发送 1 条消息的时候，可以指定 topic, partition, key,data（数据） 4 个参数。
如果你发送消息的时候指定了 Partition 的话，所有消息都会被发送到指定的 Partition。
并且，同一个 key 的消息可以保证只发送到同一个 partition，这个我们可以采用表/对象的 id 来作为 key 
```

partition已经能指定分区了，为什么还需要key？

```
开发者并不直接指定分区，因为这会导致不均匀的数据分布和其他管理问题
同一个 key 的消息可以保证只发送到同一个 partition，
key 的哈希算法能够确保消息被均匀地分布到不同的分区，这有助于负载均衡。
```

## 如何保证Kafka不丢失消息?

### 消息丢失的情况

```
丢失消息有 3 种不同的情况：
（1）生产者丢失消息的情况
（2）消费者丢失消息的情况
（3）Kafka 弄丢了消息
```

#### 生产者丢失消息

描述

```
生产者(Producer) 调用send方法发送消息之后，消息可能因为网络问题并没有发送过去。所以，我们不能默认在调用 send() 方法发送消息之后消息消息发送成功了。
为了确定消息是发送成功，我们要判断消息发送的结果。
```

解决方法

```
（1）回调监听：Producer使用send（）发送消息是异步操作，可以添加回调函数的形式监听消息是否发送成功
（2）重试：Producer 的 retries（重试次数）设置一个比较合理的值，一般是 3
```

#### 消费者丢失消息

描述

```
我们知道消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。
offset 表示 Consumer 当前消费到的 Partition(分区)的所在的位置。
Kafka 通过偏移量（offset）可以保证消息在分区内的顺序性。

当消费者拉取到了分区的某个消息之后，消费者会自动提交了 offset。
自动提交的话会有一个问题，当消费者刚拿到这个消息准备进行真正消费的时候，突然挂掉了，消息实际上并没有被消费，但是 offset 却被自动提交了。
```

解决方法

```
关闭自动提交 offset，每次在真正消费完消息之后之后再自己手动提交 offset
```

问题 TODO

```
会带来消息被重新消费的问题。比如你刚刚消费完消息之后，还没提交 offset，结果自己挂掉了，那么这个消息理论上就会被消费两次。
```

#### Kafka 弄丢了消息

描述

```
分区引入了多副本机制，当leader所在的borker挂掉，需要从follower副本中重新选出一个leader，
但是leader的数据还没有被follower副本同步的话，就会造成消息丢失。
```

解决方法

```
（1）设置acks=all（默认是1）。表示只有所有ISR列表的副本（与leader保持同步的副本）全部收到消息时，broker才会发送一个确认响应给生产者
```

