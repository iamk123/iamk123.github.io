## MySQL 遇到过死锁问题吗，你是如何解决的？

```
查看死锁日志 show engine innodb status; 
找出死锁 Sql 
分析 sql 加锁情况 
模拟死锁案发 
分析死锁日志 
分析死锁结果
```

参考

-   [手把手教你分析Mysql死锁问题](https://mp.weixin.qq.com/s?__biz=Mzg3NzU5NTIwNg==&mid=2247487979&idx=1&sn=588c83d77a8851f3b3c18cd68ed9c454&chksm=cf21cec2f85647d4a77cc239ae9a4cfd31bb8832be3d98540a08ea8b4a1f46b38cf736210a02&token=1495321435&lang=zh_CN&scene=21#wechat_redirect)
-   [两万字详解！InnoDB锁专题！](https://mp.weixin.qq.com/s?__biz=Mzg3NzU5NTIwNg==&mid=2247499275&idx=1&sn=ca72f48a290e4fd2a2ded6ef6fd045be&chksm=cf222122f855a8347b911352cebdd722b17ea45733b91ff169353c0805d9f31cea5261ef01b9&token=1712314640&lang=zh_CN#rd)





## 日常工作中你是怎么优化 SQL 的？

```
（1）增删索引。
	- 删除一些不必要的索引
	- 一些查询频繁但修改少的字段添加索引，尽量添加联合索引。
（2）避免返回不必要的数据。返回需要的字段，比如工作流任务中，包含了一个text类型的字段，查询会消耗大量的网络和io带宽。在查询列表时是用不到这个字段信息的，只有在编辑流程时才需要查该字段。
（3）优化limit大分页问题。先查询limit后的id，再进行
（4）索引失效问题
		- 最左匹配
		- 操作索引列
		- where字段 in、%like、not in、is not null
		- 隐式转换
```

参考

-   [后端程序员必备：书写高质量SQL的30条建议](https://mp.weixin.qq.com/s?__biz=Mzg3NzU5NTIwNg==&mid=2247487972&idx=1&sn=cd035a7fcd7496658846ab9f914be2db&chksm=cf21cecdf85647dbc53e212bf1a2b95d0eb2bffe08dc0141e01f8a9b2088abffc385a2ef584e&token=1495321435&lang=zh_CN&scene=21#wechat_redirect)
-   [我们为什么要分库分表？](https://mp.weixin.qq.com/s?__biz=Mzg3NzU5NTIwNg==&mid=2247498625&idx=1&sn=0d7bd9d1b46eeff4c715a6761355e9b0&chksm=cf2224a8f855adbea8931c8e011711f6c70cffeef8ddf8b87729c710eacef11b46eef80fda36&token=1712314640&lang=zh_CN#rd)





## Limit数据很大问题

###  limit 10000,10 会比 limit 10 更慢

#### 基于主键索引的limit执行过程

```sql
limit offset, size 和 limit size
其实 limit size ，相当于  limit 0, size。也就是从0开始取size条数据。

select * from page order by id limit 10000, 10
（1）在innodb里的主键索引中获取到第0到（1000 + 10）条完整行数据，返回给server层【费时的地方】
（2）server层根据offset的值挨个抛弃，最后只留下最后面的size条，也就是10条数据
```

优化

```sql
问题：用的select * 会拷贝（10000+10）条数据的完整字段，费时
解决：先查id，再根据id查整个字段

select * from page  
where id >=(select id from page  order by id limit 10000, 1) 
order by id limit 10;
```

#### 基于非主键索引的limit执行过程

```sql
select * from page order by user_name  limit 0, 10;

区别在于需要一次回表操作
当limit offset过大时，非主键索引查询非常容易变成全表扫描
```

优化

```sql
select * 
from page t1, (select id from page order by user_name limit 10000, 100) t2  
WHERE t1.id = t2.id;

问题：只是解决了回表的问题，但是还是会查询10000+100条数据给server层，再抛弃1w条数据
offset过大时，比如到了百万千万的量级，就是“深度分页问题”
```



### limit 1000000, 10 加载很慢的话，你是怎么解决的呢？

```sql
方案一: 如果 id 是连续的，返回上次查询的最大记录(偏 移量)，再往下 limit
select id，name 
from employee where id > 1000000 limit 10.

方案二：在业务允许的情况下限制页数：
建议跟业务讨论，有没有必要查这么后的分页啦。因为绝大多数用户都不会往 后翻太多页。

方案三：order by + 索引（id 为索引） ？？？感觉还是会查100w+10条
select id，name 
from employee order by id limit 1000000，10

方案四：利用延迟关联或者子查询优化超多分页场景。（先快速定位 需要获取的 id 段，然后再关联）
select a.* 
from employee a, (select id from employee where 条件 limit 100000, 10) b
where a.id = b.id
```

[参考：mysql查询 limit 1000,10 和limit 10 速度一样快吗？如果我要分页，我该怎么办？](https://mp.weixin.qq.com/s?__biz=Mzg3NzU5NTIwNg==&mid=2247499838&idx=1&sn=e30f577d2a5e4fc52e40fb070293be9d&chksm=cf221f17f85596018dde39ddfd281a527bd92c5f654d76d7313b8485d04660e559090fc0d87b&token=1712314640&lang=zh_CN#rd)



## 在高并发情况下，如何做到安全的修改同一行数据？

```
要安全的修改同一行数据，就要保证一个线程在修改时其它线程无法更新这行 记录。一般有悲观锁和乐观锁两种方案~
```



## select for update 含义，加行锁还是表锁 ？？？

```
select for update 除了有查询的作用外，还会加锁（悲观锁）
没用索引/主键的话就是表锁；否则就是是行锁，只会锁定这些索引或主键对应的行。
```



## 当数据量很大的时候怎么设计数据库？有什么方法？

```

```

## 海量数据的时候，怎么优化SQL查询？索引？

```
（1）理解查询执行计划：使用数据库的查询执行计划工具来分析查询的性能。这些工具可以提供关于查询是如何执行的详细信息，包括使用哪些索引、执行了哪些连接等。
（2）使用索引:
	- 为经常查询的字段和WHERE子句中的字段创建索引。
	- 考虑使用复合索引来支持多个字段的查询。
	- 使用覆盖索引来满足查询，从而避免访问数据表。
	- 避免在索引列上使用函数或计算，这可能导致索引无法使用。
（3）减少返回的数据量:
	- 只选择需要的列，避免使用 SELECT *。
	- 使用 LIMIT 子句来限制返回的结果数量。
（4）优化连接操作:
	- 仅在必要时使用连接，并确保使用索引列进行连接。
	- 使用内连接（INNER JOIN）代替外连接（OUTER JOIN）（如果适用）。
（5）避免使用子查询:
	- 当可能的时候，使用连接代替子查询。
```

## MYSQL怎么实现事务？用哪三个语句来支持事务？

```
（1）START TRANSACTION 或 BEGIN：
用于标记事务的开始。执行此命令后，所有的SQL语句都会在一个私有的快照中执行，直到你提交或回滚这个事务。

（2）COMMIT：
用于提交事务。当你执行COMMIT语句时，所有从START TRANSACTION或BEGIN之后所做的更改都会永久地应用到数据库。这些更改在COMMIT之前对其他事务是不可见的。

（3）ROLLBACK：
如果你决定不应用从事务开始以来所做的更改，可以使用ROLLBACK命令。执行ROLLBACK后，所有在事务中所做的更改都会被撤销，数据库会回到事务开始前的状态。

除了上述基本命令外，MySQL还提供了更高级的功能，如事务的隔离级别设置，以满足不同的并发和一致性需求。
```

