## 项目介绍

```
设备管理
试验管理
	- 零部件、核心机、成熟机
数据管理
	- 零部件、核心机、成熟机试验数据
	- 业务数据：标签、故障信息、报告
	
算法模型管理
	- 数据预处理、特征提取、故障诊断、统计分析
业务流程管理
	- 单算法任务
	- 工作流任务

可视化
	- 总览页面
```



## 基本概念

### 数据源 coresys_data_source

```
是什么？
数据的来源，mysql、hbase、mongodb、minio桶

为什么？
数据采集时，和数据处理时需要从指定数据源中获取数据进行分析、存储或其他操作。

表结构 coresys_data_source:
id 
name 
desc 
type 
config (JSON字符串): 数据源的配置信息
app_id
```

### 数据集 coresys_dataset

```
数据集就是实体的集合，表示一类实体, 方便管理、授权
id
identifier
app_id
entity_ids: [1, 2, 3]字符串
role_grant: [1, 2, 3]字符串
```

### 实体模型 coresys_entity_modal

```
定义了数据的各位维度的信息。比如一张表的结构就是一个实体，我们需要定义它的列名，类型等
id
name
identifier
type
cofig: json字符串，存储维度信息
desc
app_id
version: 溯源用1_2_3
```

维度添加

```
名称、数据类型、是否为空、是否自增、是否主键、是否唯一、注释
```

### 实体

```
实体就是实体模型的实例化，就跟java中类和对象的关系一样
id
dataset_id
entity_modal_id
name
desc
role_grant: [1, 2, 3]字符串
data_source_type 数据源
```

## 工作流引擎

### 节点

#### 任务节点

```
设置任务的标题、执行类型、算法分组、算法名称、处理节点
需要配置算法模型中定义的参数配置
```

#### 数据对象节点

```
任务节点的输入、输出配置
类型：实体、数据集、minio_file
```

#### 事件类节点

```
（1）定时事件：
（2）周期事件：
```

#### 逻辑类节点

```
（1）IF节点
（2）分支节点
（3）合并节点
```

#### 连线&线上条件

```

```

### 架构

```
设计和实现的时候进行了模块化，主要的模块包括：流程构建器（任务节点、逻辑类节点、事件类节点等）、解析器、执行器、表达式解析器、监视器。
（1）流程构建器：
	- 负责流程的构建，通过gojs实现的一种可拖拽式的流程绘制模式，绘制的流程通过json的格式保存。

（2）解析器：
	- 负责json格式的流程解析，运用了「工厂+策略」的设计模式，去调用不同节点的解析器，生成对应的类对象，然后初始化到工作流引擎的节点状态池中。

（3）执行器：
	- 负责工作流程的执行。实现时通过「令牌 + 事件驱动」的模式来实现。令牌保障了消息丢失时能够去主动检测任务状态进行更新或重启；事件驱动则保证了任务能够异步执行，并且完成时能够向前推进。
	
（4）表达式解析器：
	- 一些逻辑类节点（if、switch）会有一些表达式，前期我是自己实现了一个解析工具，递归的从左到右进行解析；后期的话在浏览一些项目的时候发现了一个很好用的开源工具，叫huTool工具。
	
（5）事件处理器：在流程启动时会去开启，通过kafka来实现，去处理一些产生的事件，包含三部分：
	- 控制台指令：在前端界面点击按钮传输的指令。比如暂停、恢复、停止
	- 节点状态更新：celery worker执行完某一个算法后，会发送状态更新指令，监视器接收到后去更新对应节点的状态。
	- 状态上报：前端是要实时监控引擎的执行过程，节点状态更新、引擎发送异常等需要往前端推送状态。
	
（6）节点状态池
	- 节点状态池包含了整个工作流中所有节点信息 & 一些api，包括节点名称、表示符、配置，以及它的执行状态等。
解析器解析json时会向状态池中初始化各节点的信息以及初始状态。
	- 底层通过HashMap来实现，后来用concurrentMap优化了一下，防止在并发过程中出现问题
```

## 设备管理

```
分类：零部件，整机/核心机，成熟机型
```

## 实验管理

```
零部件实验：包含多个起停实验
整机/核心机实验：包含多个起停实验
成熟机型运行记录
```



## 数据管理

问题：数据模型管理怎么添加？？

### 内容

```
数据模型管理
实验数据管理：零部件实验数据、整机/核心机实验数据、整机实验数据
业务数据管理：标签管理、标签匹配规则管理、故障管理、异常告警管理
```

### 数据模型管理

```
数据模型，就是对数据各个维度定义，比如类型，长度等，数据库表中各个字段的定义

数据导入过程中，可以按照数据模型进行提取并存入数据库
多次实验时，可以使用上一次实验定义的数据模型，也可以继承上一次数据模型并进行修改，定义一个新的数据模型。
```

### 结构化时序试验数据管理

功能描述

```
结构化时序试验数据存储功能，支持将结构化时序试验数据存储至 指定数据集数据表当中
支持txt、 csv、mat、xls、xlsx 常用数据文本格式数据

接入方式包含「离线文件导入」、「MQTT实时数据流接入」
```

离线文件导入

```
其中离线文件导入支持将离线文件导入至系统，文件格式为 CSV、TXT、PDF， 其中 CSV 和 TXT 文件都为 UTF-8 编码，文件内容均由表头和数据 组成。
```

MQTT实时数据流接入

```
结构化时序数据来源于「数采系统以」及「快速存取记录器」 QAR 和 ACARS。
数采系统包括稳态（低频）和动态（高频）数采系统，支持接入方式为离线文件导入和 MQTT 实时数据流接入的方式。

稳态数采系统：
采集的数据时，使用 MQTT 实时数据流接入 的方式，

动态数采系统：
采集的数据时，需要用户先把这些数据保存为 UTF-8 编码的 CSV 格式，再采用离线文件导入的方式接入系统。

快速存取记录器 QAR 和 ACARS：
数据接入方式为离线文件导入的方式，其中 QAR 数据为 CSV 文件格式的， ACARS 数据为 TXT 文件格式的。对于 ACARS 数据，系统只提取模版匹配的数据，模版 由甲方提供。
```

什么是稳态数据？？？

```

```

结构化时序试验数据查看功能

```
支持筛选数据维度采用表格分页形式展示试验数据；
支持选择数据维度分别以折线图的方式展示各维度试验数据；
支持试验数据同一参数不同测点参数的周向分布图作图功能。
```

结构化时序试验数据的导出功能

```
支持对时序试验数据进行导出，导出时可指定数据的维度以及时间段，导出格式为 CSV。
```

### 非结构化数据管理功能 minio

描述

```
非结构化数据存储功能，支持将非结构化数据存储至对象存储数据库中。非结构化数据包括「试验日志数据」以及表 3 的其他文本、图片、 音频、视频文件。
```

非结构化数据上传

```

```

非结构化数据下载

```

```

## 业务流程管理

```
业务流程图是由任务节点和连接线构成的有 向无环图，其中任务节点类型包括数据源接入节点、数据保存入库节 点、可视化节点、算法模型节点
```

## 算法模型管理

```
算法模型就是一个个基础算法，定义了它的名称、类型、算法配置以及运行环境。
算法开发的过程是在notebook完成的，算法模型定义完后就可以在「单算法任务」和「工作流」里使用

算法配置包含输入、输出、参数
- 输入输出包含了三类：数据集、实体、minio文件
- 参数就是算法的形参，包含参数名、类型、默认值
```

## 状态监视功能

```
状态监视功能，支持选定指定台份启停试验，并将实时 数据接入的采集量参数和计算量展示在实时监控界面，用户可在展示 界面配置添加或删除展示数据的图表模块，通过选择数据集数据模型 中的维度参数创建生成图表模块，并以折线图的形式展示各个维度数 据，支持设置刷新频率、时间跨度和缩放，其中维度参数包括排气温 度、高低压转子振动、滑油温度、燃油流量、EGT 指示、N1 振动、 EGT 超限、滑油消耗、燃油（温度和压力）、N2 转速、总温、滑 油压力、高压涡轮叶片温度，并可以根据甲方需求进行维度参数的新 增或修改，如果传感器的采样率过高可按需对试验数据进行降采样。
```



## MINIO文件管理

### 数据库设计

```java
分片上传-分片任务记录表 sys_upload_task
id 
upload_id							// 分片上传的uploadId，需要根据该id来生成每个分片上传的地址
file_identifier				// 文件唯一标识（md5）
file_name							// 文件名
bucket_name						// 所属桶名
object_key						// 文件的key
total_size						// 文件大小（byte）
chunk_size						// 每个分片大小（byte）
chunk_num							// 分片数量
```

### 功能

#### 文件秒传

```
上传文件时会去计算文件的md5、文件大小、分片大小，将这些信息存储到数据库，再次上传时，根据md5值就能知道文件是否上传，
如果相同的路径下存在文件，则直接返回文件的uri；
如果路径不同，则调用拷贝接口，拷贝成功后返回。
```

#### 分片上传

```
将大文件拆分成小文件，将小文件上传\下载，最后再将小文件组装成大文件
```

<img src="https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/09/03/14144416937216841693721684124s5B5JY-20055016910643501691064350082DqOU1Q-640.png" alt="图片" style="zoom:50%;" />

```
流程：
（1）前端计算文件的md5值、文件大小、分片大小、文件名，调用文件上传接口
（2）根据md5值查询是否上传过，
		- 如果上传完成则直接返回；【文件秒传】
		- 如果有上传过但为上传完成，则返回已经上传的分片；【断点续传的内容】
		- 如果未上传，则调用minio接口开启一个上传任务获取uploadId，将文件上传信息插入上传记录表中
（3）根据md5去获取每个分片上传的地址【通过md5去查uploadId，根据uploadId和分片号查询上传地址】
（4）异步将每个分片上传到指定地址
（5）合并分片完成上传【监听进度，最后一个分片上传完就调合并接口】
```

#### 断点续传

```
指在传输过程中发生中断，或者传输失败，可以从断点处继续传输，而不需要从头开始传输整个文件
```

#### 分段下载

```
断点续传下载将需要下载的文件分成若干个分片分别下载，所有分片都下载完成后，将所有分片合并成完整的文件。
```

<img src="https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/04/213943169115638316911563833938akdFF-image-20220724211002451.png" alt="image-20220724211002451" style="zoom:50%;" />

```java
GetObjectResponse stream = minioClient.getObject(
  GetObjectArgs.builder()
  .bucket(statObjectResponse.bucket())
  .object(statObjectResponse.object())
  .offset(startByte)
  .length(contentLength)
  .build()
); 
```

参考

-   [minio断点下载](https://java.isture.com/arch/minio/minio-breakpoint-downloading.html#_3-%E6%96%AD%E7%82%B9%E4%B8%8B%E8%BD%BD)
-   [springboot使用minio实现分段下载](https://www.bilibili.com/read/cv21016230/)



#### 文件预览

```
openoffice
```

#### 文件夹重命名

```
加锁-复制-删除
```



## 问题

### 文件管理

#### 文件上传一半不上传了，怎么清理碎片分片？

```
（1）定时任务：可以考虑在sys_upload_task表中新加一个status字段，表示是否合并分片，默认为false，merge请求结束后变更为true，通过一个定时任务定期清理为status为false的记录。
（2）另外MinIO自身对于临时上传的分片，会实施定时清理
```

#### 如何知道哪些分片已经上传成功？

```
（1）方式1: 通过redis记录，md5:uploadId  -> 分片号
（2）方式2：直接调minio接口，获取已经上传的分片
```

#### 多个用户上传同一个文件怎么处理？

```
（1）文件上传锁：可以引入文件上传锁，确保同一时刻只有一个用户可以进行上传操作。当一个用户开始上传文件时，其他用户需要等待上传锁释放后才能开始上传。
（2）版本控制：可以为每个文件引入版本控制，确保每个上传的文件都有唯一的版本号。用户上传同名文件时，系统会自动为其分配一个新的版本号，以保证数据的唯一性。
```

#### 优化：多用户上传同一个文件

```
对分片加锁
```

### 什么选minio？不用fastDFS

什么是minio？

```
（1）MinIO是专门为海量数据存储、人工智能、大数据分析而设计的对象存储系统
（2）单个对象最大可达5TB。非常适合储海量图片、视频、日志文件、备份数据和容器/虚拟机镜像等
（3）MinIO主要采用Golang语言实现，整个系统都运行在操作系统的用户态空间，客户端与存储服务器之间采用HTTP/HTTPs通信协议。
```

为什么要用？

```
（1）安装部署简单，支持云容器化部署
（2）操作简单，自带ui管理界面。fastDFS默认没有
（3）性能优秀，可以达到每秒GB级别的读写速度
（4）提供了多语言SDK的支持，参考文档非常全面
（5）兼容亚马逊S3 API
		- 亚马逊云的 S3 API（接口协议） 是在全球范围内达到共识的对象存储的协议，是全世界认可的对象存储标准。而MinIO是第一个采用S3兼容协议的产品之一
		- 兼容S3 API有什么好处呢？相当于目前为了节约服务器成本，选择用MinIO自主开发对象存储系统，等企业壮大之后，不想再运维基础设施，可以直接将程序平移到云厂商，不需要重新开发。
```

[参考](https://juejin.cn/post/7115313166703132709)



### 为什么用celery？

```
Celery 是一个分布式任务队列系统，它可以用于执行长时间运行或定期任务

（1）异步处理：当应用需要执行一个可能会耗时的操作时，如发送电子邮件或处理大量数据，可以使用 Celery 将这些操作作为一个后台任务进行，从而不会阻塞用户的请求。
（2）分布式执行：Celery 允许在多个机器、虚拟机或容器中分布式地执行任务。这对于需要大量计算资源或并行处理的应用程序非常有用。
（3）可靠性：如果一个工作者（worker）或任务失败，Celery 可以配置为重试任务，从而提供更高的可靠性。
（4）监控和管理：通过工具如 Flower，开发者和运维人员可以实时监控和管理 Celery 的任务和工作者状态。可以通过taskId终止任务
```



### 为什么选择Mqtt？

```
（1）轻量级协议：MQTT是一个轻量级的发布/订阅协议，特别适合于低带宽、高延迟或不稳定的网络环境。这使其成为物联网(IoT)设备间通讯的理想选择，在我们的系统中，需要对实验过程中产生的数据进行采集，所以mqtt比较适合。
（2）MQTT支持三个不同的消息交付级别：0 (至多一次)，1 (至少一次)，2 (只有一次)。这为不同的应用场景提供了灵活性。
（3）持久会话：MQTT可以配置为持久会话，即当客户端掉线后，它可以再次上线并接收它错过的所有消息。
（4）集成和兼容性：许多IoT平台和设备已经内置了对MQTT的支持，这意味着在整合时可能会更加容易。

为什么不选kafka？
（1）Kafka的用途：虽然Kafka也是一个消息传递系统，但它主要用于大数据流处理和实时数据处理。它的设计目标是高吞吐量、持久性和分布式数据流。而MQTT更注重设备到设备或设备到服务器的通讯。
```

mqtt

```
MQTT（Message Queuing Telemetry Transport，消 是一种基于发布/订阅（publish/subscribe）模式的“轻量级”通讯协议。
最 大优点在于，用极少的代码和有限的带宽，为连接远程设备提供实时可靠的消息服务。
作为一种低开销、低带宽占用的即时通讯协议，使其在 物联网、小型设备、移动应用等方面有较广泛的应用。
```

kafka

```
Kafka 是一种高吞吐量的分布式发布订阅消息系统，
优势包括：
（1）高吞吐量、低延迟：每秒可以处理几十万条消息，它的延迟最低只有几毫 秒；
（2）可扩展性：集群支持热扩展；
（3）持久性、可靠性：消息被 持久化到本地磁盘，并且支持数据备份防止数据丢失；
（4）容错性：允 许集群中节点故障（若副本数量为 n，允许 n-1 个节点故障）；
（5）高并发：支持数千个客户端同时读写。
```



### 为什么要自己实现工作流引擎

```
（1）开源重量级：现有的成熟的工作流引擎都功能都比较完善、可靠性比较高。我了解到像activity这样的工作流引擎，它们其实是很复杂的很庞大的，依赖于很多张数据库表，这就对我们集成进来有很大的影响、成本也比较大。
	- 很多功能是不需要的
	- 需要去了解每张数据库表的具体含义
	- 想要去拓展的话还需要去了解它的实现过程
	- 开源的项目如果生产过程中出了问题不可控
（2）自研轻量级：每一个功能都是为需求而生，对架构了解也很容易进行拓展和优化，出了问题也比较容易把控，容易排查和解决。
（3）特定的需求开源的工作流引擎无法实现
		我们开发的这套系统有一套自己的概念（数据源、数据集模型、数据集、实体模型、实体），用这些开源的工作流引擎很难和我们的设计融合在一起，或者说融合的成本很大。
（4）优点：能够支持任务的分布式执行，我们是一个数据分析平台，需要跑很多长时间的算法，分布式执行能够很好的利用计算资源，提高效率。
（5）技术挑战与成长：对于开发团队来说，自行设计和实现东西可以是一次很好的技术挑战和成长机会。也可以形成我们自己的知识产权，不能说一个实验室没有自己沉淀的东西，什么都是拿来主义，那这样就会没有竞争力，容易被替代，这也使得我们实验室能够持续的有很多大项目合作的机会。
```

### 如何考虑到系统的扩展性和稳定性？

```
拓展性
（1）设计和实现的时候进行了模块化，主要的模块包括：流程构建器（任务节点、逻辑类节点、事件类节点等）、解析器、执行器、表达式解析器、监视器。
	- 流程构建器：负责流程的构建，通过gojs实现的一种可拖拽式的流程绘制模式，绘制的流程通过json的格式保存。
	- 解析器：负责json格式的流程解析，运用了「工厂+策略」的设计模式，去调用不同节点的解析器，生成对应的类对象，然后初始化到工作流引擎的节点状态池中。
	- 执行器：负责工作流程的执行。实现时通过「令牌 + 事件驱动」的模式来实现。令牌保障了消息丢失时能够去主动检测任务状态进行更新或重启；事件驱动则保证了任务能够异步执行，并且完成时能够向前推进。
	- 表达式解析器：一些逻辑类节点（if、switch）会有一些表达式，前期我是自己实现了一个解析工具，递归的从左到右进行解析；后期的话在浏览一些项目的时候发现了一个很好用的开源工具，叫huTool工具。
	- 监视器：通过mqtt来实现，去监听指定的话题，包含控制台指令、状态更新指令、状态上报
```

### 如何保证算法模型的质量和准确性的？

```
（1）遵循统一的规范：输入、输出、参数列表
（2）校验
（3）实体数据查看：如数据导入
```

### 如何优化大文件上传过程？

```
（1）分片上传：将大文件分割成多个小片段分别上传
（2）多个分片同时上传
（3）断点续传
（4）错误重试
（5）文件秒传
```

### 如何通过分布式锁解决文件夹的重命名、复制和删除问题？

```
问题描述：
minio是一种key、value的存储形式，没有提供文件夹的重命名功能，需要我们自己去实现这部分逻辑。重命名文件夹时，文件夹里面的文件也需要重命名，所以需要考虑原子性、一致性、隔离性问题。

（1）获取分布式锁：保证重命名过程中没有其他进程可以修改目标文件夹
（2）创建新的文件夹
（3）文件迁移：遍历文件夹下的所有文件，复制到新的目录上去
（4）删除原文件夹
（5）释放锁

考虑的问题：
（1）原子性：整个重命名操作是原子的，这意味着要么全部成功，要么全部失败。
（2）一致性：通过锁机制，我们确保在重命名过程中系统保持一致性，不会出现因并发操作而导致的数据不一致问题。
（3）隔离性：分布式锁可以保证在重命名操作期间，其他进程或线程无法访问被锁定的资源，从而实现操作的隔离性。
```

### 修改过程中是否允许其他用户上传文件？

```
我们希望避免在重命名过程中有其他用户上传文件到原文件夹中，因为这样可能会导致数据不一致或丢失。

我们考虑了两种策略：
（1）禁止上传
（2）队列上传请求：另一种策略是，在重命名过程中，将其他用户的上传请求放入一个队列中。一旦重命名完成并释放了锁，队列中的上传请求可以被处理。这样可以确保即使在重命名过程中，上传请求也不会被丢失，但这可能会增加系统的复杂性。

如何选择？
保证数据一致性选第一种
可以容忍短暂的上传延迟，就第二种。
```



### 有什么难点

#### 数据采集阶段：非结构化大文件上传

```
问题描述：
- 数据采集的时候分为实时采集、离线导入的方式。离线文件导入时通常文件会有一些比较大的文件，几个GB。
- 直接上传的话，用户体验很不好，如果出现网络中断，就需要重新上传，前面的操作也就白费了。

解决办法：
- 为了解决这个问题，我们选择了一个分布式的对象存储系统MinIO，通过文件的分片上传、断点续传、文件妙传来优化。
- 分片上传就是将一个大文件拆分成多个小的分片进行上传，在数据库里建了一张上传记录表，用于记录上传的任务（包括uploadId、file_identifier、fileName、文件大小、bucket、分片大小、分片数量）

流程：
（1）前端计算文件的md5值、文件大小、分片大小、文件名，调用文件上传接口
（2）根据md5值查询是否上传过，
		- 如果上传完成则直接返回；【文件秒传】
		- 如果有上传过但未上传完成，则返回已经上传的分片；【断点续传的内容】
		- 如果未上传，则调用minio接口开启一个上传任务获取uploadId，将文件上传信息插入上传记录表中
（3）根据md5去获取每个分片上传的地址【通过md5去查uploadId，根据uploadId和分片号查询上传地址】
（4）异步将每个分片上传到指定地址
（5）合并分片完成上传【监听进度，最后一个分片上传完就调合并接口】
```

#### 数据分析阶段：

```
我们的系统是一个数据分析平台，需要集成很多算法。我们一开始做法是，这些数据分析流程中会有很多共同的地方，比如数据预处理，都会有一些缺失值处理。我们通过抽取这些公共的算法封装成函数，然后再开发一些模版，将这些流程串起来。

这样就会存在一些问题：
（1）开发模式上的问题：这种开发方式，我们作为乙方会很被动，只有他们有算法需求，我们就需要派人去给他们集成。
（2）原先的方式执行流程，算法的执行过程是很难监控的，并且流程开始后，如果中途出现了错误，整个流程就要重新开始。
当数据量很大的时候有的算法步骤需要执行的时间很长，就相当于之前的都白做了。

解决办法：
（1）算法标准化：将每个算法抽象成算法模型，算法的输入、输出、参数有一套统一的规范，大家都遵循这个规范来开发。将单算法的执行做成一个服务的形式。
（2）开发了工作流执行引擎：通过流程编辑的方式，去自由组合算法的执行流程，并通过工作流引擎实现流程的自动执行。
```

怎么将算法的执行做成一个服务

```
算法执行服务是通过python编写的，提供一些REST API
我们运用了python的模块动态加载功能，结合Celery这个分布式调度框架来完成。
在Celery中注册了一个Run方法，并且每个算法都要去实现这个run方法，作为统一的入口。
当要去执行某个算法时，通过文件名找到对应的算法，然后将这个任务发布到worker中执行去执行，这样就能保证整个流程正常的运转
```

#### 数据可视化

```
通过数据分析完后，就要进行数据的可视化展示，比如通过折线图、坎贝尔图等。而一个总览页面通常会展示很多图，并且一个图的数据量也不小。
就发现从打开页面到数据可视化渲染完 整个过程需要花费挺长时间
```

#### 如何不重新部署还能添加算法

```
算法执行服务是通过python编写的，提供一些REST API
我们运用了python的模块动态加载功能，结合Celery这个分布式调度框架来完成。
在Celery中注册了一个Run方法，并且每个算法都要去实现这个run方法，作为统一的入口。
当要去执行某个算法时，通过文件名找到对应的算法，然后将这个任务发布到worker中执行去执行，这样就能保证整个流程正常的运转

api接口
- 获取任务状态
- 获取任务结果
- 创建任务
- 部署操作
- 停止任务
```

数字院（生产）   科技部（管理）

```

```



#### 难点3: 结构化数据的维度很多，难以复用

```
实验过程中产生的一些结构化数据维度很多，可能会有几百上千列，我们需要设计一种机制来管理好这些维度定义，并且能够复用、衍生、及溯源

我们就设计了实体模型（数据模型）这个概念，实体模型就是对数据列维度的定义，包括名称、类型等信息
多次实验列维度可能有所不同，就可以新建一个实体模型，集成原来的实体模型，然后进行修改
```









## 优化

### 串行接口改并行接口

```
对于一些不存在依赖关系的业务，需要在同一个接口中查询时，串行的处理就会导致后面的逻辑需要等待前面的业务查询处理完成之后才能开始。
比如查询坎贝尔图数据的时候，需要查询数据、辅助线，主体数据需要进行一些缺失值处理和排序，辅助线需要进行格式化，而这两个业务是不存在先后关系的，可以并行完成。

目前是通过「countDownLatch + 线程池」来完成
```

实现方式

```
方式1: join
方式2: countDownLatch + 线程池
方式3: CompletableFuture
```

参考

-   [串行处理的优化方式有哪些？](https://blog.csdn.net/WODESHENNI/article/details/125051287)
-   [如何写好代码：手把手教你写一个并行调用模板](https://articles.zsxq.com/id_051qnbm2cw68.html)
-   [JAVA使用CompletableFuture实现流水线并行处理，加速你的接口响应](https://heapdump.cn/article/4456384)



### SQL优化

如何分析

```
使用explain可以得到sql的查询计划
重点关注type、
```

怎么优化

```
（1）增删索引。
	- 删除一些不必要的索引
	- 一些查询频繁但修改少的字段添加索引，尽量添加联合索引。
（2）避免返回不必要的数据，返回需要的字段。
	- 比如工作流任务中，包含了一个text类型的字段，查询会消耗大量的网络和io带宽。在查询列表时是用不到这个字段信息的，只有在编辑流程时才需要查该字段。
（3）优化sql结构：
	- count(*) = count(1) > count(id) > count(字段)
	- limit：优化limit大分页问题。前端返回上次查询的最大记录；先查询limit后的id，再进行
（4）索引失效问题
		- 联合索引没有最左匹配
		- 操作索引列，计算、函数、类型转换
		- 查询条件 %like、or、not in、is not null
		- 隐式转换
```



### 项目中是怎么使用分布式锁的?

```
12 
9.30-10		8-9
1500
```

