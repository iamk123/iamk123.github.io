if(typeof AWPageMounts=='undefined'){AWPageMounts={}};AWPageMounts['m005']=[{"name":"00-系统功能.md","path":"005-项目/001-民用航空发动机健康管理系统/00-系统功能.md","content":"## 项目介绍\n\n```\n\n```\n\n\n\n## 基本概念\n\n### 数据源 coresys_data_source\n\n```\n是什么？\n数据的来源，mysql、hbase、mongodb、minio桶\n\n为什么？\n数据采集时，和数据处理时需要从指定数据源中获取数据进行分析、存储或其他操作。\n\n表结构 coresys_data_source:\nid \nname \ndesc \ntype \nconfig (JSON字符串): 数据源的配置信息\napp_id\n```\n\n### 数据集 coresys_dataset\n\n```\n数据集就是实体的集合，表示一类实体, 方便管理、授权\nid\nidentifier\napp_id\nentity_ids: [1, 2, 3]字符串\nrole_grant: [1, 2, 3]字符串\n```\n\n### 实体模型 coresys_entity_modal\n\n```\n定义了数据的各位维度的信息。比如一张表的结构就是一个实体，我们需要定义它的列名，类型等\nid\nname\nidentifier\ntype\ncofig: json字符串，存储维度信息\ndesc\napp_id\nversion: 溯源用1_2_3\n```\n\n维度添加\n\n```\n名称、数据类型、是否为空、是否自增、是否主键、是否唯一、注释\n```\n\n### 实体\n\n```\n实体就是实体模型的实例化，就跟java中类和对象的关系一样\nid\ndataset_id\nentity_modal_id\nname\ndesc\nrole_grant: [1, 2, 3]字符串\ndata_source_type 数据源\n```\n\n## 工作流引擎\n\n### 节点\n\n#### 任务节点\n\n```\n设置任务的标题、执行类型、算法分组、算法名称、处理节点\n需要配置算法模型中定义的参数配置\n```\n\n#### 数据对象节点\n\n```\n任务节点的输入、输出配置\n类型：实体、数据集、minio_file\n```\n\n#### 事件类节点\n\n```\n（1）定时事件：\n（2）周期事件：\n```\n\n#### 逻辑类节点\n\n```\n（1）IF节点\n（2）分支节点\n（3）合并节点\n```\n\n#### 连线&线上条件\n\n```\n\n```\n\n### 架构\n\n```\n设计和实现的时候进行了模块化，主要的模块包括：流程构建器（任务节点、逻辑类节点、事件类节点等）、解析器、执行器、表达式解析器、监视器。\n（1）流程构建器：\n\t- 负责流程的构建，通过gojs实现的一种可拖拽式的流程绘制模式，绘制的流程通过json的格式保存。\n\n（2）解析器：\n\t- 负责json格式的流程解析，运用了「工厂+策略」的设计模式，去调用不同节点的解析器，生成对应的类对象，然后初始化到工作流引擎的节点状态池中。\n\n（3）执行器：\n\t- 负责工作流程的执行。实现时通过「令牌 + 事件驱动」的模式来实现。令牌保障了消息丢失时能够去主动检测任务状态进行更新或重启；事件驱动则保证了任务能够异步执行，并且完成时能够向前推进。\n\t\n（4）表达式解析器：\n\t- 一些逻辑类节点（if、switch）会有一些表达式，前期我是自己实现了一个解析工具，递归的从左到右进行解析；后期的话在浏览一些项目的时候发现了一个很好用的开源工具，叫huTool工具。\n\t\n（5）监视器：在流程启动时会去开启，通过mqtt来实现，去监听指定的话题，包含三部分：\n\t- 控制台指令：在前端界面点击按钮传输的指令。比如暂停、恢复、停止\n\t- 节点状态更新：celery worker执行完某一个算法后，会发送状态更新指令，监视器接收到后去更新对应节点的状态。\n\t- 状态上报：前端是要实时监控引擎的执行过程，节点状态更新、引擎发送异常等需要往前端推送状态。\n\t\n（6）节点状态池\n\t- 节点状态池包含了整个工作流中所有节点信息 & 一些api，包括节点名称、表示符、配置，以及它的执行状态等。\n解析器解析json时会向状态池中初始化各节点的信息以及初始状态。\n\t- 底层通过HashMap来实现，后来用concurrentMap优化了一下，防止在并发过程中出现问题\n```\n\n## 设备管理\n\n```\n分类：零部件，整机/核心机，成熟机型\n```\n\n## 实验管理\n\n```\n零部件实验：包含多个起停实验\n整机/核心机实验：包含多个起停实验\n成熟机型运行记录\n```\n\n\n\n## 数据管理\n\n问题：数据模型管理怎么添加？？\n\n### 内容\n\n```\n数据模型管理\n实验数据管理：零部件实验数据、整机/核心机实验数据、整机实验数据\n业务数据管理：标签管理、标签匹配规则管理、故障管理、异常告警管理\n```\n\n### 数据模型管理\n\n```\n数据模型，就是对数据各个维度定义，比如类型，长度等，数据库表中各个字段的定义\n\n数据导入过程中，可以按照数据模型进行提取并存入数据库\n多次实验时，可以使用上一次实验定义的数据模型，也可以继承上一次数据模型并进行修改，定义一个新的数据模型。\n```\n\n### 结构化时序试验数据管理\n\n功能描述\n\n```\n结构化时序试验数据存储功能，支持将结构化时序试验数据存储至 指定数据集数据表当中\n支持txt、 csv、mat、xls、xlsx 常用数据文本格式数据\n\n接入方式包含「离线文件导入」、「MQTT实时数据流接入」\n```\n\n离线文件导入\n\n```\n其中离线文件导入支持将离线文件导入至系统，文件格式为 CSV、TXT、PDF， 其中 CSV 和 TXT 文件都为 UTF-8 编码，文件内容均由表头和数据 组成。\n```\n\nMQTT实时数据流接入\n\n```\n结构化时序数据来源于「数采系统以」及「快速存取记录器」 QAR 和 ACARS。\n数采系统包括稳态（低频）和动态（高频）数采系统，支持接入方式为离线文件导入和 MQTT 实时数据流接入的方式。\n\n稳态数采系统：\n采集的数据时，使用 MQTT 实时数据流接入 的方式，\n\n动态数采系统：\n采集的数据时，需要用户先把这些数据保存为 UTF-8 编码的 CSV 格式，再采用离线文件导入的方式接入系统。\n\n快速存取记录器 QAR 和 ACARS：\n数据接入方式为离线文件导入的方式，其中 QAR 数据为 CSV 文件格式的， ACARS 数据为 TXT 文件格式的。对于 ACARS 数据，系统只提取模版匹配的数据，模版 由甲方提供。\n```\n\n什么是稳态数据？？？\n\n```\n\n```\n\n结构化时序试验数据查看功能\n\n```\n支持筛选数据维度采用表格分页形式展示试验数据；\n支持选择数据维度分别以折线图的方式展示各维度试验数据；\n支持试验数据同一参数不同测点参数的周向分布图作图功能。\n```\n\n结构化时序试验数据的导出功能\n\n```\n支持对时序试验数据进行导出，导出时可指定数据的维度以及时间段，导出格式为 CSV。\n```\n\n### 非结构化数据管理功能 minio\n\n描述\n\n```\n非结构化数据存储功能，支持将非结构化数据存储至对象存储数据库中。非结构化数据包括「试验日志数据」以及表 3 的其他文本、图片、 音频、视频文件。\n```\n\n非结构化数据上传\n\n```\n\n```\n\n非结构化数据下载\n\n```\n\n```\n\n## 业务流程管理\n\n```\n业务流程图是由任务节点和连接线构成的有 向无环图，其中任务节点类型包括数据源接入节点、数据保存入库节 点、可视化节点、算法模型节点\n```\n\n## 算法模型管理\n\n```\n算法模型就是一个个基础算法，定义了它的名称、类型、算法配置以及运行环境。\n算法开发的过程是在notebook完成的，算法模型定义完后就可以在「单算法任务」和「工作流」里使用\n\n算法配置包含输入、输出、参数\n- 输入输出包含了三类：数据集、实体、minio文件\n- 参数就是算法的形参，包含参数名、类型、默认值\n```\n\n## 状态监视功能\n\n```\n状态监视功能，支持选定指定台份启停试验，并将实时 数据接入的采集量参数和计算量展示在实时监控界面，用户可在展示 界面配置添加或删除展示数据的图表模块，通过选择数据集数据模型 中的维度参数创建生成图表模块，并以折线图的形式展示各个维度数 据，支持设置刷新频率、时间跨度和缩放，其中维度参数包括排气温 度、高低压转子振动、滑油温度、燃油流量、EGT 指示、N1 振动、 EGT 超限、滑油消耗、燃油（温度和压力）、N2 转速、总温、滑 油压力、高压涡轮叶片温度，并可以根据甲方需求进行维度参数的新 增或修改，如果传感器的采样率过高可按需对试验数据进行降采样。\n```\n\n\n\n## MINIO文件管理\n\n### 数据库设计\n\n```java\n分片上传-分片任务记录表 sys_upload_task\nid \nupload_id\t\t\t\t\t\t\t// 分片上传的uploadId，需要根据该id来生成每个分片上传的地址\nfile_identifier\t\t\t\t// 文件唯一标识（md5）\nfile_name\t\t\t\t\t\t\t// 文件名\nbucket_name\t\t\t\t\t\t// 所属桶名\nobject_key\t\t\t\t\t\t// 文件的key\ntotal_size\t\t\t\t\t\t// 文件大小（byte）\nchunk_size\t\t\t\t\t\t// 每个分片大小（byte）\nchunk_num\t\t\t\t\t\t\t// 分片数量\n```\n\n### 功能\n\n#### 文件秒传\n\n```\n上传文件时会去计算文件的md5、文件大小、分片大小，将这些信息存储到数据库，再次上传时，根据md5值就能知道文件是否上传，\n如果相同的路径下存在文件，则直接返回文件的uri；\n如果路径不同，则调用拷贝接口，拷贝成功后返回。\n```\n\n#### 分片上传\n\n```\n将大文件拆分成小文件，将小文件上传\\下载，最后再将小文件组装成大文件\n```\n\n<img src=\"https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/09/03/14144416937216841693721684124s5B5JY-20055016910643501691064350082DqOU1Q-640.png\" alt=\"图片\" style=\"zoom:50%;\" />\n\n```\n流程：\n（1）前端计算文件的md5值、文件大小、分片大小、文件名，调用文件上传接口\n（2）根据md5值查询是否上传过，\n\t\t- 如果上传完成则直接返回；【文件秒传】\n\t\t- 如果有上传过但为上传完成，则返回已经上传的分片；【断点续传的内容】\n\t\t- 如果未上传，则调用minio接口开启一个上传任务获取uploadId，将文件上传信息插入上传记录表中\n（3）根据md5去获取每个分片上传的地址【通过md5去查uploadId，根据uploadId和分片号查询上传地址】\n（4）异步将每个分片上传到指定地址\n（5）合并分片完成上传【监听进度，最后一个分片上传完就调合并接口】\n```\n\n#### 断点续传\n\n```\n指在传输过程中发生中断，或者传输失败，可以从断点处继续传输，而不需要从头开始传输整个文件\n```\n\n#### 分段下载\n\n```\n断点续传下载将需要下载的文件分成若干个分片分别下载，所有分片都下载完成后，将所有分片合并成完整的文件。\n```\n\n<img src=\"https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/04/213943169115638316911563833938akdFF-image-20220724211002451.png\" alt=\"image-20220724211002451\" style=\"zoom:50%;\" />\n\n```java\nGetObjectResponse stream = minioClient.getObject(\n  GetObjectArgs.builder()\n  .bucket(statObjectResponse.bucket())\n  .object(statObjectResponse.object())\n  .offset(startByte)\n  .length(contentLength)\n  .build()\n); \n```\n\n参考\n\n-   [minio断点下载](https://java.isture.com/arch/minio/minio-breakpoint-downloading.html#_3-%E6%96%AD%E7%82%B9%E4%B8%8B%E8%BD%BD)\n-   [springboot使用minio实现分段下载](https://www.bilibili.com/read/cv21016230/)\n\n\n\n#### 文件预览\n\n```\nopenoffice\n```\n\n#### 文件夹重命名\n\n```\n加锁-复制-删除\n```\n\n\n\n## 问题\n\n### 文件管理\n\n#### 文件上传一半不上传了，怎么清理碎片分片？\n\n```\n（1）定时任务：可以考虑在sys_upload_task表中新加一个status字段，表示是否合并分片，默认为false，merge请求结束后变更为true，通过一个定时任务定期清理为status为false的记录。\n（2）另外MinIO自身对于临时上传的分片，会实施定时清理\n```\n\n#### 如何知道哪些分片已经上传成功？\n\n```\n（1）方式1: 通过redis记录，md5:uploadId  -> 分片号\n（2）方式2：直接调minio接口，获取已经上传的分片\n```\n\n#### 多个用户上传同一个文件怎么处理？\n\n```\n（1）文件上传锁：可以引入文件上传锁，确保同一时刻只有一个用户可以进行上传操作。当一个用户开始上传文件时，其他用户需要等待上传锁释放后才能开始上传。\n（2）版本控制：可以为每个文件引入版本控制，确保每个上传的文件都有唯一的版本号。用户上传同名文件时，系统会自动为其分配一个新的版本号，以保证数据的唯一性。\n```\n\n#### 优化：多用户上传同一个文件\n\n```\n对分片加锁\n```\n\n### 什么选minio？不用fastDFS\n\n什么是minio？\n\n```\n（1）MinIO是专门为海量数据存储、人工智能、大数据分析而设计的对象存储系统\n（2）单个对象最大可达5TB。非常适合储海量图片、视频、日志文件、备份数据和容器/虚拟机镜像等\n（3）MinIO主要采用Golang语言实现，整个系统都运行在操作系统的用户态空间，客户端与存储服务器之间采用HTTP/HTTPs通信协议。\n```\n\n为什么要用？\n\n```\n（1）安装部署简单，支持云容器化部署\n（2）操作简单，自带ui管理界面。fastDFS默认没有\n（3）性能优秀，可以达到每秒GB级别的读写速度\n（4）提供了多语言SDK的支持，参考文档非常全面\n（5）兼容亚马逊S3 API\n\t\t- 亚马逊云的 S3 API（接口协议） 是在全球范围内达到共识的对象存储的协议，是全世界认可的对象存储标准。而MinIO是第一个采用S3兼容协议的产品之一\n\t\t- 兼容S3 API有什么好处呢？相当于目前为了节约服务器成本，选择用MinIO自主开发对象存储系统，等企业壮大之后，不想再运维基础设施，可以直接将程序平移到云厂商，不需要重新开发。\n```\n\n[参考](https://juejin.cn/post/7115313166703132709)\n\n\n\n### 为什么用celery？\n\n```\nCelery 是一个分布式任务队列系统，它可以用于执行长时间运行或定期任务\n\n（1）异步处理：当应用需要执行一个可能会耗时的操作时，如发送电子邮件或处理大量数据，可以使用 Celery 将这些操作作为一个后台任务进行，从而不会阻塞用户的请求。\n（2）分布式执行：Celery 允许在多个机器、虚拟机或容器中分布式地执行任务。这对于需要大量计算资源或并行处理的应用程序非常有用。\n（3）可靠性：如果一个工作者（worker）或任务失败，Celery 可以配置为重试任务，从而提供更高的可靠性。\n（4）监控和管理：通过工具如 Flower，开发者和运维人员可以实时监控和管理 Celery 的任务和工作者状态。可以通过taskId终止任务\n```\n\n\n\n### 为什么选择Mqtt？\n\n```\n（1）轻量级协议：MQTT是一个轻量级的发布/订阅协议，特别适合于低带宽、高延迟或不稳定的网络环境。这使其成为物联网(IoT)设备间通讯的理想选择，在我们的系统中，需要对实验过程中产生的数据进行采集，所以mqtt比较适合。\n（2）MQTT支持三个不同的消息交付级别：0 (至多一次)，1 (至少一次)，2 (只有一次)。这为不同的应用场景提供了灵活性。\n（3）持久会话：MQTT可以配置为持久会话，即当客户端掉线后，它可以再次上线并接收它错过的所有消息。\n（4）集成和兼容性：许多IoT平台和设备已经内置了对MQTT的支持，这意味着在整合时可能会更加容易。\n\n为什么不选kafka？\n（1）Kafka的用途：虽然Kafka也是一个消息传递系统，但它主要用于大数据流处理和实时数据处理。它的设计目标是高吞吐量、持久性和分布式数据流。而MQTT更注重设备到设备或设备到服务器的通讯。\n```\n\nmqtt\n\n```\nMQTT（Message Queuing Telemetry Transport，消 是一种基于发布/订阅（publish/subscribe）模式的“轻量级”通讯协议。\n最 大优点在于，用极少的代码和有限的带宽，为连接远程设备提供实时可靠的消息服务。\n作为一种低开销、低带宽占用的即时通讯协议，使其在 物联网、小型设备、移动应用等方面有较广泛的应用。\n```\n\nkafka\n\n```\nKafka 是一种高吞吐量的分布式发布订阅消息系统，\n优势包括：\n（1）高吞吐量、低延迟：每秒可以处理几十万条消息，它的延迟最低只有几毫 秒；\n（2）可扩展性：集群支持热扩展；\n（3）持久性、可靠性：消息被 持久化到本地磁盘，并且支持数据备份防止数据丢失；\n（4）容错性：允 许集群中节点故障（若副本数量为 n，允许 n-1 个节点故障）；\n（5）高并发：支持数千个客户端同时读写。\n```\n\n\n\n### 为什么要自己实现工作流引擎\n\n```\n（1）开源重量级：现有的成熟的工作流引擎都功能都比较完善、可靠性比较高。我了解到像activity这样的工作流引擎，它们其实是很复杂的很庞大的，依赖于很多张数据库表，这就对我们集成进来有很大的影响、成本也比较大。\n\t- 很多功能是不需要的\n\t- 需要去了解每张数据库表的具体含义\n\t- 想要去拓展的话还需要去了解它的实现过程\n\t- 开源的项目如果生产过程中出了问题不可控\n（2）自研轻量级：每一个功能都是为需求而生，对架构了解也很容易进行拓展和优化，出了问题也比较容易把控，容易排查和解决。\n（3）特定的需求开源的工作流引擎无法实现\n\t\t我们开发的这套系统有一套自己的概念（数据源、数据集模型、数据集、实体模型、实体），用这些开源的工作流引擎很难和我们的设计融合在一起，或者说融合的成本很大。\n（4）优点：能够支持任务的分布式执行，我们是一个数据分析平台，需要跑很多长时间的算法，分布式执行能够很好的利用计算资源，提高效率。\n（5）技术挑战与成长：对于开发团队来说，自行设计和实现东西可以是一次很好的技术挑战和成长机会。也可以形成我们自己的知识产权，不能说一个实验室没有自己沉淀的东西，什么都是拿来主义，那这样就会没有竞争力，容易被替代，这也使得我们实验室能够持续的有很多大项目合作的机会。\n```\n\n### 如何考虑到系统的扩展性和稳定性？\n\n```\n拓展性\n（1）设计和实现的时候进行了模块化，主要的模块包括：流程构建器（任务节点、逻辑类节点、事件类节点等）、解析器、执行器、表达式解析器、监视器。\n\t- 流程构建器：负责流程的构建，通过gojs实现的一种可拖拽式的流程绘制模式，绘制的流程通过json的格式保存。\n\t- 解析器：负责json格式的流程解析，运用了「工厂+策略」的设计模式，去调用不同节点的解析器，生成对应的类对象，然后初始化到工作流引擎的节点状态池中。\n\t- 执行器：负责工作流程的执行。实现时通过「令牌 + 事件驱动」的模式来实现。令牌保障了消息丢失时能够去主动检测任务状态进行更新或重启；事件驱动则保证了任务能够异步执行，并且完成时能够向前推进。\n\t- 表达式解析器：一些逻辑类节点（if、switch）会有一些表达式，前期我是自己实现了一个解析工具，递归的从左到右进行解析；后期的话在浏览一些项目的时候发现了一个很好用的开源工具，叫huTool工具。\n\t- 监视器：通过mqtt来实现，去监听指定的话题，包含控制台指令、状态更新指令、状态上报\n```\n\n### 如何保证算法模型的质量和准确性的？\n\n```\n（1）遵循统一的规范：输入、输出、参数列表\n（2）校验\n（3）实体数据查看：如数据导入\n```\n\n### 如何优化大文件上传过程？\n\n```\n（1）分片上传：将大文件分割成多个小片段分别上传\n（2）多个分片同时上传\n（3）断点续传\n（4）错误重试\n（5）文件秒传\n```\n\n### 如何通过分布式锁解决文件夹的重命名、复制和删除问题？\n\n```\n问题描述：\nminio是一种key、value的存储形式，没有提供文件夹的重命名功能，需要我们自己去实现这部分逻辑。重命名文件夹时，文件夹里面的文件也需要重命名，所以需要考虑原子性、一致性、隔离性问题。\n\n（1）获取分布式锁：保证重命名过程中没有其他进程可以修改目标文件夹\n（2）创建新的文件夹\n（3）文件迁移：遍历文件夹下的所有文件，复制到新的目录上去\n（4）删除原文件夹\n（5）释放锁\n\n考虑的问题：\n（1）原子性：整个重命名操作是原子的，这意味着要么全部成功，要么全部失败。\n（2）一致性：通过锁机制，我们确保在重命名过程中系统保持一致性，不会出现因并发操作而导致的数据不一致问题。\n（3）隔离性：分布式锁可以保证在重命名操作期间，其他进程或线程无法访问被锁定的资源，从而实现操作的隔离性。\n```\n\n### 修改过程中是否允许其他用户上传文件？\n\n```\n我们希望避免在重命名过程中有其他用户上传文件到原文件夹中，因为这样可能会导致数据不一致或丢失。\n\n我们考虑了两种策略：\n（1）禁止上传\n（2）队列上传请求：另一种策略是，在重命名过程中，将其他用户的上传请求放入一个队列中。一旦重命名完成并释放了锁，队列中的上传请求可以被处理。这样可以确保即使在重命名过程中，上传请求也不会被丢失，但这可能会增加系统的复杂性。\n\n如何选择？\n保证数据一致性选第一种\n可以容忍短暂的上传延迟，就第二种。\n```\n\n\n\n### 有什么难点\n\n#### 数据采集阶段：非结构化大文件上传\n\n```\n问题描述：\n- 数据采集的时候分为实时采集、离线导入的方式。离线文件导入时通常文件会有一些比较大的文件，几个GB。\n- 直接上传的话，用户体验很不好，如果出现网络中断，就需要重新上传，前面的操作也就白费了。\n\n解决办法：\n- 为了解决这个问题，我们选择了一个分布式的对象存储系统MinIO，通过文件的分片上传、断点续传、文件妙传来优化。\n- 分片上传就是将一个大文件拆分成多个小的分片进行上传，在数据库里建了一张上传记录表，用于记录上传的任务（包括uploadId、file_identifier、fileName、文件大小、bucket、分片大小、分片数量）\n\n流程：\n（1）前端计算文件的md5值、文件大小、分片大小、文件名，调用文件上传接口\n（2）根据md5值查询是否上传过，\n\t\t- 如果上传完成则直接返回；【文件秒传】\n\t\t- 如果有上传过但未上传完成，则返回已经上传的分片；【断点续传的内容】\n\t\t- 如果未上传，则调用minio接口开启一个上传任务获取uploadId，将文件上传信息插入上传记录表中\n（3）根据md5去获取每个分片上传的地址【通过md5去查uploadId，根据uploadId和分片号查询上传地址】\n（4）异步将每个分片上传到指定地址\n（5）合并分片完成上传【监听进度，最后一个分片上传完就调合并接口】\n```\n\n#### 数据分析阶段：\n\n```\n我们的系统是一个数据分析平台，需要集成很多算法。我们一开始做法是，这些数据分析流程中会有很多共同的地方，比如数据预处理，都会有一些缺失值处理。我们通过抽取这些公共的算法封装成函数，然后再开发一些模版，将这些流程串起来。\n\n这样就会存在一些问题：\n（1）开发模式上的问题：这种开发方式，我们作为乙方会很被动，只有他们有算法需求，我们就需要派人去给他们集成。\n（2）原先的方式执行流程，算法的执行过程是很难监控的，并且流程开始后，如果中途出现了错误，整个流程就要重新开始。\n当数据量很大的时候有的算法步骤需要执行的时间很长，就相当于之前的都白做了。\n\n解决办法：\n（1）算法标准化：将每个算法抽象成算法模型，算法的输入、输出、参数有一套统一的规范，大家都遵循这个规范来开发。将单算法的执行做成一个服务的形式。\n（2）开发了工作流执行引擎：通过流程编辑的方式，去自由组合算法的执行流程，并通过工作流引擎实现流程的自动执行。\n```\n\n怎么将算法的执行做成一个服务\n\n```\n算法执行服务是通过python编写的，提供一些REST API\n我们运用了python的模块动态加载功能，结合Celery这个分布式调度框架来完成。\n在Celery中注册了一个Run方法，并且每个算法都要去实现这个run方法，作为统一的入口。\n当要去执行某个算法时，通过文件名找到对应的算法，然后将这个任务发布到worker中执行去执行，这样就能保证整个流程正常的运转\n```\n\n#### 数据可视化\n\n```\n通过数据分析完后，就要进行数据的可视化展示，比如通过折线图、坎贝尔图等。而一个总览页面通常会展示很多图，并且一个图的数据量也不小。\n就发现从打开页面到数据可视化渲染完 整个过程需要花费挺长时间\n```\n\n#### 如何不重新部署还能添加算法\n\n```\n算法执行服务是通过python编写的，提供一些REST API\n我们运用了python的模块动态加载功能，结合Celery这个分布式调度框架来完成。\n在Celery中注册了一个Run方法，并且每个算法都要去实现这个run方法，作为统一的入口。\n当要去执行某个算法时，通过文件名找到对应的算法，然后将这个任务发布到worker中执行去执行，这样就能保证整个流程正常的运转\n\napi接口\n- 获取任务状态\n- 获取任务结果\n- 创建任务\n- 部署操作\n- 停止任务\n```\n\n\n\n#### 难点3: 结构化数据的维度很多，难以复用\n\n```\n实验过程中产生的一些结构化数据维度很多，可能会有几百上千列，我们需要设计一种机制来管理好这些维度定义，并且能够复用、衍生、及溯源\n\n我们就设计了实体模型（数据模型）这个概念，实体模型就是对数据列维度的定义，包括名称、类型等信息\n多次实验列维度可能有所不同，就可以新建一个实体模型，集成原来的实体模型，然后进行修改\n```\n\n\n\n\n\n\n\n\n\n## 优化\n\n### 串行接口改并行接口\n\n```\n对于一些不存在依赖关系的业务，需要在同一个接口中查询时，串行的处理就会导致后面的逻辑需要等待前面的业务查询处理完成之后才能开始。\n比如查询坎贝尔图数据的时候，需要查询数据、辅助线，主体数据需要进行一些缺失值处理和排序，辅助线需要进行格式化，而这两个业务是不存在先后关系的，可以并行完成。\n\n目前是通过「countDownLatch + 线程池」来完成\n```\n\n实现方式\n\n```\n方式1: join\n方式2: countDownLatch + 线程池\n方式3: CompletableFuture\n```\n\n参考\n\n-   [串行处理的优化方式有哪些？](https://blog.csdn.net/WODESHENNI/article/details/125051287)\n-   [如何写好代码：手把手教你写一个并行调用模板](https://articles.zsxq.com/id_051qnbm2cw68.html)\n-   [JAVA使用CompletableFuture实现流水线并行处理，加速你的接口响应](https://heapdump.cn/article/4456384)\n\n\n\n### SQL优化\n\n如何分析\n\n```\n使用explain可以得到sql的查询计划\n重点关注type、\n```\n\n怎么优化\n\n```\n（1）增删索引。\n\t- 删除一些不必要的索引\n\t- 一些查询频繁但修改少的字段添加索引，尽量添加联合索引。\n（2）避免返回不必要的数据，返回需要的字段。\n\t- 比如工作流任务中，包含了一个text类型的字段，查询会消耗大量的网络和io带宽。在查询列表时是用不到这个字段信息的，只有在编辑流程时才需要查该字段。\n（3）优化sql结构：\n\t- count(*) = count(1) > count(id) > count(字段)\n\t- limit：优化limit大分页问题。前端返回上次查询的最大记录；先查询limit后的id，再进行\n（4）索引失效问题\n\t\t- 联合索引没有最左匹配\n\t\t- 操作索引列，计算、函数、类型转换\n\t\t- 查询条件 %like、or、not in、is not null\n\t\t- 隐式转换\n```\n\n\n\n### 项目中是怎么使用分布式锁的?\n\n```\n\n```\n\n","timestamp":1695293386005},{"name":"03-设计图.md","path":"005-项目/001-民用航空发动机健康管理系统/03-设计图.md","content":"软件逻辑架构图\n\n![image-20230817231059358](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/17/23105916922850591692285059511P1Gvac-image-20230817231059358.png)\n\n物理结构图\n\n![image-20230817231132354](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/17/231132169228509216922850924542RaPbD-image-20230817231132354.png)\n\n\n\n```\n商用发动机健康管理平台\n\n项目描述:\n项目是与中国航发商发合作项目,旨在实时监控航空发动机试验,并能收集数据进行处理,分析及诊断,协助试验推进,实现数据分析全流程。包含实验管理功能,状态监视功能,异常自动检测功能,故障诊断功能,数据可视化功能等\n\n技术栈:\nSpringboot+Mybatis+MySQL+Redis+Mqtt;Python+Celery+HBase+MongoDB\n\n主要工作\n（1）参与系统设计,包括数据源,数据集,实体模型,实体等设计,解决多类型结构数据存储,衍生,溯源等问题\n（2）设计工作流引擎基础架构,包含流程构建器(任务节点,逻辑类节点,事件类节点等)解析器,执行器,表达式解析器、监视器等。使用线程池,mqtt,celery实现分布式工作流执行引擎\n（3）负责算法模型的设计,实现算法模型管理,分布式单算法任务管理;并参与部分算法模型的开发,如实体指定维度排序算法,缺失值处理,行平均算法,列平均算法等\n（4）通过minio实现非结构化数据管理,并通过文件分片上传,断点续传,文件秒传等优化大文件上传过程;通过分布式锁解决文件夹重命名,复制,删除问题\n（5）使用mqtt构建异步消息系统,实现发送通知,异常告警,任务状态同步,工作流任务推进等\n\n项目优化：\n（1）通过将业务流程从串行改为并行处理,提高接口响应速度,使耗时减少超过一半\n（2）通过优化数据库索引,sql语句等优化慢sql问题,如limit大分页问题,索引失效问题等\n```\n\n","timestamp":1695293386005},{"name":"01-系统功能.md","path":"005-项目/002-weTeam校园/01-系统功能.md","content":"## 公用模块\n\n### 分布式共享session\n\n```\n如果一个分布式 Web 服务将用户的 Session 信息保存在各自服务器，用户刷 新一次可能就需要重新登录了，这样显然有问题。实际上，可以使用 Redis 将 用户的 Session 进行集中管理，每次用户更新或者查询登录信息都直接从 Redis 中集中获取。\n```\n\n\n\n### 登录/登出\n\n```\n使用JWT+Redis的方式实现登录功能，采用双令牌认证的方式实现用户无感知登录刷新，踢下线，单设备登录\n无感知登录参考（前后端）：https://juejin.cn/post/7215569601161150522\n后端实现：https://mp.weixin.qq.com/s/x1hGWJ1FbTH-9w_28fSy5g\n```\n\nTODO: \n\n```\n- 踢下线\n```\n\n\n\n### ThreadLocal存储用户信息\n\n用处\n\n```java\n1. 线程隔离\n2. 统一管理用户信息。不用每次都去解析httpServletRequest\n  \n@GetMapping(\"/add\")\npublic ResultUtil showUsers(@RequestParam String username, \n                            HttpServletRequest httpServletRequest){\n  \tString token = httpServletRequest.getHeader(\"token\");\n}\n```\n\n实现\n\n`RequestHolder.java`\n\n```java\npublic class RequestHolder {\n    private final static ThreadLocal<Integer> requestHolderUserId = new ThreadLocal<>();\n    private final static ThreadLocal<LoggerModel> requestHolderLoggerModel = new ThreadLocal<>(); // 请求日志\n\n    private RequestHolder() {\n    }\n\n    public static void setUserId(Integer userId) {\n        requestHolderUserId.set(userId);\n    }\n    public static Integer getUserId() {\n        return requestHolderUserId.get();\n    }\n    public static void removeUserId() {\n        requestHolderUserId.remove();\n    }\n  \n  \t// 请求日志相关方法省略\n\n    /**\n     * 获取当前token\n     * @return\n     */\n    public static String getToken() {\n        HttpServletRequest  request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest();\n        String token = \"\";\n        token = request.getHeader(CommonConstants.TOKEN);\n        if(StringUtils.isEmpty(token)) {\n            token = request.getParameter(CommonConstants.TOKEN);\n        }\n        return token;\n    }\n\n    /**\n     * 获取当前refresh token\n     * @return\n     */\n    public static String getRefreshToken() {\n        HttpServletRequest  request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest();\n        String token = \"\";\n        token = request.getHeader(CommonConstants.REFRESH_TOKEN);\n        if(StringUtils.isEmpty(token)) {\n            token = request.getParameter(CommonConstants.REFRESH_TOKEN);\n        }\n        return token;\n    }\n}\n```\n\n在拦截器`AuthInterceptor.java`中解析请求并存入RequestHolder中, 请求处理完后移除\n\n```java\n@Component\npublic class AuthInterceptor implements HandlerInterceptor {\n    @Autowired\n    private ILoggerStore loggerStore;\n    @Autowired\n    RedisUtil redisUtil;\n\n    @Override\n    public boolean preHandle(HttpServletRequest request,\n                             HttpServletResponse response, Object handler) throws Exception {\n\n        if (handler.getClass().isAssignableFrom(HandlerMethod.class)) {\n\n            String token = RequestHolder.getToken();\n            Integer userId = JwtToken.getUserId(token);\n\t\t\t\t\t\t\n          \t// ...\n            // 解码token验证\n            if (!JwtToken.verify(token)) {\n                throw new BizException(GlobalErrEnum.GL99990401);\n            }\n            RequestHolder.setUserId(userId);\n\n        }\n        return true;\n    }\n\n    @Override\n    public void afterCompletion(HttpServletRequest request,\n                                HttpServletResponse response, \n                                Object handler, Exception ex) throws Exception {\n\n        // 记得要移除！！！！！\n        RequestHolder.removeLoggerModel();\n        // 记得要移除！！！！！\n        RequestHolder.removeUserId();\n    }\n}\n```\n\n使用\n\n```java\nString token = RequestHolder.getToken();\nInteger userId = RequestHolder.getUserId();\n```\n\n\n\n### 数据统计 TODO： [如何统计网站uv？](https://www.yuque.com/snailclimb/mf2z3k/dawnum) 密码：cnk4\n\n#### 网站UV\n\n##### 功能概述\n\n```\nuv即Unique Visitor，统计网站的独立访问用户数\n```\n\n##### 实现过程\n\n存入：\n\n在拦截器`DataInterceptor`中拦截请求，preHandle中调用`DataService.recordUV(String ip)`\n存储在redis中， key为`vu:日期`（格式：yyyMMdd）\n\n```java\npublic void recordUV(String ip) {\n    String redisKey = RedisKeyUtil.getUVKey(df.format(new Date()));  // vu:yyyyMMdd\n    redisTemplate.opsForHyperLogLog().add(redisKey, ip);\n}\n```\n\n统计：\n\n```java\npublic long calculateUV(Date start, Date end) {\n    if (start == null || end == null) {\n      throw new IllegalArgumentException(\"参数不能为空!\");\n    }\n\n    // 整理该日期范围内的key\n    List<String> keyList = new ArrayList<>();\n    Calendar calendar = Calendar.getInstance();\n    calendar.setTime(start);\n    while (!calendar.getTime().after(end)) {\t// 将每个日期对应的 key 添加到 keyList 中\n      String key = RedisKeyUtil.getUVKey(df.format(calendar.getTime()));\n      keyList.add(key);\n      calendar.add(Calendar.DATE, 1);\n    }\n\n    // 合并这些数据，存到redisKey中\n    String redisKey = RedisKeyUtil.getUVKey(df.format(start), df.format(end));\t// uv:yyyyMMdd:yyyMMdd\n    redisTemplate.opsForHyperLogLog().union(redisKey, keyList.toArray());  // 解释1\n\n    // 返回统计的结果\n    return redisTemplate.opsForHyperLogLog().size(redisKey);\n}\n```\n\n解释1\n\n```\nredisTemplate.opsForHyperLogLog().union(redisKey, keyList.toArray()) 是将多个 HyperLogLog 结构合并成一个的操作。\n\n在代码中，keyList 是包含多个日期对应的 HyperLogLog 结构的 key 的列表。这些 key 对应的 HyperLogLog 结构记录了每个日期范围内的独立访客信息。\n\nredisTemplate.opsForHyperLogLog().union(redisKey, keyList.toArray()) 的作用是将 keyList 中的多个 HyperLogLog 结构合并到名为 redisKey 的 HyperLogLog 结构中。通过这个操作，可以将多个日期范围内的独立访客信息统一存储在一个 HyperLogLog 结构中，方便后续进行独立访客数量的统计。\n\n合并后，redisKey 对应的 HyperLogLog 结构将包含所有日期范围内的独立访客信息，可以通过 redisTemplate.opsForHyperLogLog().size(redisKey) 获取统计结果，即给定日期范围内的独立访客数量。\n```\n\n#### 网站DAU\n\n##### 功能概述\n\n```\nDaily Active User，日活跃用户数量\n```\n\n##### 实现过程\n\n存入：\n\n在拦截器`DataInterceptor`中拦截请求，preHandle中调用`DataService.recordDAU(int userId)`\n存储在redis中， key为`dau:日期`（格式：yyyMMdd）\n\n```java\npublic void recordDAU(int userId) {\n    String redisKey = RedisKeyUtil.getDAUKey(df.format(new Date()));\t// dau:yyyyMMdd\n    redisTemplate.opsForValue().setBit(redisKey, userId, true);\n}\n```\n\n统计：\n\n```java\n// 统计指定日期范围内的DAU\n@Override\npublic long calculateDAU(Date start, Date end) {\n    if (start == null || end == null) {\n      \tthrow new IllegalArgumentException(\"参数不能为空!\");\n    }\n\n    // 整理该日期范围内的key\n    List<byte[]> keyList = new ArrayList<>();\n    Calendar calendar = Calendar.getInstance();\n    calendar.setTime(start);\n    while (!calendar.getTime().after(end)) {\n        String key = RedisKeyUtil.getDAUKey(df.format(calendar.getTime()));\n        keyList.add(key.getBytes());\n        calendar.add(Calendar.DATE, 1);\n    }\n\n    // 进行OR运算\n    return (long) redisTemplate.execute(new RedisCallback() {\n      @Override\n      public Object doInRedis(RedisConnection connection) throws DataAccessException {\n          String redisKey = RedisKeyUtil.getDAUKey(df.format(start), df.format(end));\n          connection.bitOp(RedisStringCommands.BitOperation.OR,\n                         redisKey.getBytes(), keyList.toArray(new byte[0][0]));\n        \treturn connection.bitCount(redisKey.getBytes());\n      }\n    });\n}\n```\n\n\n\n## 用户模块\n\n### 关注、点赞、收藏\n\n关注比赛，关注人，关注帖子抽象出来，即都为实体\n\n| 实体类型entityType | 对应值 |\n| :----------------: | :----: |\n|      比赛Game      |   1    |\n|      用户User      |   2    |\n|  比赛类别GameType  |   3    |\n\n\n\n关注列表：只有人才能关注\n\n粉丝列表：比赛粉丝列表、用户粉丝列表，...\n\n\n\n-   用户U1关注了用户U2 ：\n\n    ```\n    follow : u1Id : 2 -> [u2Id, ...]；  \t\t\t// u1关注u2\n    follower : 2 : u2Id  -> [u1Id, ...];\t\t// u2的粉丝是u1\n    ```\n\n-   用户U1的用户关注列表：\n\n    ```\n    follow : u1Id : 2 返回集合\n    ```\n\n-   用户U1的用户关注数：\n\n    ```\n    follow:: u1Id: 2 返回集合大小\n    ```\n\n-   用户U1的粉丝数：follower：2：u1Id\n\n    ```\n    follower：2：u1Id 返回集合大小\n    ```\n\n-   用户U2的粉丝数：follower : 2 : u2Id 返回集合大小\n\n    ```\n    follower：2：u2Id 返回集合大小\n    ```\n\n    \n\n-   用户U1关注比赛G1：\n\n    ```\n    follow : u1Id : 1 -> g1Id\n    follower : 1 : g1Id - > u1Id\n    ```\n\n-   用户U1的比赛关注列表：\n\n    ```\n    follo : u1Id : 1返回集合\n    ```\n\n-   用户U1的比赛关注数：\n\n    ```\n    follo : u1Id : 1返回集合 返回集合大小\n    ```\n\n-   比赛G1的关注者：\n\n    ```\n    follower : 1 : g1Id \n    ```\n\n    \n\n```\n// 某个用户关注的实体  key -> value\nfollow:用户id:关注的实体类型 -> zset(关注的实体id， 评分)\nfollow:userId:entityType -> zset(entityId, now)  \n\neg：\n用户1关注了比赛1： followee:1:1 -> zset(1, new Time())\n用户1关注了用户3:  followee:1:2 -> zset(3, new Time())\n```\n\n**其他方式**\n\n```\nsadd 1:follow 2\nsadd 2:fans 1\n```\n\n求关注的人也关注了他（取交集）\n\n可能认识的人（差级）\n\n[参考](https://mp.weixin.qq.com/s/I3fKeerhggozvx9FOUchpA)\n\n\n\n#### 关注\n\n实现方法\n\n```\n用redis的zset功能，score为当前时间戳，便于展示列表时倒叙排列\n```\n\n`SysUserController.java`\n\n```java\n@PostMapping(\"/{userId}/follow\")\npublic CommonResult<?> follow(@PathVariable(\"userId\") Integer userId) {\n    Integer uId = RequestHolder.getUserId();\n    followService.follow(uId, ENTITY_TYPE_USER, userId);\n\n    // ...省略触发关注事件\n\n    return CommonResult.success();\n}\n```\n\n`WtFollowServiceImpl.java`\n\n```java\npublic void follow(Integer userId, int entityType, int entityId) {\n    redisTemplate.execute(new SessionCallback() {\n        @Override\n        public Object execute(RedisOperations operations) throws DataAccessException {\n            String followeeKey = RedisKeyUtil.getFolloweeKey(userId, entityType);\n            String followerKey = RedisKeyUtil.getFollowerKey(entityType, entityId);\n\n            operations.multi();\n\n            operations.opsForZSet().add(followeeKey, entityId, System.currentTimeMillis());\n            operations.opsForZSet().add(followerKey, userId, System.currentTimeMillis());\n\n            return operations.exec();\n        }\n    });\n}\n```\n\n#### 取关\n\n`SysUserController.java`\n\n```java\n@DeleteMapping(\"/{userId}/unfollow\")\npublic CommonResult<?>  unFollow(@PathVariable(\"userId\") Integer userId) {\n    Integer uId = RequestHolder.getUserId();\n    followService.unfollow(uId, ENTITY_TYPE_USER, userId);\n    return CommonResult.success();\n}\n```\n\n`WtFollowServiceImpl.java`\n\n```java\n@Override\npublic void unfollow(Integer userId, int entityType, int entityId) {\n    redisTemplate.execute(new SessionCallback() {\n        @Override\n        public Object execute(RedisOperations operations) throws DataAccessException {\n            String followeeKey = RedisKeyUtil.getFolloweeKey(userId, entityType);\n            String followerKey = RedisKeyUtil.getFollowerKey(entityType, entityId);\n\n            operations.multi();\n\n            operations.opsForZSet().remove(followeeKey, entityId);\n            operations.opsForZSet().remove(followerKey, userId);\n\n            return operations.exec();\n        }\n    });\n}\n```\n\n#### 关注列表\n\n```java\n@Override\npublic List<Integer> findFollowIds(int entityType, Integer userId, int offset, Integer limit) {\n    List<Integer> followIds = new ArrayList<>();\n    String followerKey = RedisKeyUtil.getFolloweeKey(userId, entityType);\n    Set<Integer> ids = redisTemplate.opsForZSet().reverseRange(followerKey, offset, offset + limit - 1);\n    if(ids != null) {\n      \tfollowIds = new ArrayList<>(ids);\n    }\n  return followIds;\n}\n```\n\n#### 粉丝列表\n\n```java\n@Override\npublic List<Integer> findFollowerIds(int entityType, int entityId, int offset, int limit) {\n    List<Integer> followerIds = new ArrayList<>();\n    String followerKey = RedisKeyUtil.getFollowerKey(entityType, entityId);\n    Set<Integer> ids = redisTemplate.opsForZSet().reverseRange(followerKey, offset, offset + limit - 1);\n    if(ids != null) {\n      \tfollowerIds = new ArrayList<>(ids);\n    }\n    return followerIds;\n}\n```\n\n\n\n\n\n## 竞赛模块\n\n### 热门竞赛排行 TODO:[如何设计一个排行榜](https://www.yuque.com/snailclimb/mf2z3k/hbsnl8) 密码cnk4\n\n#### 方式1\n\n问题：需要查询全部帖子更新分数\n\n优化：\n\n-   只更新查询前一小时更新的帖子\n\n```java\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.data.redis.core.RedisTemplate;\nimport org.springframework.scheduling.annotation.Scheduled;\nimport org.springframework.stereotype.Service;\n\nimport java.util.Set;\n\n@Service\npublic class HotPostService {\n    private static final String HOT_POSTS_KEY = \"hot_posts\";\n\n    @Autowired\n    private RedisTemplate<String, String> redisTemplate;\n\n    public void increasePostScore(String postId, int score) {\n        redisTemplate.opsForZSet().incrementScore(HOT_POSTS_KEY, postId, score);\n    }\n\n    public void decreasePostScore(String postId, int score) {\n        redisTemplate.opsForZSet().incrementScore(HOT_POSTS_KEY, postId, -score);\n    }\n\n    public Set<String> getHotPosts(int count) {\n        return redisTemplate.opsForZSet().reverseRange(HOT_POSTS_KEY, 0, count - 1);\n    }\n\n    @Scheduled(cron = \"0 0 * * * *\") // 每小时执行一次\n    public void updatePostScores() {\n        // 获取所有帖子的数据，例如从数据库或缓存中获取\n        List<Post> posts = getAllPosts();\n\n        // 遍历帖子列表，计算热度分数并更新到 Redis\n        for (Post post : posts) {\n            int score = calculatePostScore(post); // 根据业务规则计算热度分数\n            redisTemplate.opsForZSet().add(HOT_POSTS_KEY, post.getId(), score);\n        }\n    }\n\n    // 其他方法...\n}\n\n```\n\n\n\n#### 方式2 \n\n```\nscore = log(精华分 + 评论数*1- + 点赞数*2 + 收藏数*2) + （发布时间 - 牛科纪元）\n实现思路：\n\t修改帖子时，通过kafka将id存到redis中\n\t用set去存有修改的帖子id，用定时器定时计算set中修改过的的帖子分数\n\t帖子的score为帖子表的一个字段，查询时根据权重倒叙\n```\n\n[仿牛客网视频](https://www.nowcoder.com/study/live/246/7/16)\n\n[牛客网实现](https://juejin.cn/post/7121927069876879391)\n\n\n\n#### 方式3（主要）\n\n思路\n\n```\n对于整个排行榜, 我们用 zset 保存排行榜数据, key 为排行榜信息, member 为帖子id, score 存储帖子积分\n```\n\n如何把小时、天、周、月的数据，实时计算?\n\n```\n截取时间戳将去变换为小时的时间戳。以小时为单位，即每个小时为一个zset\n- 近24小时，就合并24个zset\n- 近7天，就合并24*7zset\n- 近30天，就合并24*30个zset\n```\n\n如何实现以每个小时为一个zset ?如何把时间切割为小时?\n\n```\n先把当前的时间转换为为毫秒的时间戳，然后除以一个小时，即当前时间T/1000*60*60=小时key，然后用这个小时序号作为zset的key。\n例如: 2020-01-12 15:30:00 = 1578814200000毫秒转换小时\n即 key = 1578814200000/1000*60*60 = 438560\n```\n\n何时更新？\n\n```\n1. 帖子分数有变化，如点赞、收藏、评论时，通过kafka异步计算\n2. 定时刷新。虽然我们将排行榜数据存入zset中了, 但这个只是提高了我们的访问效率, 并不能完全保证数据的准确性. 可能会因为各种原因(并发, 网络异常)导致缓存数据不准确, 因此需要定时刷新缓存数据\n```\n\n如何更新？\n\n```\n每次更新最近一个小时的zset，遍历通过id去计算帖子分数然后回存\n日榜则合并最近24个zset，有相同的key，则取最大值\n```\n\n如何处理缓存击穿？\n\n```\n缓存肯定是要设置过期时间的, 过期时间肯定是在缓存数据不经常访问的时候. 那如果缓存过期后用户访问排行榜, 这个时候就需要从数据库中查询相关数据, 重新计算排行榜前n位(没必要全部重算), 显然重算排行榜是一个比较费事费力的操作.\n\n但是假如这个时候是大量用户并发访问, 然后查询排行榜缓存, 发现没有数据, 于是都去查询数据库重算. 这个时候数据库压力就会很大, 很容易挂掉. 即 缓存击穿.\n\n解决方式\n- 不设置过期时间, 不过期就不会失效.\n- 加锁, 重新加载缓存的时候加锁, 防止所有的请求都去数据库查询重算.（双重锁检测）\n```\n\n双重锁检测是什么？\n\n```\n虽然叫做双重锁检测，但实际上并不是指使用了两个锁。双重锁检测是指在加锁前后都进行了检测，以确保只有一个实例被创建。\n即先检测redis排行缓存是否存在？如果不存在则加锁，再检测redis排行缓存是否存在，如果还是没有才重新算榜\n避免了不必要的同步开销，提高了性能和效率\n```\n\n\n\n\n\n##### 实现\n\n相应的key值\n\n```java\nString GAME_RANK_HOUR_KEY = \"wt:game:rank:hour:\";\t\t// 小时\nString GAME_RANK_DAY_KEY = \"wt:game:rank:day\";\t\t\t// 天\nString GAME_RANK_WEEK_KEY = \"wt:game:rank:week\";\t\t// 周\nString GAME_RANK_MONTH_KEY = \"wt:game:rank:month\"; \t// 月\n```\n\n计算分数`WtGameServiceImpl.java`\n\n```java\n// 计算帖子分数\npublic double calculateGameScore(Integer id) {\n    WtGame game = gameDao.selectById(id);\n    if(game == null) {\n        log.error(\"竞赛不存在: id = \" + id);\n        return 0;\n    }\n    // TODO: 是否置顶\n    boolean wonderful = false;\n    // TODO: 收藏数\n    int commentCnt = 0;\n    // TODO: 点赞数\n    int likeCnt = 0;\n    // 计算权重\n    double w = (wonderful ? 75 : 0) + commentCnt * 10 + likeCnt * 2;\n    // 分数 = 帖子权重 + 距离天数\n    double score = Math.log10(Math.max(w, 1))\n      + (game.getCreateTime().getTime() - epoch.getTime()) / (1000 * 3600 * 24);\n\n    return score;\n}\n```\n\n评论、收藏等通过kafka异步更新帖子分数\n\n```java\n@Component\npublic class EventConsumer implements WeTeamConstant {\n  \n    @KafkaListener(topics = {TOPIC_FOLLOW, TOPIC_COMMENT, TOPIC_LIKE})\n    public void handleMessage(ConsumerRecord record) {\n      \t// ...\n      \tif(record.topic().equals(TOPIC_COMMENT)) {\n            // 计算帖子分数\n            double score = gameService.calculateGameScore(event.getEntityId());\n            // 计算当前的小时key\n            long hour = System.currentTimeMillis() / (1000 * 60 * 60);\n            String key = GAME_RANK_HOUR_KEY + hour;\n            redisTemplate.opsForZSet().add(key, event.getEntityId(), score);\n        }\n    }\n}\n```\n\n定时刷新\n\n```java\n@Component\npublic class ScheduledTasks implements WeTeamConstant {\n    private static Logger log = LoggerFactory.getLogger(DefaultExceptionHandler.class);\n\n    @Autowired\n    private RedisTemplate redisTemplate;\n    @Autowired\n    private WtGameService gameService;\n\n    private static final SimpleDateFormat dateFormat = new SimpleDateFormat(\"HH:mm:ss\");\n\n    @Scheduled(cron = \"0 0 * * * *\") // 每小时的整点触发\n    public void refreshRank() {\n        this.refreshHour();\n        this.refreshDay();\n        this.refreshWeek();\n        this.refreshMonth();\n    }\n\n    // 刷新小时榜\n    public void refreshHour() {\n        // 计算当前的小时key\n        long hour = System.currentTimeMillis() / (1000 * 60 * 60);\n        String key = GAME_RANK_HOUR_KEY + hour;\n\n        Set<Integer> members = redisTemplate.opsForSet().members(key);\n        for (Integer member : members) {\n            double score = gameService.calculateGameScore(member);\n            redisTemplate.opsForZSet().add(key, member, score);\n        }\n    }\n\n    // 刷新日榜\n    public void refreshDay() {\n        long hour = System.currentTimeMillis() / (1000 * 60 * 60);\n        List<String> otherKeys = new ArrayList<>();\n        // 算出近24小时内的key\n        for (int i = 1; i < 23; i++) {\n            String key = GAME_RANK_HOUR_KEY + (hour - i);\n            otherKeys.add(key);\n        }\n\n        // 把当前的时间key，并且把后推23个小时，共计近24小时，求出并集存入Constants.DAY_KEY中。\n        // 这里根据业务可以更改，如果是查询当天的，可以获取日期+0点组成时间戳，这样的话调用逻辑也有所更改\n        // 求并集, 相同key取最大值\n        redisTemplate.opsForZSet().unionAndStore(GAME_RANK_HOUR_KEY + hour, otherKeys, GAME_RANK_DAY_KEY, RedisZSetCommands.Aggregate.MAX);\n\n        // 设置当天的key 40天过期，不然历史数据浪费内存\n        for (int i = 0; i < 24; i++) {\n            String key = GAME_RANK_HOUR_KEY + (hour - i);\n            redisTemplate.expire(key, 40, TimeUnit.DAYS);\n        }\n    }\n\n    // 刷新周榜\n    public void refreshWeek() {\n        long hour = System.currentTimeMillis() / (1000 * 60 * 60);\n        List<String> otherKeys = new ArrayList<>();\n        //算出近7天内的key\n        for (int i = 1; i < 24 * 7 - 1; i++) {\n            String key = GAME_RANK_HOUR_KEY + (hour - i);\n            otherKeys.add(key);\n        }\n        //把当前的时间key，并且把后推24*7-1个小时，共计近24*7小时，求出并集存入Constants.WEEK_KEY中\n        redisTemplate.opsForZSet().unionAndStore(GAME_RANK_HOUR_KEY + hour, otherKeys, GAME_RANK_WEEK_KEY, RedisZSetCommands.Aggregate.MAX);\n\n        log.info(\"周刷新完成..........\");\n    }\n\n    // 刷新月榜\n    public void refreshMonth() {\n        long hour = System.currentTimeMillis() / (1000 * 60 * 60);\n        List<String> otherKeys = new ArrayList<>();\n        // 算出近30天内的key\n        for (int i = 1; i < 24 * 30 - 1; i++) {\n            String key = GAME_RANK_HOUR_KEY + (hour - i);\n            otherKeys.add(key);\n        }\n        // 把当前的时间key，并且把后推24*30个小时，共计近24*30小时，求出并集存入Constants.MONTH_KEY中\n        redisTemplate.opsForZSet().unionAndStore(GAME_RANK_HOUR_KEY + hour, otherKeys, GAME_RANK_MONTH_KEY, RedisZSetCommands.Aggregate.MAX);\n        log.info(\"月刷新完成..........\");\n    }\n}\n```\n\n[Redis zset 实现排行榜, 并定时增量刷新缓存, 以及防止缓存击穿](https://blog.csdn.net/Wu_Shang001/article/details/111601003)\n\n[zset实战之微博热度排行榜](https://www.xk857.com/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/redis%E4%B8%93%E6%A0%8F/%E9%AB%98%E9%98%B6%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/zset%E5%AE%9E%E6%88%98%E4%B9%8B%E5%BE%AE%E5%8D%9A%E7%83%AD%E5%BA%A6%E6%8E%92%E8%A1%8C%E6%A6%9C.html#%E6%AD%A5%E9%AA%A41-%E5%85%88%E5%88%9D%E5%A7%8B%E5%8C%961%E4%B8%AA%E6%9C%88%E7%9A%84%E5%8E%86%E5%8F%B2%E6%95%B0%E6%8D%AE)\n\n\n\n## 消息通知模块\n\nkafka的作用\n\n```\n解耦、削峰、异步\n```\n\n消息事件实体，利用**链式编程**，允许在单个语句中连续调用多个方法。\n\n```java\n/**\n * kafka消息事件\n */\npublic class Event {\n\n    // 主题\n    private String topic;\n\n    // 触发事件的人\n    private int userId;\n\n    // 实体类型\n    private int entityType;\n\n    // 实体id\n    private int entityId;\n\n    // 实体所属用户id\n    private int entityUserId;\n\n    private Map<String, Object> data = new HashMap<>();\n\n    public String getTopic() {\n        return topic;\n    }\n\n    public Event setTopic(String topic) {\n        this.topic = topic;\n        return this;\n    }\n\n    public int getUserId() {\n        return userId;\n    }\n\n    public Event setUserId(int userId) {\n        this.userId = userId;\n        return this;\n    }\n\n    public int getEntityType() {\n        return entityType;\n    }\n\n    public Event setEntityType(int entityType) {\n        this.entityType = entityType;\n        return this;\n    }\n\n    public int getEntityId() {\n        return entityId;\n    }\n\n    public Event setEntityId(int entityId) {\n        this.entityId = entityId;\n        return this;\n    }\n\n    public int getEntityUserId() {\n        return entityUserId;\n    }\n\n    public Event setEntityUserId(int entityUserId) {\n        this.entityUserId = entityUserId;\n        return this;\n    }\n\n    public Map<String, Object> getData() {\n        return data;\n    }\n\n    public Event setData(String key, Object value) {\n        this.data.put(key, value);\n        return this;\n    }\n}\n\n\n```\n\n生产者\n\n```java\n/**\n * kafka生产者\n */\n@Component\npublic class EventProducer {\n\n    @Autowired\n    private KafkaTemplate kafkaTemplate;\n\n    // 处理事件\n    public void fireEvent(Event event) {\n        // 将事件发布到指定主题\n        kafkaTemplate.send(event.getTopic(), JSONObject.toJSONString(event));\n    }\n}\n```\n\n消费者\n\n```java\n/**\n * kafka消费者\n */\n@Component\npublic class EventConsumer implements WeTeamConstant {\n    @Autowired\n    WtMessageDao messageDao;\n    @Autowired\n    WtGameService gameService;\n    @Autowired\n    private RedisTemplate redisTemplate;\n\n    private static final Logger logger = LoggerFactory.getLogger(EventConsumer.class);\n\n    /**\n     * 监听关注事件，发送通知\n     * @param record\n     */\n    @KafkaListener(topics = {TOPIC_FOLLOW, TOPIC_COMMENT, TOPIC_LIKE})\n    public void handleMessage(ConsumerRecord record) {\n        if (record == null || record.value() == null) {\n            logger.error(\"消息内容为空！\");\n            return;\n        }\n\n        Event event = JSONObject.parseObject(record.value().toString(), Event.class);\n        if (event == null) {\n            logger.error(\"消息格式错误！\");\n            return;\n        }\n\n        if(record.topic().equals(TOPIC_COMMENT)) {\n            // 计算帖子分数\n            double score = gameService.calculateGameScore(event.getEntityId());\n            // 计算当前的小时key\n            long hour = System.currentTimeMillis() / (1000 * 60 * 60);\n            String key = GAME_RANK_HOUR_KEY + hour;\n            redisTemplate.opsForZSet().add(key, event.getEntityId(), score);\n        }\n\n        // 发送站内通知\n        WtMessage message = new WtMessage();\n        message.setFromId(SYSTEM_USER_ID);\n        message.setToId(event.getEntityUserId());\n        message.setConversationId(event.getTopic());\n        message.setCreateTime(new Date());\n\n        Map<String, Object> content = new HashMap<>();\n        content.put(\"userId\", event.getUserId());\n        content.put(\"entityType\", event.getEntityType());\n        content.put(\"entityId\", event.getEntityId());\n\n        if (!event.getData().isEmpty()) {\n            for (Map.Entry<String, Object> entry : event.getData().entrySet()) {\n                content.put(entry.getKey(), entry.getValue());\n            }\n        }\n\n        message.setContent(JSONObject.toJSONString(content));\n        // 防止html字符转译\n        // message.setContent(HtmlUtils.htmlEscape(message.getContent()));\n        message.setContent(message.getContent());\n        messageDao.insert(message);\n    }\n}\n```\n\n使用（以关注为例）\n\n```java\n@PostMapping(\"/{userId}/follow\")\npublic CommonResult<?> follow(@PathVariable(\"userId\") Integer userId) {\n    Integer uId = RequestHolder.getUserId();\n    followService.follow(uId, ENTITY_TYPE_USER, userId);\n\n    Event event = new Event()\n        .setTopic(TOPIC_FOLLOW)\n        .setUserId(uId)\n        .setEntityType(ENTITY_TYPE_USER)\n        .setEntityId(userId)\n        .setEntityUserId(userId);\n    eventProducer.fireEvent(event);\n\n    return CommonResult.success();\n}\n```\n\n","timestamp":1695293386005},{"name":"01-场景题.md","path":"005-项目/01-场景题.md","content":"海量日志数据，访问最频繁的IP地址怎么找出来？只给你一个内存有限的机器 \n\n```\n\n```\n\n","timestamp":1695293386005},{"name":"02-接口幂等性问题.md","path":"005-项目/02-接口幂等性问题.md","content":"参考\n\n-   [面试：如何保证接口的幂等性？常见的实现方案有哪些？](https://cloud.tencent.com/developer/article/1809887)\n-   [如何保证接口的幂等性？](https://juejin.cn/post/7001667579991293989)\n-   [高并发下如何保证接口的幂等性？](https://segmentfault.com/a/1190000039737646)\n\n\n\n## 什么是幂等？\n\n```\n幂等表示一次和多次请求某一个资源应该具有同样的结果\n```\n\n## 幂等性问题\n\n```\n（1）如何防止接口的重复无效请求。\n（2）每次请求的结果一样\n```\n\n## 为什么会产生接口幂等性问题\n\n```\n对于业务中需要考虑幂等性的地方一般都是接口的重复请求，重复请求是指同一个请求因为某些原因被多次提交。导致这种情况的发生有以下几种常见的场景：\n\n（1）前端重复提交：\n\t\t用户在提交表单的时候，可能会因网络波动没有及时做出提交成功响应，致使用户认为没有成功提交，然后一直点提交按钮，这时就会发生重复提交表单请求。\n\t\t\n（2）接口超时重试：\n\t\t第三方调用接口时候，为了超时等异常情况造成的请求失败，都会添加重试机制，导致一个请求提交多次。\n\t\t\n（3）消息重复消费：\n\t\t当使用 MQ 消息中间件时候，如果发生消息中间件出现错误未及时提交消费信息，导致发生重复消费。\n```\n\n### 防重设计 vs 幂等设计？\n\n```\n防重设计 和 幂等设计，其实是有区别的。\n防重设计主要为了避免产生重复数据，对接口返回没有太多要求。\n而幂等设计除了避免产生重复数据之外，还要求每次请求都返回一样的结果。\n```\n\n\n\n## 幂等性解决方案\n\n```\n前端\n（1）前端控制\n（2）token机制\n\n数据库\n（1）唯一索引\n（2）悲观锁 \n（3）乐观锁\n（4）状态机\n\n其他\n（1）分布式锁\n```\n\n\n\n### 1 前端\n\n#### 方案一：前端控制\n\n在前端做拦截，比如按钮点击一次之后就置灰或者隐藏。但是往往前端并不可靠，还是得后端处理才更放心。\n\n#### 方案二：Token机制\n\n```\n（1）客户端请求申请获取`token`：用户进入表单页面首先调用后台接口获取 token 并存入 redis\n（2）提交表单时带上 token ，后端先删除 redis 中的 token，删除成功则保存表单数据，失败则提示用户重复提交。\n```\n\n<img src=\"https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/03/14/23523816788091581678809158980IWA1pN-cc03edc216354a1b8b9923f47b51fc80~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp\" alt=\"img\" style=\"zoom: 67%;\" />\n\n为什么不先判断 redis 是否存在这个 token 再删除？\n\n```\n是因为要保证操作的原子性，极端情况下，第一个请求查询到 redis 中存在这个 token，还没来得及删除，第二个请求进来，也查询到 redis 中存在这个 token，那么还是会造成重复提交的问题。\n```\n\n存在的问题\n\n```\ntoken 机制需要先请求获取 token 的接口，在有些情况下很明显并不合适。我们大部分请求都是要落到数据库的，所以我们可以从数据库着手。\n```\n\n能不能改为“判断token是否存在来判断是不是第一次请求”？\n\n```\nhttps://segmentfault.com/a/1190000039737646\n```\n\n\n\n### 2 数据库\n\n#### **方案一、唯一索引**\n\n这种方案就比较好理解了，使用唯一索引可以避免脏数据的添加，当插入重复数据时数据库会抛异常，保证了数据的唯一性。唯一索引可以支持插入、更新、删除业务操作。\n\n```\n交易请求过来，我会先根据请求的唯一流水号 bizSeq字段，先select一下数据库的流水表\n（1）如果数据已经存在，就拦截是重复请求，直接返回成功；\n（2）如果数据不存在，就执行insert插入，如果insert成功，则直接返回成功，如果insert产生主键冲突异常，则捕获异常，接着直接返回成功。\n\n如果重复请求的概率比较低的话，我们可以直接插入请求，利用主键/唯一索引冲突，去判断是重复请求。\n```\n\n\n\n#### **方案二、悲观锁**\n\n这里所说的悲观锁是基于数据库层面的，在获取数据时进行加锁，当同时有多个重复请求时，其他请求都无法进行操作。悲观锁只适用于更新操作。\n\n```mysql\n// 例如\nselect name from t_goods where id=1 for update;\n\n注意： id 字段一定要是主键或者唯一索引，不然会锁住整张表，这是会死人的。悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，根据实际情况选用。\n```\n\n问： 悲观锁怎么能防止重复数据提交，多个请求只有一个请求能进行操作，其他请求在等待，那么这个请求结束后，其他请求不还是进行了更新操作吗？\n\n```\nbegin transaction\n1.select * from order_info where id = \"20201020\" for update 加record lock\n2.Java代码判断status == \'初始\' 执行3，否则返回\n3.update order_info set status = \'成功\' where id = \'20201020\'并且发货\ncommit\n```\n\n[参考：**重复支付问题如何解决（悲观锁和乐观锁）**](https://blog.51cto.com/u_15127700/4540810)\n\n-   https://mp.weixin.qq.com/s/UN0T80ygxnyCgnmrkpwtPg\n\n**问题**\n\n-   不适合高并发\n-   只适用于更新操作\n\n#### **方案三、乐观锁**\n\n可以通过**版本号**实现，为表增加一个 version 字段，当数据需要更新时，先去数据库里获取此时的version版本号。\n\n```mysql\nselect version from t_goods where id=1\n复制代码\n```\n\n更新数据时首先要对比版本号，如果不相等说明已经有其他的请求去更新数据了，提示更新失败。\n\n```mysql\nupdate t_goods set count=count+1,version=version+1 where version=#{version}\n```\n\n问题\n\n```\n只适用于更新\n```\n\n\n\n\n\n#### 方案四 状态机\n\n其实也是乐观锁的原理。这种方法适合在有状态流转的情况下，比如订单的创建和付款，订单的创建肯定是在付款之前，这时我们可以通过在设计状态字段时，使用 int 类型，并且通过值类型的大小来实现幂等性。\n\n```mysql\nupdate t_goods set status=#{status} where id=1 and status<#{status}\n```\n\n[更具体参考](https://segmentfault.com/a/1190000039737646)\n\n为什么版本号建议自增的呢？\n\n```\n因为乐观锁存在ABA的问题，如果version版本一直是自增的就不会出现ABA的情况啦。\n```\n\n\n\n\n\n\n\n###  3 分布式锁\n\n<img src=\"https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/09/07/14161016940673701694067370830r5acTU-640.png\" alt=\"图片\" style=\"zoom:50%;\" />\n\n有时候我们的业务不仅仅是操作数据库，也可能是发送短信、消息等等，那数据库层面的锁就不适合了。这种情况下就要考虑代码层面的锁了，而 java 的自带的锁在分布式集群部署的场景下并不适用，那么就可以采用分布式锁来实现（Redis 或 Zookeeper）。\n\n拿 Redis 分布式锁举例，比如一个订单发起支付请求，支付系统会去 Redis 缓存中查询是否存在该订单号的 Key，如果不存在，则以 Key 为订单号向 Redis 插入。查询订单是否已经支付，如果没有则进行支付，支付完成后删除该订单号的Key。通过 Redis 做到了分布式锁，只有这次订单支付请求完成，下次请求才能进来。当然这里需要设置一个Key 的过期时间，在发生异常的时候还要注意删除 Redis 的 Key。\n\nhttps://juejin.cn/post/7127667756693979173\n\n```\nRedisson提供了一套功能丰富的分布式对象和服务，包括分布式锁、分布式集合、分布式队列等，可以更方便地实现分布式锁的功能。\n```\n\n\n\n参考\n\n-   [高并发下如何保证接口的幂等性？](https://segmentfault.com/a/1190000039737646)\n-   [田螺：聊聊幂等设计](https://mp.weixin.qq.com/s?__biz=Mzg3NzU5NTIwNg==&mid=2247497427&idx=1&sn=2ed160c9917ad989eee1ac60d6122855&chksm=cf2229faf855a0ecf5eb34c7335acdf6420426490ee99fc2b602d54ff4ffcecfdab24eeab0a3&token=2044040586&lang=zh_CN#rd)\n\n","timestamp":1695293386005},{"name":"03-简历投递.md","path":"005-项目/03-简历投递.md","content":"\n\n```\nlinkuan_npu@mail.nwpu.edu.cn\n```\n\n\n\n```\n商用发动机健康管理平台\n\n项目描述：\n项目是与中国航发商发合作项目，旨在实时监控航空发动机试验，并能收集试验数据进行处理、分析及诊断，协助试验推进，实现数据分析全流程。开发了一个包含试验管理、状态监视、异常自动检测、故障诊断和数据可视化等功能的平台。\n\n技术栈：\nSpringBoot + MyBatis + MySQL + Redis + Kafka; Python + Celery + HBase + MongoDB;\n\n主要工作：\n（1）参与系统设计，设计了数据源、数据集、实体模型、实体等，解决多类型结构数据存储、衍生和溯源问题。\n（2）设计工作流引擎基础架构，包含流程构建器（任务节点、逻辑类节点、事件类节点等）、解析器、执行器、表达式解析器、监视器等。使用线程池、Kafka、Celery实现了一个分布式工作流执行引擎。\n（3）负责算法模型的设计，实现了算法模型管理、分布式单算法任务管理；并参与部分算法模型的开发，包括指定维度排序、缺失值处理、台阶计算等算法。\n（4）通过MinIO实现非结构化数据管理，并通过文件分片上传、断点续传、文件秒传等优化大文件上传过程；通过分布式锁解决文件夹重命名、复制、删除问题\n（5）使用Kafka构建异步消息系统，实现发送通知、异常告警、任务状态同步和工作流任务推进。\n\n项目优化：\n（1）通过将业务流程从串行改为并行处理，提高接口响应速度，将耗时减少超过一半。\n（2）通过优化索引、SQL语句等优化数据库，如合理增删索引、字段类型选择，排查索引失效问题、limit大分页问题。\n```\n\n\n\n```\nweTeam校园\n\n项目描述：\n项目是一个校园活动交流平台，旨在解决疫情期间活动查找难、宣传难及组队难等问题。实现了注册登录、活动管理、组队管理、点赞评论、消息提醒和网站数据统计等功能。项目获中国高校计算机大赛西北赛区一等奖、全国三等奖，成功申报国家级创新创业项目，并以该项目作为创业项目基石继续发展。线上地址:微信小程序\"团团小文体\"\n\n技术栈：\nSpringBoot + MyBatis + MySQL + Redis + Kafka\n\n工作内容： \n（1）实现了活动管理、组队管理、评论管理等模块。\n（2）使用JWT+Redis实现登录功能，解决分布式Session问题，采用双令牌认证的方式实现用户无感知登录刷新。\n（3）使用Redis实现热门榜单、点赞关注收藏等，并解决数据库与缓存双写一致性问题、缓存穿透、缓存雪崩、缓存击穿问题。\n（4）使用Kafka构建异步消息系统，发送评论、点赞、关注和活动更新等通知，起到对系统削峰、解耦和异步调用的作用。\n（5）使用AOP记录系统日志、权限检查，对项目进行解耦，增加重用性和和可维护性。\n\n项目收获：\n（1）以竞赛为驱动，短期内学习SpringBoot、MyBatis、Redis等技术，完成一个完整的前后端分离的项目。通过项目了解Redis、Kafka在项目中的具体应用。\n（2）学习了Docker基本用法，通过容器来部署项目前后端。\n```\n\n\n\n```\n“深度扶贫地区青春行”社会实践 2019.08\n\n（1）实践以“异地扶贫”为主旨，走进国家级贫困县广西融水，深入了解异地扶贫搬迁工作的现状。实践以实地采 访的形式开展，并形成调研报告，最终获“校级一等奖”优秀实践队表彰。 \n（2）前期负责与当地相关负责人沟通协调，参与日程计划安排。实践过程中参与留守儿童的趣味暑期课堂活动及深 入基层进行实地采访交流。\n```\n\n\n\n```\n2022年学业二等奖学金\n2021年学业二等奖学金\n2020年国家励志奖学金\n2020年西工大校一等奖学金\n2020年中国高校计算机大赛全国三等奖（西北赛区一等奖）\n2020年微信小程序应用开发赛二等奖\n2020年西工大小程序设计大赛一等奖                                       \n2020年美国大学生数学建模大赛三等奖\n2019年全国高校计算机大赛全国三等奖\n2018年西工大五一数模校赛三等奖\n\n\n2022年学业二等奖学金\n2021年学业二等奖学金\n2020年国家励志奖学金\n2020年西工大校一等奖学金\n2020年中国高校计算机大赛全国三等奖（西北赛区一等奖）\n2020年微信小程序应用开发赛二等奖\n2020年西工大小程序设计大赛一等奖                                       \n2020年美国大学生数学建模大赛三等奖\n2019年全国高校计算机大赛全国三等奖\n2019年社会实践获校级一等奖\n2018年西工大五一数模校赛三等奖\n\n2020.12  获国家励志奖学金                         \n2020.12  获西工大校优秀奖学金\n2020.08  获中国高校计算机大赛西北赛区一等奖       \n2020.07  获微信小程序应用开发赛校赛二等奖          \n2020.05  获西工大小程序设计大赛校赛一等奖         \n2020.01  获美国大学生数学建模大赛国际三等奖\n2019.08 参加“深度扶贫地区青春行”社会实践获“校级一等奖”优秀实践队表彰\n2019.05  获全国高校计算机大赛全国三等奖           \n2018.05  获西工大五一数模校赛三等奖\n```\n\n\n\n```\n（1）参与多个前后端分离项目的开发和维护，熟悉Angular + springBoot的开发流程，能够独立完成前后端项目的开发。\n（2）具有较强的执行力、分析解决问题的能力，对编程充满热爱，自学过多种编程语言并开发项目，如Golang、python、vue、angular等。\n```\n\n\n\n\n\n\n\n","timestamp":1695293386005}]