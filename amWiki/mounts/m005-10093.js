if(typeof AWPageMounts=='undefined'){AWPageMounts={}};AWPageMounts['m005']=[{"name":"00-系统功能.md","path":"005-项目/001-民用航空发动机健康管理系统/00-系统功能.md","content":"## 基本概念\n\n### 数据源\n\n```\n是什么？\n数据的来源，mysql、hbase、mongodb、minio桶\n\n为什么？\n数据采集时，和数据处理时需要从指定数据源中获取数据进行分析、存储或其他操作。\n```\n\n### 数据集\n\n```\n数据集就是实体的集合，表示一类实体\n```\n\n### 实体模型\n\n```\n定义了数据的各位维度的信息。比如一张表的结构就是一个实体，我们需要定义它的列名，类型等\n```\n\n### 实体\n\n```\n实体就是实体模型的实例化，就跟java中类和对象的关系一样\n```\n\n## 工作流引擎\n\n### 节点\n\n#### 任务节点\n\n```\n设置任务的标题、执行类型、算法分组、算法名称、处理节点\n需要配置算法模型中定义的参数配置\n```\n\n#### 数据对象节点\n\n```\n任务节点的输入、输出配置\n类型：实体、数据集、minio_file\n```\n\n#### 事件类节点\n\n```\n（1）定时事件：\n（2）周期事件：\n```\n\n#### 逻辑类节点\n\n```\n（1）IF节点\n（2）分支节点\n（3）合并节点\n```\n\n#### 连线&线上条件\n\n```\n\n```\n\n### 节点状态池\n\n```\n节点状态池包含了整个工作流中所有节点信息 & 一些api，包括节点名称、表示符、配置，以及它的执行状态等。\n解析器解析json时会向状态池中初始化各节点的信息以及初始状态。\n\n底层通过HashMap来实现，后来用concurrentMap优化了一下，防止在并发过程中出现问题\n```\n\n### 解析器\n\n```\n前端绘制完后返回一个json数据，解析器的作用就是去解析这个json文件，根据不同类型的节点，调用不同的解析器来解析并创建对应的类对象，并初始化到状态池中。\n\n解析器采用了「工厂模式」+「策略模式」进行了优化，通过节点的type属性，来找到对应的解析器\n```\n\n### 监视器\n\n```\n在流程启动时会去开启，通过mqtt来实现，去监听指定的话题，包含三部分：\n（1）控制台指令：在前端界面点击按钮传输的指令。比如暂停、恢复、停止\n（2）节点状态更新：celery worker执行完某一个算法后，会发送状态更新指令，监视器接收到后去更新对应节点的状态。\n（3）状态上报：前端是要实时监控引擎的执行过程，节点状态更新、引擎发送异常等需要往前端推送状态。\n```\n\n\n\n## 设备管理\n\n```\n分类：零部件，整机/核心机，成熟机型\n```\n\n## 实验管理\n\n```\n零部件实验：包含多个起停实验\n整机/核心机实验：包含多个起停实验\n成熟机型运行记录\n```\n\n\n\n## 数据管理\n\n问题：数据模型管理怎么添加？？\n\n### 内容\n\n```\n数据模型管理\n实验数据管理：零部件实验数据、整机/核心机实验数据、整机实验数据\n业务数据管理：标签管理、标签匹配规则管理、故障管理、异常告警管理\n```\n\n### 数据模型管理\n\n```\n数据模型，就是对数据各个维度定义，比如类型，长度等，数据库表中各个字段的定义\n\n数据导入过程中，可以按照数据模型进行提取并存入数据库\n多次实验时，可以使用上一次实验定义的数据模型，也可以继承上一次数据模型并进行修改，定义一个新的数据模型。\n```\n\n### 结构化时序试验数据管理\n\n功能描述\n\n```\n结构化时序试验数据存储功能，支持将结构化时序试验数据存储至 指定数据集数据表当中\n支持txt、 csv、mat、xls、xlsx 常用数据文本格式数据\n\n接入方式包含「离线文件导入」、「MQTT实时数据流接入」\n```\n\n离线文件导入\n\n```\n其中离线文件导入支持将离线文件导入至系统，文件格式为 CSV、TXT、PDF， 其中 CSV 和 TXT 文件都为 UTF-8 编码，文件内容均由表头和数据 组成。\n```\n\nMQTT实时数据流接入\n\n```\n结构化时序数据来源于「数采系统以」及「快速存取记录器」 QAR 和 ACARS。\n数采系统包括稳态（低频）和动态（高频）数采系统，支持接入方式为离线文件导入和 MQTT 实时数据流接入的方式。\n\n稳态数采系统：\n采集的数据时，使用 MQTT 实时数据流接入 的方式，\n\n动态数采系统：\n采集的数据时，需要用户先把这些数据保存为 UTF-8 编码的 CSV 格式，再采用离线文件导入的方式接入系统。\n\n快速存取记录器 QAR 和 ACARS：\n数据接入方式为离线文件导入的方式，其中 QAR 数据为 CSV 文件格式的， ACARS 数据为 TXT 文件格式的。对于 ACARS 数据，系统只提取模版匹配的数据，模版 由甲方提供。\n```\n\n什么是稳态数据？？？\n\n```\n\n```\n\n结构化时序试验数据查看功能\n\n```\n支持筛选数据维度采用表格分页形式展示试验数据；\n支持选择数据维度分别以折线图的方式展示各维度试验数据；\n支持试验数据同一参数不同测点参数的周向分布图作图功能。\n```\n\n结构化时序试验数据的导出功能\n\n```\n支持对时序试验数据进行导出，导出时可指定数据的维度以及时间段，导出格式为 CSV。\n```\n\n### 非结构化数据管理功能 minio\n\n描述\n\n```\n非结构化数据存储功能，支持将非结构化数据存储至对象存储数据库中。非结构化数据包括「试验日志数据」以及表 3 的其他文本、图片、 音频、视频文件。\n```\n\n非结构化数据上传\n\n```\n\n```\n\n非结构化数据下载\n\n```\n\n```\n\n## 业务流程管理\n\n```\n业务流程图是由任务节点和连接线构成的有 向无环图，其中任务节点类型包括数据源接入节点、数据保存入库节 点、可视化节点、算法模型节点\n```\n\n## 算法模型管理\n\n```\n算法模型就是一个个基础算法，定义了它的名称、类型、算法配置以及运行环境。\n算法开发的过程是在notebook完成的，算法模型定义完后就可以在「单算法任务」和「工作流」里使用\n\n算法配置包含输入、输出、参数\n- 输入输出包含了三类：数据集、实体、minio文件\n- 参数就是算法的形参，包含参数名、类型、默认值\n```\n\n## 状态监视功能\n\n```\n状态监视功能，支持选定指定台份启停试验，并将实时 数据接入的采集量参数和计算量展示在实时监控界面，用户可在展示 界面配置添加或删除展示数据的图表模块，通过选择数据集数据模型 中的维度参数创建生成图表模块，并以折线图的形式展示各个维度数 据，支持设置刷新频率、时间跨度和缩放，其中维度参数包括排气温 度、高低压转子振动、滑油温度、燃油流量、EGT 指示、N1 振动、 EGT 超限、滑油消耗、燃油（温度和压力）、N2 转速、总温、滑 油压力、高压涡轮叶片温度，并可以根据甲方需求进行维度参数的新 增或修改，如果传感器的采样率过高可按需对试验数据进行降采样。\n```\n\n\n\n## MINIO文件管理\n\n### 数据库设计\n\n```java\n分片上传-分片任务记录表 sys_upload_task\nid \nupload_id\t\t\t\t\t\t\t// 分片上传的uploadId，需要根据该id来生成每个分片上传的地址\nfile_identifier\t\t\t\t// 文件唯一标识（md5）\nfile_name\t\t\t\t\t\t\t// 文件名\nbucket_name\t\t\t\t\t\t// 所属桶名\nobject_key\t\t\t\t\t\t// 文件的key\ntotal_size\t\t\t\t\t\t// 文件大小（byte）\nchunk_size\t\t\t\t\t\t// 每个分片大小（byte）\nchunk_num\t\t\t\t\t\t\t// 分片数量\n```\n\n### 功能\n\n#### 文件秒传\n\n```\n上传文件时会去计算文件的md5、文件大小、分片大小，将这些信息存储到数据库，再次上传时，根据md5值就能知道文件是否上传，\n如果相同的路径下存在文件，则直接返回文件的uri；\n如果路径不同，则调用拷贝接口，拷贝成功后返回。\n```\n\n#### 分片上传\n\n```\n将大文件拆分成小文件，将小文件上传\\下载，最后再将小文件组装成大文件\n```\n\n<img src=\"https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/09/03/14144416937216841693721684124s5B5JY-20055016910643501691064350082DqOU1Q-640.png\" alt=\"图片\" style=\"zoom:50%;\" />\n\n```\n流程：\n（1）前端计算文件的md5值、文件大小、分片大小、文件名，调用文件上传接口\n（2）根据md5值查询是否上传过，\n\t\t- 如果上传完成则直接返回；【文件秒传】\n\t\t- 如果有上传过但为上传完成，则返回已经上传的分片；【断点续传的内容】\n\t\t- 如果未上传，则调用minio接口开启一个上传任务获取uploadId，将文件上传信息插入上传记录表中\n（3）根据md5去获取每个分片上传的地址【通过md5去查uploadId，根据uploadId和分片号查询上传地址】\n（4）异步将每个分片上传到指定地址\n（5）合并分片完成上传【监听进度，最后一个分片上传完就调合并接口】\n```\n\n#### 断点续传\n\n```\n指在传输过程中发生中断，或者传输失败，可以从断点处继续传输，而不需要从头开始传输整个文件\n```\n\n#### 分段下载\n\n```\n断点续传下载将需要下载的文件分成若干个分片分别下载，所有分片都下载完成后，将所有分片合并成完整的文件。\n```\n\n<img src=\"https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/04/213943169115638316911563833938akdFF-image-20220724211002451.png\" alt=\"image-20220724211002451\" style=\"zoom:50%;\" />\n\n```java\nGetObjectResponse stream = minioClient.getObject(\n  GetObjectArgs.builder()\n  .bucket(statObjectResponse.bucket())\n  .object(statObjectResponse.object())\n  .offset(startByte)\n  .length(contentLength)\n  .build()\n); \n```\n\n参考\n\n-   [minio断点下载](https://java.isture.com/arch/minio/minio-breakpoint-downloading.html#_3-%E6%96%AD%E7%82%B9%E4%B8%8B%E8%BD%BD)\n-   [springboot使用minio实现分段下载](https://www.bilibili.com/read/cv21016230/)\n\n\n\n#### 文件预览\n\n```\nopenoffice\n```\n\n#### 文件夹重命名\n\n```\n加锁-复制-删除\n```\n\n\n\n## 问题\n\n### 文件上传一半不上传了，怎么清理碎片分片？\n\n```\n（1）定时任务：可以考虑在sys_upload_task表中新加一个status字段，表示是否合并分片，默认为false，merge请求结束后变更为true，通过一个定时任务定期清理为status为false的记录。\n（2）另外MinIO自身对于临时上传的分片，会实施定时清理\n```\n\n### 如何知道哪些分片已经上传成功？\n\n```\n（1）方式1: 通过redis记录，md5:uploadId  -> 分片号\n（2）方式2：直接调minio接口，获取已经上传的分片\n```\n\n### 多个用户上传同一个文件怎么处理？\n\n```\n（1）文件上传锁：可以引入文件上传锁，确保同一时刻只有一个用户可以进行上传操作。当一个用户开始上传文件时，其他用户需要等待上传锁释放后才能开始上传。\n（2）版本控制：可以为每个文件引入版本控制，确保每个上传的文件都有唯一的版本号。用户上传同名文件时，系统会自动为其分配一个新的版本号，以保证数据的唯一性。\n```\n\n### 优化：多用户上传同一个文件\n\n```\n对分片加锁\n```\n\n### 什么选minio？不用fastDFS\n\n什么是minio？\n\n```\n（1）MinIO是专门为海量数据存储、人工智能、大数据分析而设计的对象存储系统\n（2）单个对象最大可达5TB。非常适合储海量图片、视频、日志文件、备份数据和容器/虚拟机镜像等\n（3）MinIO主要采用Golang语言实现，整个系统都运行在操作系统的用户态空间，客户端与存储服务器之间采用HTTP/HTTPs通信协议。\n```\n\n为什么要用？\n\n```\n（1）安装部署简单，支持云容器化部署\n（2）操作简单，自带ui管理界面。fastDFS默认没有\n（3）性能优秀，可以达到每秒GB级别的读写速度\n（4）提供了多语言SDK的支持，参考文档非常全面\n（5）兼容亚马逊S3 API\n\t\t- 亚马逊云的 S3 API（接口协议） 是在全球范围内达到共识的对象存储的协议，是全世界认可的对象存储标准。而MinIO是第一个采用S3兼容协议的产品之一\n\t\t- 兼容S3 API有什么好处呢？相当于目前为了节约服务器成本，选择用MinIO自主开发对象存储系统，等企业壮大之后，不想再运维基础设施，可以直接将程序平移到云厂商，不需要重新开发。\n```\n\n[参考](https://juejin.cn/post/7115313166703132709)\n\n\n\n### 为什么用celery？\n\n```\nCelery 是一个分布式任务队列系统，它可以用于执行长时间运行或定期任务\n\n（1）异步处理：当应用需要执行一个可能会耗时的操作时，如发送电子邮件或处理大量数据，可以使用 Celery 将这些操作作为一个后台任务进行，从而不会阻塞用户的请求。\n（2）分布式执行：Celery 允许在多个机器、虚拟机或容器中分布式地执行任务。这对于需要大量计算资源或并行处理的应用程序非常有用。\n（3）可靠性：如果一个工作者（worker）或任务失败，Celery 可以配置为重试任务，从而提供更高的可靠性。\n（4）监控和管理：通过工具如 Flower，开发者和运维人员可以实时监控和管理 Celery 的任务和工作者状态。可以通过taskId终止任务\n```\n\n\n\n### 为什么选择Mqtt？\n\n```\n（1）轻量级协议：MQTT是一个轻量级的发布/订阅协议，特别适合于低带宽、高延迟或不稳定的网络环境。这使其成为物联网(IoT)设备间通讯的理想选择，在我们的系统中，需要对实验过程中产生的数据进行采集，所以mqtt比较适合。\n（2）MQTT支持三个不同的消息交付级别：0 (至多一次)，1 (至少一次)，2 (只有一次)。这为不同的应用场景提供了灵活性。\n（3）持久会话：MQTT可以配置为持久会话，即当客户端掉线后，它可以再次上线并接收它错过的所有消息。\n（4）集成和兼容性：许多IoT平台和设备已经内置了对MQTT的支持，这意味着在整合时可能会更加容易。\n\n为什么不选kafka？\n（1）Kafka的用途：虽然Kafka也是一个消息传递系统，但它主要用于大数据流处理和实时数据处理。它的设计目标是高吞吐量、持久性和分布式数据流。而MQTT更注重设备到设备或设备到服务器的通讯。\n```\n\nmqtt\n\n```\nMQTT（Message Queuing Telemetry Transport，消 是一种基于发布/订阅（publish/subscribe）模式的“轻量级”通讯协议。\n最 大优点在于，用极少的代码和有限的带宽，为连接远程设备提供实时可靠的消息服务。\n作为一种低开销、低带宽占用的即时通讯协议，使其在 物联网、小型设备、移动应用等方面有较广泛的应用。\n```\n\nkafka\n\n```\nKafka 是一种高吞吐量的分布式发布订阅消息系统，\n优势包括：\n（1）高 吞吐量、低延迟：每秒可以处理几十万条消息，它的延迟最低只有几毫 秒；\n（2）可扩展性：集群支持热扩展；\n（3）持久性、可靠性：消息被 持久化到本地磁盘，并且支持数据备份防止数据丢失；\n（4）容错性：允 许集群中节点故障（若副本数量为 n，允许 n-1 个节点故障）；\n（5）高并发：支持数千个客户端同时读写。\n```\n\n\n\n\n\n\n\n\n\n### 有什么难点\n\n#### 难点1: 可拓展性\n\n```\n我们的系统是一个数据分析平台，需要集成很多算法，如果对于每个算法，我们都从头开始写编写，添加新的接口，写死在系统中，那么我们就会和甲方一直的绑定在一起，很被动，无法脱身，只有他们有算法需求，我们就需要派人去给他们集成。\n我们的想法是“能让他们自己玩，但又不能让他们脱离我们自己玩”，所以设计了这套分布式任务执行过程\n\n我们运用了python的模块动态加载功能，结合celery写了一个统一的入口，叫run操作，\n每一个算法都需要编写一个run方法，在执行过程中，通过文件名找到对应的算法，然后执行run方法，然后发布到worker中执行\n每个算法的输入、输出有一套统一的规范，大家都遵循这个规范来开发，这样就能保证整个流程正常的运转\n```\n\n#### 难点2: 大文件的处理\n\n```\n包括大文件的上传、使用：\n（1）上传\n实验过程中，会产生一些大文件非结构化数据，我们需要导入到系统中，来进行后面的处理分析流程\n大文件上传就会存在很多问题，如果上传过程中因为网络等原因中断，那么我们就得重新来过，前面的操作就白费了\n\n所以在文件的上传过程中进行了优化，通过文件分片上传、断点续传、文件秒传来优化上传过程\n\n（2）使用\n这部分主要是算法开发中会进行处理\n```\n\n#### 难点3: 结构化数据的维度很多，难以复用\n\n```\n实验过程中产生的一些结构化数据维度很多，可能会有几百上千列，我们需要设计一种机制来管理好这些维度定义，并且能够复用、衍生、及溯源\n\n我们就设计了实体模型（数据模型）这个概念，实体模型就是对数据列维度的定义，包括名称、类型等信息\n多次实验列维度可能有所不同，就可以新建一个实体模型，集成原来的实体模型，然后进行修改\n```\n\n\n\n## 优化\n\n### 串行接口改并行接口\n\n```\n对于一些不存在依赖关系的业务，需要在同一个接口中查询时，串行的处理就会导致后面的逻辑需要等待前面的业务查询处理完成之后才能开始。\n比如查询坎贝尔图数据的时候，需要查询数据、辅助线，主题数据需要进行一些缺失值处理和排序，辅助线需要进行格式化，而这两个业务是不存在先后关系的，可以并行完成。\n\n目前是通过「countDownLatch + 线程池」来完成\n```\n\n实现方式\n\n```\n方式1: join\n方式2: countDownLatch + 线程池\n方式3: CompletableFuture\n```\n\n参考\n\n-   [串行处理的优化方式有哪些？](https://blog.csdn.net/WODESHENNI/article/details/125051287)\n-   [如何写好代码：手把手教你写一个并行调用模板](https://articles.zsxq.com/id_051qnbm2cw68.html)\n-   [JAVA使用CompletableFuture实现流水线并行处理，加速你的接口响应](https://heapdump.cn/article/4456384)\n\n\n\n### SQL优化\n\n如何分析\n\n```\n使用explain可以得到sql的查询计划\n重点关注type、\n```\n\n怎么优化\n\n```\n（1）增删索引。\n\t- 删除一些不必要的索引\n\t- 一些查询频繁但修改少的字段添加索引，尽量添加联合索引。\n（2）避免返回不必要的数据。返回需要的字段，比如工作流任务中，包含了一个text类型的字段，查询会消耗大量的网络和io带宽。在查询列表时是用不到这个字段信息的，只有在编辑流程时才需要查该字段。\n（3）优化limit大分页问题。先查询limit后的id，再进行\n（4）索引失效问题\n\t\t- 最左匹配\n\t\t- 操作索引列\n\t\t- where字段 %like、not in、is not null\n\t\t- 隐式转换\n```\n\n\n\n## 反问\n\n```\n（1）我觉得美团优选的这个业务就很好，能很好的解决我们这些不经常去菜市场也不方便去的问题。\n如果我能进到下一轮，我应该去准备哪些地方来完善我的简历，或者说咱们部门比较看重哪一块的能力？\n```\n\n","timestamp":1693737903384},{"name":"03-设计图.md","path":"005-项目/001-民用航空发动机健康管理系统/03-设计图.md","content":"软件逻辑架构图\n\n![image-20230817231059358](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/17/23105916922850591692285059511P1Gvac-image-20230817231059358.png)\n\n物理结构图\n\n![image-20230817231132354](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/17/231132169228509216922850924542RaPbD-image-20230817231132354.png)","timestamp":1693737903384},{"name":"01-系统功能.md","path":"005-项目/002-weTeam校园/01-系统功能.md","content":"","timestamp":1693737903384},{"name":"01-场景题.md","path":"005-项目/01-场景题.md","content":"海量日志数据，访问最频繁的IP地址怎么找出来？只给你一个内存有限的机器 \n\n```\n\n```\n\n","timestamp":1693737903384}]