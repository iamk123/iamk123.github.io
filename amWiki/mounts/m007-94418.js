if(typeof AWPageMounts=='undefined'){AWPageMounts={}};AWPageMounts['m007']=[{"name":"01-springboot引入redis.md","path":"007-Redis/001-实践/01-springboot引入redis.md","content":"![image-20220714142255347](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2022/07/14/14225516577797751657779775453rJJreW-image-20220714142255347.png)\n\n## 步骤\n\n引入依赖\n\n`pom.xml`\n\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-data-redis</artifactId>\n    <exclusions>\n      <exclusion>\n        <artifactId>lettuce-core</artifactId>\n        <groupId>io.lettuce</groupId>\n      </exclusion>\n    </exclusions>\n</dependency>\n  <dependency>\n    <groupId>redis.clients</groupId>\n    <artifactId>jedis</artifactId>\n</dependency>\n```\n\n配置redis数据库\n\n`application/yaml`\n\n```yaml\nspring:\n  redis:\n    database: 0\n    host: 127.0.0.1\n    port: 6379\n    password:\n    jedis:\n      pool:\n        min-idle: 0\n        max-active: 8\n        max-idle: 8\n        max-wait: -1ms\n    connect-timeout: 30000ms\n\n```\n\n\n\n`RedisConfig.java`\n\n```java\n@Configuration\npublic class RedisConfig {\n\n    @Bean\n    public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory factory) {\n        RedisTemplate<String, Object> template = new RedisTemplate<>();\n        template.setConnectionFactory(factory);\n\n        // 设置key的序列化方式\n        template.setKeySerializer(RedisSerializer.string());\n        // 设置value的序列化方式\n        template.setValueSerializer(RedisSerializer.json());\n        // 设置hash的key的序列化方式\n        template.setHashKeySerializer(RedisSerializer.string());\n        // 设置hash的value的序列化方式\n        template.setHashValueSerializer(RedisSerializer.json());\n\n        template.afterPropertiesSet();\n        return template;\n    }\n}\n```\n\n\n\n使用\n\n```java\n\n@RunWith(SpringRunner.class)\n@SpringBootTest\n@ContextConfiguration(classes = CommunityApplication.class)\npublic class RedisTests {\n\n    @Autowired\n    private RedisTemplate redisTemplate;\n\n  \t// 字符串\n    @Test\n    public void testStrings() {\n        String redisKey = \"test:count\";\n\n        redisTemplate.opsForValue().set(redisKey, 1);\n\n        System.out.println(redisTemplate.opsForValue().get(redisKey));\n        System.out.println(redisTemplate.opsForValue().increment(redisKey));\n        System.out.println(redisTemplate.opsForValue().decrement(redisKey));\n    }\n\n    // hash\n    @Test\n    public void testHashes() {\n        String redisKey = \"test:user\";\n\n        redisTemplate.opsForHash().put(redisKey, \"id\", 1);\n        redisTemplate.opsForHash().put(redisKey, \"username\", \"zhangsan\");\n\n        System.out.println(redisTemplate.opsForHash().get(redisKey, \"id\"));\n        System.out.println(redisTemplate.opsForHash().get(redisKey, \"username\"));\n    }\n\n  \t// list\n    @Test\n    public void testLists() {\n        String redisKey = \"test:ids\";\n\n        redisTemplate.opsForList().leftPush(redisKey, 101);\n        redisTemplate.opsForList().leftPush(redisKey, 102);\n        redisTemplate.opsForList().leftPush(redisKey, 103);\n\n        System.out.println(redisTemplate.opsForList().size(redisKey));\n        System.out.println(redisTemplate.opsForList().index(redisKey, 0));\n        System.out.println(redisTemplate.opsForList().range(redisKey, 0, 2));\n\n        System.out.println(redisTemplate.opsForList().leftPop(redisKey));\n        System.out.println(redisTemplate.opsForList().leftPop(redisKey));\n        System.out.println(redisTemplate.opsForList().leftPop(redisKey));\n    }\n\n    // set\n    @Test\n    public void testSets() {\n        String redisKey = \"test:teachers\";\n\n        redisTemplate.opsForSet().add(redisKey, \"刘备\", \"关羽\", \"张飞\", \"赵云\", \"诸葛亮\");\n\n        System.out.println(redisTemplate.opsForSet().size(redisKey));\n        System.out.println(redisTemplate.opsForSet().pop(redisKey));\n        System.out.println(redisTemplate.opsForSet().members(redisKey));\n    }\n\n    // 排序set\n    @Test\n    public void testSortedSets() {\n        String redisKey = \"test:students\";\n\n        redisTemplate.opsForZSet().add(redisKey, \"唐僧\", 80);\n        redisTemplate.opsForZSet().add(redisKey, \"悟空\", 90);\n        redisTemplate.opsForZSet().add(redisKey, \"八戒\", 50);\n        redisTemplate.opsForZSet().add(redisKey, \"沙僧\", 70);\n        redisTemplate.opsForZSet().add(redisKey, \"白龙马\", 60);\n\n        System.out.println(redisTemplate.opsForZSet().zCard(redisKey));\n        System.out.println(redisTemplate.opsForZSet().score(redisKey, \"八戒\"));\n        System.out.println(redisTemplate.opsForZSet().reverseRank(redisKey, \"八戒\"));\n        System.out.println(redisTemplate.opsForZSet().reverseRange(redisKey, 0, 2));\n    }\n\n    @Test\n    public void testKeys() {\n        redisTemplate.delete(\"test:user\");\n\n        System.out.println(redisTemplate.hasKey(\"test:user\"));\n\n        redisTemplate.expire(\"test:students\", 10, TimeUnit.SECONDS);\n    }\n\n    // 批量发送命令,节约网络开销.\n    @Test\n    public void testBoundOperations() {\n        String redisKey = \"test:count\";\n        BoundValueOperations operations = redisTemplate.boundValueOps(redisKey);\n        operations.increment();\n        operations.increment();\n        operations.increment();\n        operations.increment();\n        operations.increment();\n        System.out.println(operations.get());\n    }\n\n    // 编程式事务\n    @Test\n    public void testTransaction() {\n        Object result = redisTemplate.execute(new SessionCallback() {\n            @Override\n            public Object execute(RedisOperations redisOperations) throws DataAccessException {\n                String redisKey = \"text:tx\";\n\n                // 启用事务\n                redisOperations.multi();\n                redisOperations.opsForSet().add(redisKey, \"zhangsan\");\n                redisOperations.opsForSet().add(redisKey, \"lisi\");\n                redisOperations.opsForSet().add(redisKey, \"wangwu\");\n\n                System.out.println(redisOperations.opsForSet().members(redisKey));\n\n                // 提交事务\n                return redisOperations.exec();\n            }\n        });\n        System.out.println(result);\n    }\n\n}\n\n```\n\n\n\n\n\n## 参考\n\n-   [SpringBoot集成Redis - 基于RedisTemplate+Jedis的数据操作](https://pdai.tech/md/spring/springboot/springboot-x-redis-jedis.html)\n\n-   [SpringBoot整合Redis实现分布式缓存、分布式锁等，实战分享！](https://www.51cto.com/article/744722.html)\n    -   springboot redis的基本使用\n","timestamp":1693737620936},{"name":"02-redis实现分布式锁.md","path":"007-Redis/001-实践/02-redis实现分布式锁.md","content":"TODO：\n\n https://mp.weixin.qq.com/s/3zuATaua6avMuGPjYEDUdQ\n\n```\n1.2 过期时间不精准问题\n1.3 数据弱一致性问题\n\n基于 watchDog 看门狗机制以及 redLock 红锁机制给出对应的解决方案.\n```\n\nhttps://mp.weixin.qq.com/s/ha4Ojv9tDNaeMg4mAVwUTA\n\n```\n自动续期\n```\n\n\n\n实现原理\n\n```\n（1）获取锁的时候，使用setnx加锁，并使用expire命令为锁添加一个超时时间，超过该时间则自动释放锁，锁的value值为一个随机生成的UUID，通过此在释放锁的时候进行判断。\n（2）获取锁的时候还设置一个获取的超时时间，若超过这个时间则放弃获取锁。\n（3）释放锁的时候，通过UUID判断是不是该锁，若是该锁，则执行delete进行锁释放。\n```\n\n## key的设计\n\n```\n固定前缀:项目名:数据库名:表名:字段名:具体的值\n```\n\n## 问题\n\n### 剩余票问题\n\n如果10张票，10个人抢，同一时刻也只有一个人能拿到锁，其它也会因拿不到锁而失败返回，就会剩余票，怎么解决？\n\n```java\npublic boolean lock(String lockKey, String value, long expireTime) {\n        System.out.println(\"lock:: key:\" + lockKey + \" value: \" + value);\n        return redisTemplate.opsForValue().setIfAbsent(lockKey, value, expireTime, TimeUnit.SECONDS);\n}\n```\n解决\n\n```\n（1）规定时间内尝试获取锁，而不是获取失败就立即返回\n（2）重试机制。获取到锁的线程，执行业务逻辑之前先检测剩余票数，为0直接释放锁。未获取锁的线程在获取锁的逻辑中使用循环，直到获取到锁或超过一定的尝试次数才退出循环\n\n```\n\n```java\n@Resource\nprivate RedisTemplate redisTemplate;\n\nvoid saleTick() {\n\t\t...\n    int maxRetryCount = 3; // 最大重试次数\n    int retryIntervalMillis = 100; // 重试间隔时间（毫秒）\n    int retryCount = 0;\n  \n     try {\n          boolean locked = false;\n          while (!locked && retryCount < maxRetryCount) {\n            \tboolean locked = redisLock.tryLock(key, requestId, Duration.ofSeconds(2));\t// 2s内尝试获取锁\n              if (!locked) {\n                  retryCount++;\n                  Thread.sleep(retryIntervalMillis); // 重试间隔\n              }\n          }\n       \n       \t\t// 获取到锁的业务逻辑...\n     } finally {\n        redisLock.unlock(key, requestId);\n    }\n}\n```\n\n### 解锁要使用lua的原因？\n\n```java\n// 不使用lua的方式\npublic boolean unlock(String key, String value) {\n  \tObject currentValue = redisTemplate.opsForValue().get(key);\n  \tboolean result = false;\n    if (StringUtils.isNotEmpty(String.valueOf(currentValue)) && currentValue.equals(value)) {\n      result = redisTemplate.opsForValue().getOperations().delete(key);\n    }\n    return result;\n}\n```\n\n不使用Lua解锁可能会存在以下隐患：\n\n```\n\n（1）非原子性操作：如果在解锁过程中使用了多个Redis命令，例如先查询锁状态再进行解锁操作，那么这两个操作之间可能会发生竞争条件。即使在判断锁状态时锁是存在的，但在执行解锁操作之前，其他客户端可能已经抢占了锁，导致解锁操作失败。\n（2）网络开销增加：在不使用Lua解锁的情况下，解锁过程需要发送多个Redis命令，这会增加网络通信的开销。每个命令都需要与Redis服务器进行交互，而频繁的网络通信可能会增加延迟和降低性能。\n（3）锁的误解锁：在解锁过程中，如果由于某种原因（例如网络故障、程序异常等）导致解锁命令未能成功发送或执行，那么就会出现锁的误解锁情况。这会导致其他客户端在未完成任务的情况下获得了锁，可能引发数据一致性问题。\n\n综上所述，不使用Lua解锁可能会带来竞争条件、增加网络开销和锁的误解锁等隐患。使用Lua脚本可以解决这些问题，并提供更可靠和高效的分布式锁机制。\n\n```\n### 程序异常无法解锁，导致死锁\n\n```\nfinally中进行删除锁的操作\n```\n\n### 误解锁问题\n\n```\n给锁加一个标识符，只允许自己来操作锁，其他访问程序不能操作锁\n如String requestId = String.valueOf(gameId + Thread.currentThread().getId());\n```\n\n### 运行的程序彻底死掉，如断电，还是会无法解锁导致死锁\n\n```\n还要给锁加一个过期时间，这样就算程序死了，当时间过期后，还是能够继续执行\n```\n\n### 锁的过期时间过短，业务还未执行完成\n\n```\n守护线程/定期任务，续期\n```\n\n### 扣减库存的过程可以用lua脚本保证原子性\n\n```\n\n```\n\n### 处理业务逻辑中，使用lua脚本，避免超卖问题??也不会哦\n\n不使用lua脚本，[无法保证原子性，典型的RMW模型](https://juejin.cn/post/7127667756693979173)？？好像也不会出现超卖问题？？？\n\n```java\nint stock = Integer.parseInt(redisTemplate.opsForValue().get(\"product001-stock\").toString());\nif(stock <= 0) {\n    System.out.println(\"卖完啦！\");\n    return;\n}\nint currentStock = stock - 1;\nredisTemplate.opsForValue().set(\"product001-stock\",currentStock);\n```\n\n使用lua脚本\n\n```java\n// 方式2：Lua：参数列表下标从0开始, 获取KEYS[1]对应的值，判断是否<=0，小于返回0；大于则-1\nString script = \"local stock = redis.call(\'get\', KEYS[1])\\n\" +\n                \"if tonumber(stock) <= 0 then\\n\" +\n                \"    return 0\\n\" +\n                \"else\\n\" +\n                \"    redis.call(\'decr\', KEYS[1])\\n\" +\n                \"    return 1\\n\" +\n                \"end\";\nRedisScript<Long> redisScript = new DefaultRedisScript<>(script, Long.class);\nString key2 = \"product001-stock\";\nLong result = (Long) redisTemplate.execute(redisScript, Collections.singletonList(key2));\nint stock = Integer.parseInt(redisTemplate.opsForValue().get(\"product001-stock\").toString());\nif (result == 1) {\n  \t// 执行成功\n  \tSystem.out.println(\"线程：\" + Thread.currentThread().getName() + \" 抢到票，剩余: \" + stock);\n} else {\n    // 执行失败\n    System.out.println(\"抢票失败\");\n}\n```\n\n\n\n## 例子：抢票\n\n`redis`配置\n\n```java\npackage com.example.springbootdemo.redis;\n\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.data.redis.connection.RedisConnectionFactory;\nimport org.springframework.data.redis.core.RedisTemplate;\nimport org.springframework.data.redis.serializer.GenericJackson2JsonRedisSerializer;\nimport org.springframework.data.redis.serializer.GenericToStringSerializer;\nimport org.springframework.data.redis.serializer.RedisSerializer;\nimport org.springframework.data.redis.serializer.StringRedisSerializer;\n\n\n@Configuration\npublic class RedisConfig {\n\n    @Bean\n    public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory factory) {\n        RedisTemplate<String, Object> template = new RedisTemplate<>();\n        template.setConnectionFactory(factory);\n\n        // 设置key的序列化方式\n        template.setKeySerializer(RedisSerializer.string());\n        // 设置value的序列化方式\n        template.setValueSerializer(RedisSerializer.json());\n        // 设置hash的key的序列化方式\n        template.setHashKeySerializer(RedisSerializer.string());\n        // 设置hash的value的序列化方式\n        template.setHashValueSerializer(RedisSerializer.json());\n\n        template.afterPropertiesSet();\n        return template;\n    }\n}\n```\n\nRedis分布式锁通用操作类\n\nTODO: 到期自动续期，参考redisson的看门狗watchdog\n\n```java\npackage com.example.springbootdemo.redis;\n\nimport com.alibaba.fastjson.JSON;\nimport lombok.Getter;\nimport lombok.Setter;\nimport lombok.extern.slf4j.Slf4j;\nimport org.apache.commons.lang3.StringUtils;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.data.redis.core.RedisTemplate;\nimport org.springframework.data.redis.core.script.DefaultRedisScript;\nimport org.springframework.data.redis.core.script.RedisScript;\nimport org.springframework.scheduling.annotation.Async;\nimport org.springframework.scheduling.annotation.Scheduled;\nimport org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;\nimport org.springframework.stereotype.Component;\n\nimport javax.annotation.Resource;\nimport java.lang.management.LockInfo;\nimport java.time.Duration;\nimport java.util.ArrayList;\nimport java.util.Collections;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.Executor;\nimport java.util.concurrent.ThreadPoolExecutor;\nimport java.util.concurrent.TimeUnit;\n\n/**\n * Redis分布式锁通用操作类\n */\n@Slf4j\n@Component\npublic class RedisLockUtils {\n    @Resource\n    private RedisTemplate redisTemplate;\n    private static Map<String, LockInfo> lockInfoMap = new ConcurrentHashMap<>();\n    private static final Long SUCCESS = 1L;\n\n    /** 分布式锁过期时间，单位秒 */\n    private static final Long DEFAULT_LOCK_EXPIRE_TIME = 60L;\n\n    @Getter\n    @Setter\n    public static class LockInfo {\n        private String key;\n        private String value;\n        private int expireTime;\n        //更新时间\n        private long renewalTime;\n        //更新间隔\n        private long renewalInterval;\n        public static LockInfo getLockInfo(String key, String value, int expireTime) {\n            LockInfo lockInfo = new LockInfo();\n            lockInfo.setKey(key);\n            lockInfo.setValue(value);\n            lockInfo.setExpireTime(expireTime);\n            lockInfo.setRenewalTime(System.currentTimeMillis());\n            lockInfo.setRenewalInterval(expireTime * 2000 / 3);\n            return lockInfo;\n        }\n    }\n\n    /**\n     * 使用lua脚本更新redis锁的过期时间\n     * @param lockKey\n     * @param value\n     * @return 成功返回true, 失败返回false\n     */\n    public boolean renewal(String lockKey, String value, int expireTime) {\n        String luaScript = \"if redis.call(\'get\', KEYS[1]) == ARGV[1] then return redis.call(\'expire\', KEYS[1], ARGV[2]) else return 0 end\";\n        DefaultRedisScript<Boolean> redisScript = new DefaultRedisScript<>();\n        redisScript.setResultType(Boolean.class);\n        redisScript.setScriptText(luaScript);\n        List<String> keys = new ArrayList<>();\n        keys.add(lockKey);\n\n        Object result = redisTemplate.execute(redisScript, keys, value, expireTime);\n        log.info(\"更新redis锁的过期时间：{}\", result);\n        return (boolean) result;\n    }\n\n    /**\n     * 直接加锁\n     * @param lockKey    锁\n     * @param value      身份标识（保证锁不会被其他人释放）\n     * @param expireTime 锁的过期时间（单位：秒）\n     * @return 成功返回true, 失败返回false\n     */\n    public boolean lock(String lockKey, String value, long expireTime) {\n        // System.out.println(\"lock:: key:\" + lockKey + \" value: \" + value);\n        return redisTemplate.opsForValue().setIfAbsent(lockKey, value, expireTime, TimeUnit.SECONDS);\n    }\n\n    /**\n     * 直接加锁2 - lua脚本\n     * @param key\n     * @param value\n     * @param expire\n     * @return\n     */\n    public boolean lock2(String key, String value, Long expire){\n        String luaScript = \"if redis.call(\'setnx\', KEYS[1], ARGV[1]) == 1 then return redis.call(\'expire\', KEYS[1], ARGV[2]) else return 0 end\";\n        RedisScript<Long> redisScript = new DefaultRedisScript<>(luaScript, Long.class);\n        Long result = (Long) redisTemplate.execute(redisScript, Collections.singletonList(key), value, String.valueOf(expire));\n        return result.equals(Long.valueOf(1));\n    }\n\n    /**\n     * 尝试在指定时间内加锁\n     * @param key\n     * @param value\n     * @param timeout 锁等待时间\n     * @return\n     */\n    public boolean tryLock(String key, String value, Duration timeout){\n        long waitMills = timeout.toMillis();\n        long currentTimeMillis = System.currentTimeMillis();\n        do {\n            boolean lock = lock(key, value, DEFAULT_LOCK_EXPIRE_TIME);\n            if (lock) {\n                return true;\n            }\n            try {\n                Thread.sleep(1L);\n            } catch (InterruptedException e) {\n                Thread.interrupted();\n            }\n        } while (System.currentTimeMillis() < currentTimeMillis + waitMills);\n        return false;\n    }\n\n\n    /**\n     * 释放锁 - lua脚本解锁\n     * @param key\n     * @param value\n     * @return\n     */\n    public boolean unlock(String key,String value){\n        String luaScript = \"if redis.call(\'get\', KEYS[1]) == ARGV[1] then return redis.call(\'del\', KEYS[1]) else return 0 end\";\n        RedisScript<Long> redisScript = new DefaultRedisScript<>(luaScript, Long.class);\n        Long result = (Long) redisTemplate.execute(redisScript, Collections.singletonList(key), value);\n        return result.equals(Long.valueOf(1));\n    }\n\n    /**\n     * 定时去检查redis锁的过期时间\n     */\n    @Scheduled(fixedRate = 5000L)\n    @Async(\"redisExecutor\")\n    public void renewal() {\n        long now = System.currentTimeMillis();\n        for (Map.Entry<String, LockInfo> lockInfoEntry : lockInfoMap.entrySet()) {\n            LockInfo lockInfo = lockInfoEntry.getValue();\n            if (lockInfo.getRenewalTime() + lockInfo.getRenewalInterval() < now) {\n                renewal(lockInfo.getKey(), lockInfo.getValue(), lockInfo.getExpireTime());\n                lockInfo.setRenewalTime(now);\n                log.info(\"lockInfo {}\", JSON.toJSONString(lockInfo));\n            }\n        }\n    }\n\n    /**\n     * 分布式锁设置单独线程池\n     * @return\n     */\n    @Bean(\"redisExecutor\")\n    public Executor redisExecutor() {\n        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();\n        executor.setCorePoolSize(1);\n        executor.setMaxPoolSize(1);\n        executor.setQueueCapacity(1);\n        executor.setKeepAliveSeconds(60);\n        executor.setThreadNamePrefix(\"redis-renewal-\");\n        executor.setRejectedExecutionHandler(new ThreadPoolExecutor.DiscardOldestPolicy());\n        return executor;\n    }\n}\n\n```\n\n抢票业务请求\n\n```java\npackage com.example.springbootdemo.redis;\n\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.data.redis.core.RedisTemplate;\nimport org.springframework.data.redis.core.script.DefaultRedisScript;\nimport org.springframework.data.redis.core.script.RedisScript;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PostMapping;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\nimport javax.annotation.Resource;\nimport java.time.Duration;\nimport java.util.Collections;\nimport java.util.Random;\n\n@RestController\npublic class IndexController {\n    @Resource\n    private RedisTemplate redisTemplate;\n\n    @Autowired\n    private RedisLockUtils redisLock;\n\n    @GetMapping(\"/saleTick\")\n    public String saleTick() {\n        System.out.println(\"===saleTick===\");\n        String productId = \"product001\";\n        String requestId = productId + Thread.currentThread().getId();\n        String key = productId;\n        int maxRetryCount = 3; // 最大重试次数\n        int retryIntervalMillis = 100; // 重试间隔时间（毫秒）\n        int retryCount = 0;\n\n        try {\n            // 方式1：获取失败直接返回\n            // boolean locked = redisLock.lock(key, requestId, 10);\n\n            // 方式2：规定时间内尝试获取锁\n            // boolean locked = redisLock.tryLock(key, requestId, Duration.ofSeconds(2));\n\n            // 方式3：重试机制\n            boolean locked = false;\n            while (!locked && retryCount < maxRetryCount) {\n                locked = redisLock.tryLock(key, requestId, Duration.ofSeconds(1));\t// 2s内尝试获取锁\n\n                if (!locked) {\n                    retryCount++;\n                    Thread.sleep(retryIntervalMillis); // 重试间隔\n                }\n            }\n\n\n            if (!locked) {\n                // System.out.println(\"error\");\n                return \"获取锁失败\";\n            }\n\n            // 执行业务逻辑\n            // 方式1：非lua方式\n            // int stock = Integer.parseInt(redisTemplate.opsForValue().get(\"product001-stock\").toString());\n            // if(stock <= 0) {\n            //     System.out.println(\"卖完啦！\");\n            //     return \"卖完啦\";\n            // }\n            // int currentStock = stock - 1;\n            // redisTemplate.opsForValue().set(\"product001-stock\",currentStock);\n            // try {\n            //     Random random = new Random();\n            //     Thread.sleep(random.nextInt(3) * 1000);\n            // } catch (InterruptedException e) {\n            //     e.printStackTrace();\n            // }\n            // System.out.println(\"线程：\" + Thread.currentThread().getName() + \" 抢到票，剩余: \" + currentStock);\n\n            // 方式2：Lua：参数列表下标从0开始, 获取KEYS[1]对应的值，判断是否<=0，小于返回0；大于则-1\n            String script = \"local stock = redis.call(\'get\', KEYS[1])\\n\" +\n                    \"if tonumber(stock) <= 0 then\\n\" +\n                    \"    return 0\\n\" +\n                    \"else\\n\" +\n                    \"    redis.call(\'decr\', KEYS[1])\\n\" +\n                    \"    return 1\\n\" +\n                    \"end\";\n            RedisScript<Long> redisScript = new DefaultRedisScript<>(script, Long.class);\n            String key2 = \"product001-stock\";\n            Long result = (Long) redisTemplate.execute(redisScript, Collections.singletonList(key2));\n            int stock = Integer.parseInt(redisTemplate.opsForValue().get(\"product001-stock\").toString());\n            if (result == 1) {\n                // 执行成功\n                System.out.println(\"线程：\" + Thread.currentThread().getName() + \" 抢到票，剩余: \" + stock);\n            } else {\n                // 执行失败\n                System.out.println(\"抢票失败\");\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        finally {\n\n            redisLock.unlock(key, requestId);\n        }\n\n        return \"买到了\";\n    }\n\n}\n\n```\n\n\n\n参考\n\n-   [SpringBoot整合Redis实现分布式缓存、分布式锁等，实战分享！](https://www.51cto.com/article/744722.html)\n    -   springboot redis的基本使用\n    -   lua脚本加锁、解锁\n    -   规定时间内加锁\n\n-   [SpringBoot+Redis实现分布式锁](https://zhuanlan.zhihu.com/p/536951041)\n    -   直接加锁，直接释放\n    -   封了一个内部类，描述锁的信息\n    -   加锁失败直接返回\n\n-   [手写一个Redis分布式锁，让你彻底搞懂](https://www.51cto.com/article/722510.html)\n    -   分布式锁的各种问题\n\n-   [Spring Boot 实现Redis分布式锁](https://juejin.cn/post/7127667756693979173)\n    -   代码跑不通\n\n-   [Spring Boot 集成Redisson实现分布式锁](https://juejin.cn/post/7128050664336261157)\n    -   解决锁定续期、可重入的问题\n    -   分布式系统可用\n\n-   [SpringBoot集成Redis - Redis分布式锁的实现之Jedis(setNXPX+Lua)](https://www.pdai.tech/md/spring/springboot/springboot-x-redis-lettuce-dist-lock.html)\n    -   切片，注解的方式使用\n    -   有源码\n\n-   [分布式系统 - 分布式锁及实现方案](https://www.pdai.tech/md/arch/arch-z-lock.html)\n\n-   [SpringBoot接口 - 如何保证接口幂等](https://www.pdai.tech/md/spring/springboot/springboot-x-interface-mideng.html)","timestamp":1693737620936},{"name":"03-布隆过滤器.md","path":"007-Redis/001-实践/03-布隆过滤器.md","content":"\n\n## 1 缓存穿透\n\n### 出现场景\n\n```java\n// 商品服务查询详情\npublic Product queryProductById (Long id){\n   // 查询缓存\n   Product product = queryFromCache(id);\n   if(product != null) {\n     return product ;\n   }\n   // 从数据库查询\n   product = queryFromDataBase(id);\n   if(product != null) {\n       saveCache(id , product);\n   }\n   return product;\n}\n```\n\n假设此商品既不存储在缓存中，也不存在数据库中，则没有办法**回写缓存** ，当有类似这样大量的请求访问服务时，数据库的压力就会极大。\n\n\n\n## 2 原理解析\n\n[布隆过滤器如何工作](https://xiaolincoding.com/redis/cluster/cache_problem.html#缓存穿透)\n\n### 是什么？\n\n```\n是一个很长的二进制向量 和一系列随机映射函数，用于检索一个元素是否在一个集合中。\n优点是空间效率 和查询时间 都远远超过一般的算法 ，缺点是有一定的误识别率和删除困难。\n```\n\n### 实现原理\n\n```\n当一个元素被加入集合时，通过 K 个散列函数将这个元素映射成一个位数组中的 K 个点，把它们置为 1。检索时，我们只要看看这些点是不是都是 1 就（大约）知道集合中有没有它了：如果这些点有任何一个 0 ，则被检元素一定不在 ；如果都是 1 ，则被检元素很可能在 \n```\n\n简单来说就是准备一个长度为 m 的位数组并初始化所有元素为 0，用 k 个散列函数对元素进行 k 次散列运算跟 len (m) 取余得到 k 个位置并将 m 中对应位置设置为 1。\n\n![图片](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/06/02/20501216857102121685710212633NzArlu-640-20230602205012453.png)\n\n如上图，位数组的长度是８，散列函数个数是 3，先后保持两个元素ｘ，ｙ。这两个元素都经过三次哈希函数生成三个哈希值，并映射到位数组的不同的位置，并置为1。元素 x 映射到位数组的第０位，第４位，第７位，元素ｙ映射到数组的位数组的第１位，第４位，第６位。\n\n保存元素 x 后，位数组的第4位被设置为1之后，在处理元素 y 时第4位会被覆盖，同样也会设置为 1。\n\n当布隆过滤器**保存的元素越多** ，**被置为 1 的 bit 位也会越来越多** ，元素 x 即便没有存储过，假设哈希函数映射到位数组的三个位都被其他值设置为 1 了，对于布隆过滤器的机制来讲，元素 x 这个值也是存在的，也就是说布隆过滤器**存在一定的误判率** 。\n\n### 误判率\n\n```\n若位数组长度太小则会导致所有 bit 位很快都会被置为 1 ，那么检索任意值都会返回”可能存在“ ， 起不到过滤的效果。位数组长度越大，则误判率越小。\n\n同时，哈希函数的个数也需要考量，哈希函数的个数越大，检索的速度会越慢，误判率也越小，反之，则误判率越高。\n```\n\n### 时间和空间效率\n\n```\n布隆过滤器的空间复杂度为 O(m) ，插入和查询时间复杂度都是 O(k) 。存储空间和插入、查询时间都不会随元素增加而增大。空间、时间效率都很高。\n```\n\n### 哈希函数类型\n\n```\nMurmur3，FNV 系列和 Jenkins 等非密码学哈希函数适合，因为 Murmur3 算法简单，能够平衡好速度和随机分布，很多开源产品经常选用它作为哈希函数。\n```\n\n### 布隆过滤器支持删除吗？\n\n```\n布隆过滤器其实并不支持删除元素，因为多个元素可能哈希到一个布隆过滤器的同一个位置，如果直接删除该位置的元素，则会影响其他元素的判断。\n```\n\n## 3 开源项目实现\n\n### Guava实现\n\nGoogle Guava是 Google 开发和维护的开源 Java开发库，它包含许多基本的工具类，例如字符串处理、集合、并发工具、I/O和数学函数等等。\n\n**1、添加Maven依赖**\n\n```\n<dependency>\n    <groupId>com.google.guava</groupId>\n    <artifactId>guava</artifactId>\n    <version>31.0.1-jre<</version>\n</dependency>\n```\n\n**2、创建布隆过滤器**\n\n```java\nBloomFilter<Integer> filter = BloomFilter.create(\n  //Funnel 是一个接口，用于将任意类型的对象转换为字节流，\n  //以便用于布隆过滤器的哈希计算。\n  Funnels.integerFunnel(), \n  10000,  // 插入数据条目数量\n  0.001  // 误判率\n);\n```\n\n**3、添加数据**\n\n```java\n@PostConstruct\npublic void addProduct() {\n    logger.info(\"初始化布隆过滤器数据开始\");\n    //插入4个元素\n     filter.put(1L);\n     filter.put(2L);\n     filter.put(3L);\n     filter.put(4L);\n     logger.info(\"初始化布隆过滤器数据结束\");\n}\n```\n\n**4、判断数据是否存在**\n\n```java\npublic boolean maycontain(Long id) {\n    return filter.mightContain(id);\n}\n```\n\n### Redisson实现\n\nRedisson 是一个用 Java 编写的 Redis 客户端，它实现了分布式对象和服务，包括集合、映射、锁、队列等。Redisson的API简单易用，使得在分布式环境下使用Redis 更加容易和高效。\n\n**1、添加Maven依赖**\n\n```\n<dependency>\n   <groupId>org.redisson</groupId>\n   <artifactId>redisson</artifactId>\n   <version>3.16.1</version>\n</dependency>\n```\n\n**2、配置 Redisson 客户端**\n\n```\n@Configuration\npublic class RedissonConfig {\n\n Bean\n public RedissonClient redissonClient() {\n    Config config = new Config();\n    config.useSingleServer().setAddress(\"redis://localhost:6379\");\n    return Redisson.create(config);\n }\n \n}\n```\n\n**3、初始化**\n\n```\nRBloomFilter<Long> bloomFilter = redissonClient.\n                                      getBloomFilter(\"myBloomFilter\");\n//10000表示插入元素的个数，0.001表示误判率\nbloomFilter.tryInit(10000, 0.001);\n//插入4个元素\nbloomFilter.add(1L);\nbloomFilter.add(2L);\nbloomFilter.add(3L);\nbloomFilter.add(4L);\n```\n\n**4、判断数据是否存在**\n\n```\npublic boolean mightcontain(Long id) {\n    return bloomFilter.contains(id);\n}\n```\n\n**从源码分析 Redisson 布隆过滤器是如何实现的**\n\n[参考](https://mp.weixin.qq.com/s/0TSPT5PgFG_0pxklkcM3OA)\n\n\n\n## 4 实战要点\n\n### **1、缓存穿透场景**\n\n首先我们需要**初始化** 布隆过滤器，然后当用户请求时，判断过滤器中是否包含该元素，若不包含该元素，则直接返回不存在。\n\n若包含则从缓存中查询数据，若缓存中也没有，则查询数据库并回写到缓存里，最后给前端返回。\n\n![图片](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/06/02/20594116857107811685710781730Cpqt7x-640-20230602205941617.png)\n\n### **2、元素删除场景**\n\n现实场景，元素不仅仅是只有增加，还存在删除元素的场景，比如说商品的删除。\n\n原理解析这一节，我们已经知晓：**布隆过滤器其实并不支持删除元素，因为多个元素可能哈希到一个布隆过滤器的同一个位置，如果直接删除该位置的元素，则会影响其他元素的判断** 。\n\n我们有两种方案：\n\n#### **计数布隆过滤器**\n\n计数过滤器（Counting Bloom Filter）是布隆过滤器的扩展，标准 Bloom Filter 位数组的每一位扩展为一个小的计数器（Counter），在插入元素时给对应的 k （k 为哈希函数个数）个 Counter 的值分别加 1，删除元素时给对应的 k 个 Counter 的值分别减 1。\n\n![图片](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/06/02/21001416857108141685710814342ZcHtYu-640-20230602210014247.png)\n\n虽然计数布隆过滤器可以解决布隆过滤器无法删除元素的问题，但是又引入了另一个问题：“**更多的资源占用，而且在很多时候会造成极大的空间浪费** ”。\n\n#### **定时重新构建布隆过滤器**\n\n从工程角度来看，**定时重新构建布隆过滤器** 这个方案可行也可靠，同时也相对简单。\n\n![图片](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/06/02/21005316857108531685710853982v3g1sy-640-20230602210053895.png)\n\n1.  定时任务触发全量商品查询 ;\n2.  将商品编号添加到新的布隆过滤器 ;\n3.  任务完成，修改商品布隆过滤器的映射（从旧 A 修改成 新 B ）;\n4.  商品服务根据布隆过滤器的映射，选择新的布隆过滤器 B进行相关的查询操作 ；\n5.  选择合适的时间点，删除旧的布隆过滤器 A。\n\n\n\n## 5 自己实现一个布隆过滤器\n\n### 基础布隆过滤器\n\n```java\nimport java.util.BitSet;\n\npublic class BloomFilter {\n    private static final int DEFAULT_SIZE = 1000000; // 默认布隆过滤器的大小\n    private static final int[] SEEDS = {3, 5, 7, 11, 13, 17, 19, 23}; // 哈希函数种子\n\n    private BitSet bitSet;\n    private HashFunction[] hashFunctions;\n\n    public BloomFilter() {\n        this(DEFAULT_SIZE);\n    }\n\n    public BloomFilter(int size) {\n        bitSet = new BitSet(size);\n        hashFunctions = new HashFunction[SEEDS.length];\n        for (int i = 0; i < SEEDS.length; i++) {\n            hashFunctions[i] = new HashFunction(size, SEEDS[i]);\n        }\n    }\n\n    public void add(String value) {\n        for (HashFunction hashFunction : hashFunctions) {\n            int hash = hashFunction.hash(value);\n            bitSet.set(hash, true);\n        }\n    }\n\n    public boolean contains(String value) {\n        for (HashFunction hashFunction : hashFunctions) {\n            int hash = hashFunction.hash(value);\n            if (!bitSet.get(hash)) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    private static class HashFunction {\n        private int size;\n        private int seed;\n\n        public HashFunction(int size, int seed) {\n            this.size = size;\n            this.seed = seed;\n        }\n\n        public int hash(String value) {\n            int result = 0;\n            int len = value.length();\n            for (int i = 0; i < len; i++) {\n                result = seed * result + value.charAt(i);\n            }\n            return (size - 1) & result;\n        }\n    }\n}\n\n```\n\n### 定时重构布隆过滤器\n\n考虑元素删除情况, 使用\n\n```java\nimport java.util.BitSet;\nimport java.util.concurrent.TimeUnit;\n\npublic class BloomFilter {\n    private static final int DEFAULT_SIZE = 1000000; // 默认布隆过滤器的大小\n    private static final int[] SEEDS = {3, 5, 7, 11, 13, 17, 19, 23}; // 哈希函数种子\n\n    private BitSet bitSet;\n    private HashFunction[] hashFunctions;\n    private long rebuildInterval; // 重新构建布隆过滤器的时间间隔\n    private long lastRebuildTime; // 上次重新构建布隆过滤器的时间\n\n    public BloomFilter() {\n        this(DEFAULT_SIZE);\n    }\n\n    public BloomFilter(int size) {\n        bitSet = new BitSet(size);\n        hashFunctions = new HashFunction[SEEDS.length];\n        for (int i = 0; i < SEEDS.length; i++) {\n            hashFunctions[i] = new HashFunction(size, SEEDS[i]);\n        }\n        rebuildInterval = TimeUnit.DAYS.toMillis(1); // 默认重新构建时间间隔为1天\n        lastRebuildTime = System.currentTimeMillis();\n    }\n\n    public void setRebuildInterval(long intervalInMillis) {\n        this.rebuildInterval = intervalInMillis;\n    }\n\n    public void add(String value) {\n        for (HashFunction hashFunction : hashFunctions) {\n            int hash = hashFunction.hash(value);\n            bitSet.set(hash, true);\n        }\n    }\n\n    // 判断一个元素是否可能存在于布隆过滤器中\n    public boolean contains(String value) {\n        for (HashFunction hashFunction : hashFunctions) {\n            int hash = hashFunction.hash(value);\n            if (!bitSet.get(hash)) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    public void remove(String value) {\n        if (!contains(value)) {\n            return;\n        }\n        for (HashFunction hashFunction : hashFunctions) {\n            int hash = hashFunction.hash(value);\n            bitSet.set(hash, false);\n        }\n    }\n\n    public void rebuild() {\n        bitSet.clear();\n        lastRebuildTime = System.currentTimeMillis();\n    }\n\n    public void periodicallyRebuild() {\n        long currentTime = System.currentTimeMillis();\n        if (currentTime - lastRebuildTime >= rebuildInterval) {\n            rebuild();\n        }\n    }\n\n    private static class HashFunction {\n        private int size;\n        private int seed;\n\n        public HashFunction(int size, int seed) {\n            this.size = size;\n            this.seed = seed;\n        }\n\n        public int hash(String value) {\n            int result = 0;\n            int len = value.length();\n            for (int i = 0; i < len; i++) {\n                result = seed * result + value.charAt(i);\n            }\n            return (size - 1) & result;\n        }\n    }\n}\n\n```\n\n\n\n### redis实现布隆过滤器\n\n```java\nimport redis.clients.jedis.Jedis;\n\npublic class RedisBloomFilter {\n    private final Jedis jedis;\n    private final String filterKey;\n    private final int size;\n    private final int hashFunctions;\n\n    public RedisBloomFilter(String host, int port, String filterKey, int size, int hashFunctions) {\n        jedis = new Jedis(host, port);\n        this.filterKey = filterKey;\n        this.size = size;\n        this.hashFunctions = hashFunctions;\n    }\n\n    public void add(String value) {\n        for (int i = 0; i < hashFunctions; i++) {\n            long index = hash(value, i);\n            jedis.setbit(filterKey, index, true);\n        }\n    }\n\n    public boolean contains(String value) {\n        for (int i = 0; i < hashFunctions; i++) {\n            long index = hash(value, i);\n            if (!jedis.getbit(filterKey, index)) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    private long hash(String value, int seed) {\n        long result = 0;\n        int len = value.length();\n        for (int i = 0; i < len; i++) {\n            result = seed * result + value.charAt(i);\n        }\n        return (size - 1) & result;\n    }\n}\n\n```\n\n\n\n\n\n## 6 总结\n\n-   **布隆过滤器** 是一个很长的**二进制向量** 和一系列**随机映射函数** ，用于**检索一个元素是否在一个集合中** 。\n\n-   它的**空间效率** 和**查询时间** 都**远远超过一般的算法** ，但是有一定的误判率 （函数返回 true , 意味着元素可能存在，函数返回 false ，元素必定不存在）。\n\n-   布隆过滤器的四个核心属性：\n\n    -   k :  哈希函数个数\n\n    -   m : 位数组长度\n\n    -   n :  插入的元素个数\n\n    -   p :  误判率\n\n\n-   Java 世界里 ，通过 Guava 和 Redisson 创建和使用布隆过滤器非常简单。\n\n-   布隆过滤器无法删除元素，但我们可以通过**计数布隆过滤器** 和**定时重新构建布隆过滤器** 两种方案实现删除元素的效果。\n\n-   为什么这么多的开源项目中使用布隆过滤器 ？\n\n    ```\n    因为它的设计精巧且简洁，工程上实现非常容易，效能高，虽然有一定的误判率，但软件设计不就是要 trade off 吗 ？\n    ```\n\n    \n\n\n\n## 7 疑问\n\n布隆过滤器无法删除元素，如何解决？\n\n```\n计数布隆过滤器 & 定时重构布隆过滤器\n```\n\n定时重构布隆过滤器过程中有其他方法在使用怎么办？\n\n```\n加锁\n```\n\n除了布隆过滤器 还有什么方法解决缓存穿透问题？\n\n```\n缓存空对象：当一个查询请求发现数据库中不存在对应的结果时，可以将空对象（如null或空列表）缓存起来。这样，下次同样的查询请求到来时，可以直接从缓存中获取结果，而不需要查询数据库。这种方式可以避免频繁查询数据库，但需要注意更新数据库时也要更新对应的缓存。\n\n延迟加载：将缓存中不存在的数据标记为\"正在加载\"状态，然后再次进行查询的时候等待加载完成。这样可以避免同时大量请求穿透缓存到达数据库，而是只有一个请求去查询数据库，其他请求等待结果即可。一旦数据加载完成，后续的查询请求就可以从缓存中获取到数据。\n\n限制请求频率：通过限制请求的频率，例如使用令牌桶算法或限流器，可以有效控制请求的并发量，减轻数据库的压力。这种方式可以防止缓存穿透问题的恶意攻击或异常情况下的大量请求。\n\n热点数据预加载：对于预先知道的热点数据，可以在系统启动或者定时任务中提前加载到缓存中。这样可以确保热点数据在缓存中存在，避免缓存穿透问题。\n\n异步加载：对于缓存中不存在的数据，可以通过异步方式从数据库中加载，并将加载完成的数据更新到缓存中。这样可以避免请求阻塞，提高系统的并发能力。\n```\n\n\n\n## 参考\n\n-   [品味布隆过滤器的设计之美](https://mp.weixin.qq.com/s/0TSPT5PgFG_0pxklkcM3OA)（主要）\n-   其他\n    -   [BloomFilter 布隆过滤器思想原理和代码实现](https://cloud.tencent.com/developer/article/2196903)\n    -   [布隆过滤器解决Redis缓存穿透](https://juejin.cn/post/7125236226189164575)\n    -   [布隆过滤器原理及使用场景](https://shaoyl.com/archives/bloome-filter)\n    -   [springboot中使用布隆过滤器BloomFilter](https://www.bmabk.com/index.php/post/80034.html)\n    -   [大数据处理 - Bitmap & Bloom Filter](https://www.pdai.tech/md/algorithm/alg-domain-bigdata-bloom-filter.html)\n        -   布隆过滤器的其他应用\n\n","timestamp":1693737620936},{"name":"04-springboot中使用布隆过滤器.md","path":"007-Redis/001-实践/04-springboot中使用布隆过滤器.md","content":"\n\n`pom.xml`引入\n\n```xml\n<dependency>\n    <groupId>com.google.guava</groupId>\n    <artifactId>guava</artifactId>\n    <version>27.0.1-jre</version>\n</dependency>\n```\n\n初始化布隆过滤器\n\n```java\npackage com.weteam.portal.config;\n\nimport com.google.common.hash.BloomFilter;\nimport com.google.common.hash.Funnels;\nimport com.weteam.common.util.RedisKeyUtil;\nimport com.weteam.common.util.RedisUtil;\nimport com.weteam.portal.dao.WtGameDao;\nimport com.weteam.portal.modal.entity.WtGame;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.stereotype.Component;\n\nimport java.nio.charset.Charset;\nimport java.util.List;\n\n/**\n * 布隆过滤器配置\n */\n@Component\npublic class BloomFilterConfig {\n    @Autowired\n    private WtGameDao gameDao;\n    @Autowired\n    private RedisUtil redisUtil;\n\n    /**\n     * 期望添加的数据个数\n     */\n    @Value(\"${bf.game.expected-insertions}\")\n    private Long gameExpectedInsertions ;\n\n    /**\n     * 误判率（大于0，小于1.0）,期望的误判率，期望的误判率越低，布隆过滤器计算时间越长\n     */\n    @Value(\"${bf.game.fpp}\")\n    private Double gameFpp;\n\n\n    /**\n     * 初始化game布隆过滤器\n     * @return\n     */\n    @Bean\n    public BloomFilter<String> gameBloomFilter() {\n        BloomFilter<String> bloomFilter = createBloomFilter();\n        loadBloomFilterGameData(bloomFilter);\n        return bloomFilter;\n    }\n\n    /**\n     * 创建一个布隆过滤器\n     * @return\n     */\n    public BloomFilter<String> createBloomFilter() {\n        return BloomFilter.create(Funnels.stringFunnel(Charset.defaultCharset()),\n                gameExpectedInsertions, gameFpp);\n    }\n\n    /**\n     * 将数据添加到布隆过滤器 & redis\n     * @param bloomFilter\n     */\n    public void loadBloomFilterGameData(BloomFilter<String> bloomFilter) {\n        List<WtGame> games = gameDao.selectList(null);\n        for(WtGame game : games) {\n            String key = RedisKeyUtil.getGameKey(game.getId());\n            redisUtil.set(key, game);\n\n            // 存储到布隆过滤器\n            bloomFilter.put(String.valueOf(game.getId()));\n        }\n    }\n}\n\n```\n\n定时刷新重置，解决布隆过滤器无法删除元素的问题\n\n```java\npackage com.weteam.portal.task;\n\nimport com.google.common.hash.BloomFilter;\nimport com.google.common.hash.Funnels;\nimport com.weteam.common.exception.DefaultExceptionHandler;\nimport com.weteam.portal.config.BloomFilterConfig;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.data.redis.core.RedisTemplate;\nimport org.springframework.scheduling.annotation.Scheduled;\nimport org.springframework.stereotype.Component;\n\n\n/**\n * 布隆过滤器定时任务\n */\n@Component\npublic class BloomFilterTasks {\n\n    private static Logger log = LoggerFactory.getLogger(DefaultExceptionHandler.class);\n\n    @Autowired\n    private BloomFilterConfig bloomFilterConfig;\n    @Autowired\n    private BloomFilter<String> gameBloomFilter;\n\n    @Scheduled(cron = \"0 0 0 * * ?\") // 每天凌晨0点执行\n    public void resetBloomFilter() {\n        log.info(\"===resetBloomFilter===\");\n        // 创建一个新的布隆过滤器实例来替代旧的过滤器对象\n        BloomFilter<String> newBloomFilter = bloomFilterConfig.createBloomFilter();\n        bloomFilterConfig.loadBloomFilterGameData(newBloomFilter);\n        gameBloomFilter = newBloomFilter;\n    }\n}\n\n```\n\n业务中使用布隆过滤器\n\n```java\n@RestController\n@RequestMapping(\"/games\")\npublic class WtGameController implements WeTeamConstant {\n    @Autowired\n    private BloomFilter<String> gameBloomFilter;\n  \n    @GetMapping(\"/testGameBloomFilter/{id}\")\n    public CommonResult<?> testGameBloomFilter(@PathVariable int id) {\n        // 用布隆判断缓存是否存在\n        boolean flag = gameBloomFilter.mightContain(String.valueOf(id));\n      \n        // 存在则去缓存中查， 不存在则去数据库中查\n      \tif(flag) {\n          \n        } else {\n          \n        }\n        return CommonResult.success(b);\n    }\n}\n```\n\n\n\n参考\n\n-   [SpringBoot中布隆过滤器的使用](https://blog.csdn.net/m0_52256357/article/details/126386755)\n-   [SpringBoot + Redis实现布隆过滤器](https://juejin.cn/post/7075115527219183646)\n-   [如何在springboot项目中redis使用布隆过滤器防止缓存穿透](https://blog.csdn.net/weixin_43748936/article/details/110225696?spm=1001.2101.3001.6650.4&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4-110225696-blog-115405043.235%5Ev36%5Epc_relevant_default_base3&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4-110225696-blog-115405043.235%5Ev36%5Epc_relevant_default_base3&utm_relevant_index=5)","timestamp":1693737620936},{"name":"05-redis实践.md","path":"007-Redis/001-实践/05-redis实践.md","content":"[参考](https://mp.weixin.qq.com/s/I3fKeerhggozvx9FOUchpA)\n\nhttps://www.bmabk.com/index.php/post/126637.html\n\n\n\n### 1、缓存\n\nString类型\n\n例如：热点数据缓存（例如报表、明星出轨），对象缓存、全页缓存、可以提升热点数据的访问数据。\n\n### 2、数据共享分布式\n\nString 类型，因为 Redis 是分布式的独立服务，可以在多个应用之间共享\n\n例如：分布式Session\n\n```\n<dependency> \n\n <groupId>org.springframework.session</groupId> \n\n <artifactId>spring-session-data-redis</artifactId> \n\n</dependency>\n```\n\n### 3、分布式锁\n\nString 类型setnx方法，只有不存在时才能添加成功，返回true\n\n```\npublic static boolean getLock(String key) {\n\n    Long flag = jedis.setnx(key, \"1\");\n\n    if (flag == 1) {\n\n        jedis.expire(key, 10);\n\n    }\n\n    return flag == 1;\n\n}\n\n\n\n\npublic static void releaseLock(String key) {\n\n    jedis.del(key);\n\n}\n```\n\n### 4、全局ID\n\nint类型，incrby，利用原子性\n\nincrby userid 1000\n\n分库分表的场景，一次性拿一段\n\n### 5、计数器\n\nint类型，incr方法\n\n例如：文章的阅读量、微博点赞数、允许一定的延迟，先写入Redis再定时同步到数据库\n\n### 6、限流\n\nint类型，incr方法\n\n以访问者的ip和其他信息作为key，访问一次增加一次计数，超过次数则返回false\n\n### 7、位统计\n\nString类型的bitcount（1.6.6的bitmap数据结构介绍）\n\n字符是以8位二进制存储的\n\n```\nset k1 a\n\nsetbit k1 6 1\n\nsetbit k1 7 0\n\nget k1 \n\n/* 6 7 代表的a的二进制位的修改\n\na 对应的ASCII码是97，转换为二进制数据是01100001\n\nb 对应的ASCII码是98，转换为二进制数据是01100010\n\n\n\n\n因为bit非常节省空间（1 MB=8388608 bit），可以用来做大数据量的统计。\n\n*/\n```\n\n例如：在线用户统计，留存用户统计\n\n```\nsetbit onlineusers 01 \n\nsetbit onlineusers 11 \n\nsetbit onlineusers 20\n```\n\n支持按位与、按位或等等操作\n\n```\nBITOPANDdestkeykey[key...] ，对一个或多个 key 求逻辑并，并将结果保存到 destkey 。       \n\nBITOPORdestkeykey[key...] ，对一个或多个 key 求逻辑或，并将结果保存到 destkey 。 \n\nBITOPXORdestkeykey[key...] ，对一个或多个 key 求逻辑异或，并将结果保存到 destkey 。 \n\nBITOPNOTdestkeykey ，对给定 key 求逻辑非，并将结果保存到 destkey 。\n```\n\n计算出7天都在线的用户\n\n```\nBITOP \"AND\" \"7_days_both_online_users\" \"day_1_online_users\" \"day_2_online_users\" ...  \"day_7_online_users\"\n```\n\n### 8、购物车\n\nString 或hash。所有String可以做的hash都可以做\n\n![图片](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/06/02/19345116857056911685705691915fwYL7h-640.png)\n\n-   key：用户id；field：商品id；value：商品数量。\n-   +1：hincr。-1：hdecr。删除：hdel。全选：hgetall。商品数：hlen。\n\n### 9、用户消息时间线timeline\n\nlist，双向链表，直接作为timeline就好了。插入有序\n\n### 10、消息队列\n\nList提供了两个阻塞的弹出操作：blpop/brpop，可以设置超时时间\n\n-   blpop：blpop key1 timeout 移除并获取列表的第一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。\n-   brpop：brpop key1 timeout 移除并获取列表的最后一个元素，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。\n\n上面的操作。其实就是java的阻塞队列。学习的东西越多。学习成本越低\n\n-   队列：先进先出：rpush blpop，左头右尾，右边进入队列，左边出队列\n-   栈：先进后出：rpush brpop\n\n### 11、抽奖\n\n自带一个随机获得值\n\n```\nspop myset\n```\n\n### 12、点赞、签到、打卡\n\n![图片](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/06/02/193520168570572016857057209263ZKRq8-640-20230602193520841.png)图\n\n假如上面的微博ID是t1001，用户ID是u3001\n\n用 like:t1001 来维护 t1001 这条微博的所有点赞用户\n\n-   点赞了这条微博：sadd like:t1001 u3001\n-   取消点赞：srem like:t1001 u3001\n-   是否点赞：sismember like:t1001 u3001\n-   点赞的所有用户：smembers like:t1001\n-   点赞数：scard like:t1001\n\n是不是比数据库简单多了。\n\n### 13、商品标签\n\n![图片](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/06/02/19355116857057511685705751784N4FgCX-640-20230602193551696.png)图片\n\n老规矩，用 tags:i5001 来维护商品所有的标签。\n\n-   sadd tags:i5001 画面清晰细腻\n-   sadd tags:i5001 真彩清晰显示屏\n-   sadd tags:i5001 流程至极\n\n### 14、商品筛选\n\n```\n// 获取差集\n\nsdiff set1 set2\n\n// 获取交集（intersection ）\n\nsinter set1 set2\n\n// 获取并集\n\nsunion set1 set2\n```\n\n![图片](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/06/02/19355916857057591685705759629O9bgvR-640-20230602193559540.png)\n\n假如：iPhone11 上市了\n\n```\nsadd brand:apple iPhone11\n\n\n\n\nsadd brand:ios iPhone11\n\n\n\n\nsad screensize:6.0-6.24 iPhone11\n\n\n\n\nsad screentype:lcd iPhone 11\n```\n\n筛选商品，苹果的、ios的、屏幕在6.0-6.24之间的，屏幕材质是LCD屏幕\n\n```\nsinter brand:apple brand:ios screensize:6.0-6.24 screentype:lcd\n```\n\n### 15、用户关注、推荐模型\n\nfollow 关注 fans 粉丝\n\n相互关注：\n\n-   sadd 1:follow 2\n-   sadd 2:fans 1\n-   sadd 1:fans 2\n-   sadd 2:follow 1\n\n我关注的人也关注了他(取交集)：\n\n-   sinter 1:follow 2:fans\n\n可能认识的人：\n\n-   用户1可能认识的人(差集)：sdiff 2:follow 1:follow\n-   用户2可能认识的人：sdiff 1:follow 2:follow\n\n### 16、排行榜\n\nid 为6001 的新闻点击数加1：\n\n```\nzincrby hotNews:20190926 1 n6001\n```\n\n获取今天点击最多的15条：\n\n```\nzrevrange hotNews:20190926 0 15 withscores\n```\n\n![图片](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/06/02/193635168570579516857057951871prZUh-640-20230602193635086.png)","timestamp":1693737620936},{"name":"06-数据库和缓存双写一致性问题.md","path":"007-Redis/001-实践/06-数据库和缓存双写一致性问题.md","content":"## 3种常用的缓存读写策略\n\n```\n(1) Cache Aside Pattern（旁路缓存模式）\n(2) Read/Write Through Pattern（读写穿透）\n(3) Write Behind Pattern（异步缓存写入）\n```\n\n### Cache Aside Pattern（旁路缓存模式）\n\n![img](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/19/11485216924169321692416932252IjV7I7-cache-aside-read.png)\n\n```\n是我们平时使用比较多的一个缓存读写模式，比较适合读请求比较多的场景。\n\n读：\n- 先读缓存，有则直接返回\n- 没有缓存，从db加载，再存入缓存\n\n写：\n- 先更新数据库，再删缓存\n```\n\n###  Read/Write Through Pattern（读写穿透）\n\n```\n把 cache 视为主要数据存储，从中读取数据并将数据写入其中。cache 服务负责将此数据读取和写入 db，从而减轻了应用程序的职责。\n\n读 （与旁路缓存相同）\n- 先读缓存，有则直接返回\n- 没有缓存，从db加载，在写缓存\n\n写\n- 先查缓存，缓存不存在，直接更新db\n- 缓存存在，则更新缓存，然后缓存服务器自己更新db（同步更新 cache 和 db）\n```\n\n### Write Behind Pattern（异步缓存写入）\n\n```\n与「读写穿透」很相似，两者都是由 cache 服务来负责 cache 和 db 的读写。\n\n区别：\n- 读写穿透： 同步更新 cache 和 db\n- 异步缓存写入： 只更新缓存，不直接更新 db，而是改为异步批量的方式来更新 db。\n\n问题：\n对数据一致性带来了更大的挑战，比如 cache 数据可能还没异步更新 db 的话，cache 服务可能就就挂掉了。\n\n应用场景：\n- 消息队列中消息的异步写入磁盘、\n- MySQL 的 Innodb Buffer Pool 机制\n\n优点：\n- db 的写性能非常高，非常适合一些数据经常变化又对数据一致性要求没那么高的场景，比如浏览量、点赞量。\n```\n\n参考\n\n-   [3种常用的缓存读写策略详解](https://javaguide.cn/database/redis/3-commonly-used-cache-read-and-write-strategies.html)\n-   [美团二面：Redis与MySQL双写一致性如何保证？](https://mp.weixin.qq.com/s?__biz=Mzg3NzU5NTIwNg==&mid=2247490243&idx=1&sn=ff11c3aab9ada3b16d7f2b57c846d567&chksm=cf21c5eaf8564cfc59e3d0d56fd02b0f5513015005f498381be4d12db462442a49aabe4159ef&token=1495321435&lang=zh_CN&scene=21#wechat_redirect)\n\n\n\n\n\n## 问题背景\n\n使用缓存的常见方式\n\n```\n用户请求过来之后，先查缓存有没有数据，如果有则直接返回。\n如果缓存没数据，再继续查数据库。\n如果数据库有数据，则将查询出来的数据，放入缓存中，然后返回该数据。\n如果数据库也没数据，则直接返回空。\n```\n\n<img src=\"https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/06/06/10015016860169101686016910255xZYvGL-640.png\" alt=\"图片\" style=\"zoom:50%;\" />\n\n存在的问题：\n\n```\n如果数据库中的某条数据，放入缓存之后，又立马被更新了，那么该如何更新缓存呢？\n\n不更新缓存行不行？\n答：当然不行，如果不更新缓存，在很长的一段时间内（决定于缓存的过期时间），用户请求从缓存中获取到的都可能是旧值，而非数据库的最新值。这不是有数据不一致的问题？\n```\n\n更新缓存的4种方案\n\n```\n先写缓存，再写数据库\n先写数据库，再写缓存\n先删缓存，再写数据库\n先写数据库，再删缓存\n```\n\n## 更新缓存方式\n\n### 1 先写缓存，再写数据库\n\n#### 问题1：写数据库失败\n\n```\n某一个用户的每一次写操作，如果刚写完缓存，突然网络出现了异常，导致写数据库失败了，缓存就变成脏数据了\n```\n\n#### 问题2: 高并发问题 「写 + 写」\n\n![图片](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/07/16323216913971521691397152901apgCcz-454a8228a6549176ad7e0484fba3c92b.png)\n\n### 2 先写数据库，再写缓存\n\n#### 问题1：写缓存失败\n\n```\n在写缓存过程中，出现网络异常导致写缓存失败\n数据库数据已更新，但缓存中还是旧值\n```\n\n#### 问题2：高并发下的问题「写 + 写」\n\n<img src=\"https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/07/16315616913971161691397116319PcRbDl-8febac10b14bed16cb96d1d944cd08da.png\" alt=\"图片\" style=\"zoom:50%;\" />\n\n假设在高并发的场景中，针对同一个用户的同一条数据，有两个写数据请求：a和b，它们同时请求到业务系统。\n\n其中请求a获取的是旧数据，而请求b获取的是新数据，如下图所示：\n\n<img src=\"https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/06/06/101057168601745716860174573311V2LXi-640-20230606101057189.png\" alt=\"图片\" style=\"zoom:50%;\" />\n\n1.  请求a先过来，刚写完了数据库。但由于网络原因，卡顿了一下，还没来得及写缓存。\n2.  这时候请求b过来了，先写了数据库。\n3.  接下来，请求b顺利写了缓存。\n4.  此时，请求a卡顿结束，也写了缓存。\n\n很显然，在这个过程当中，请求b在缓存中的`新数据`，被请求a的`旧数据`覆盖了。\n\n也就是说：在高并发场景中，如果多个线程同时执行先写数据库，再写缓存的操作，可能会出现数据库是新值，而缓存中是旧值，两边数据不一致的情况。\n\n#### 问题3：浪费系统资源\n\n```\n对于写多读少的业务，每次写操作都需要写缓存，比较浪费系统资源。\n```\n\n### 3 先删缓存，再写数据库\n\n#### 问题1：「写+读」并发问题（未写就读）\n\n<img src=\"https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/07/16353016913973301691397330391pr2kJd-cc208c2931b4e889d1a58cb655537767.png\" alt=\"图片\" style=\"zoom:50%;\" />\n\n假设在高并发的场景中，同一个用户的同一条数据，有一个读数据请求c，还有另一个写数据请求d（一个更新操作），同时请求到业务系统。如下图所示：\n\n<img src=\"https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/06/06/10193316860179731686017973114G7KgaY-image-20230606101932996.png\" alt=\"image-20230606101932996\" style=\"zoom:50%;\" />\n\n```\n请求d先过来，把缓存删除了。但由于网络原因，卡顿了一下，还没来得及写数据库。\n这时请求c过来了，先查缓存发现没数据，再查数据库，有数据，但是旧值。\n请求c将数据库中的旧值，更新到缓存中。\n此时，请求d卡顿结束，把新值写入数据库。\n\n总结：d删完缓存没写完数据库c就已经读数据了，读的就是mysql的旧值并存到缓存中\n```\n\n\n\n#### 改进：延迟双删\n\n```\n写数据库之前删除一次，写完数据库后，延迟再删除一次。\n\n流程：（请求d-写操作，请求c-读操作）\n请求d先过来，把缓存删除了。但由于网络原因，卡顿了一下，还没来得及写数据库。\n这时请求c过来了，先查缓存发现没数据，再查数据库，有数据，但是旧值。\n请求c将数据库中的旧值，更新到缓存中。\n此时，请求d卡顿结束，把新值写入数据库。\n一段时间之后，比如：500ms，请求d将缓存删除。\n```\n\n#### 为什么一定要间隔一段时间之后，才能删除缓存呢？\n\n\n\n```\n请求d卡顿结束，把新值写入数据库后，请求c将数据库中的旧值，更新到缓存中。\n此时，如果请求d删除太快，在请求c将数据库中的旧值更新到缓存之前，就已经把缓存删除了，这次删除就没任何意义。必须要在请求c更新缓存之后，再删除缓存，才能把旧值及时删除了。\n所以需要在请求d中加一个时间间隔，确保请求c，或者类似于请求c的其他请求，如果在缓存中设置了旧值，最终都能够被请求d删除掉。\n```\n\n#### 问题2: 第二次删除缓存失败\n\n```\n下方：缓存删除失败\n```\n\n\n\n### 4 先写数据库，再删缓存\n\n在高并发的场景中，有一个读数据请求，有一个写数据请求，更新过程如下：\n\n1.  请求e先写数据库，由于网络原因卡顿了一下，没有来得及删除缓存。\n2.  请求f查询缓存，发现缓存中有数据，直接返回该数据。\n3.  请求e删除缓存。\n\n在这个过程中，只有请求f读了一次旧数据，后来旧数据被请求e及时删除了，看起来问题不大。\n\n但如果是读数据请求先过来呢？\n\n1.  请求f查询缓存，发现缓存中有数据，直接返回该数据。\n2.  请求e先写数据库。\n3.  请求e删除缓存。\n\n这种情况看起来也没问题呀？\n\n#### 问题1: 「读+写」并发问题\n\n在实际中，这个问题出现的概率并不高** 因为缓存的写入通常要远远快于数据库的写入\n\n![图片](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/07/16372416913974441691397444937NW2Zql-1cc7401143e79383ead96582ac11b615.png)\n\n#### 问题2: 缓存删除失败\n\n```\n\n```\n\n\n\n### 缓存删除失败\n\n### 定时任务\n\n```\n删除失败就加入定时任务列表\n```\n\n#### 增加重试机制\n\n```\n在接口中如果更新了数据库成功了，但更新缓存失败了，可以立刻重试3次。如果其中有任何一次成功，则直接返回成功。如果3次都失败了，则写入数据库，准备后续再处理。\n当然，如果你在接口中直接同步重试，该接口并发量比较高的时候，可能有点影响接口性能。\n```\n\n#### 改进：异步重试 - 消息队列\n\n![图片](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/07/16460316913979631691397963937bRXWVk-640.png)\n\n```\n（1）当用户操作写完数据库，但删除缓存失败了，产生一条mq消息，发送给mq服务器。\n（2）mq消费者读取mq消息，重试5次删除缓存。如果其中有任意一次成功了，则返回成功。如果重试了5次，还是失败，则写入死信队列中。\n（3）推荐mq使用rocketmq，重试机制和死信队列默认是支持的。使用起来非常方便，而且还支持顺序消息，延迟消息和事务消息等多种业务场景。\n\nhttps://mp.weixin.qq.com/s/DsZgnwIqW3jrE5KxShGKeg\n```\n\n#### 监听binlog \n\n为什么\n\n```\n（1）在使用定时任务的方案中，需要在业务代码中增加额外逻辑，如果删除缓存失败，需要将数据写入重试表。\n（2）使用mq的方案中，如果删除缓存失败了，需要在业务代码中发送mq消息到mq服务器。\n（3）更优雅的实现，即监听binlog\n```\n\n`canal`等中间件\n\n![图片](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/07/16513716913982971691398297573N41sxJ-640-20230807165137443.png)\n\n```\n（1）在业务接口中写数据库之后，就不管了，直接返回成功。\n（2）mysql服务器会自动把变更的数据写入binlog中。\n（3）binlog订阅者获取变更的数据，然后删除缓存。\n\n如果删除失败，则用前文的重试机制\n```\n\n![图片](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/07/16522316913983431691398343280ya4mjs-640-20230807165223151.png)\n\n\n\n## 其他\n\n### 为什么是删除缓存，而不是更新缓存呢？\n\n```\n（1）删除一个数据，相比更新一个数据更加轻量级，出问题的概率更小。\n（2）在实际业务中，缓存的数据可能不是直接来自数据库表，也许来自多张底层数据表的聚合。\n\n\nhttps://xiaolincoding.com/redis/architecture/mysql_redis_consistency.html#读者提问\n```\n\n### Canal 中间件\n\n```\n阿里巴巴开源的 Canal 中间件\n\nCanal 模拟 MySQL 主从复制的交互协议，把自己伪装成一个 MySQL 的从节点，向 MySQL 主节点发送 dump 请求，MySQL 收到请求后，就会开始推送 Binlog 给 Canal，Canal 解析 Binlog 字节流之后，转换为便于读取的结构化数据，供下游程序订阅使用。\n\nhttps://xiaolincoding.com/redis/architecture/mysql_redis_consistency.html#如何保证两个操作都能执行成功\n```\n\ncanal的工作原理\n\n<img src=\"https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/07/16571516913986351691398635006rx6QO2-2ee2280e9f59b6b4879ebdec6eb0cf52.png\" alt=\"图片\" style=\"zoom:50%;\" />\n\n\n\n### 参考\n\n-   [如何保证数据库和缓存双写一致性？](https://mp.weixin.qq.com/s/DsZgnwIqW3jrE5KxShGKeg)\n-   [江南一点雨：如何保证缓存和数据库的一致性？](https://mp.weixin.qq.com/s/7-vUDQGj8mZIeryZA3gEiw)\n-   [数据库和缓存如何保证一致性？](https://xiaolincoding.com/redis/architecture/mysql_redis_consistency.html#如何保证两个操作都能执行成功)\n-   [田螺：Redis与MySQL双写一致性如何保证？](https://mp.weixin.qq.com/s?__biz=Mzg3NzU5NTIwNg==&mid=2247490243&idx=1&sn=ff11c3aab9ada3b16d7f2b57c846d567&chksm=cf21c5eaf8564cfc59e3d0d56fd02b0f5513015005f498381be4d12db462442a49aabe4159ef&token=1495321435&lang=zh_CN&scene=21#wechat_redirect)","timestamp":1693737620936},{"name":"07-缓存穿透、缓存击穿、缓存雪崩.md","path":"007-Redis/001-实践/07-缓存穿透、缓存击穿、缓存雪崩.md","content":"\n\n| 概念 |    **关键**     | **含义**                                                     | **解决方案**                                                 |\n| :--------: | :-------------: | :----------------------------------------------------------- | :----------------------------------------------------------- |\n|  缓存雪崩  |   Key集体失效   | 某个时间点，缓存中的Key集体发生过期失效致使大量查询数据库的请求都落在DB上，导致DB负载过高 | 不同时失效：为Key设置不同的、随机TTL，错开缓存中的Key的失效时间点，减少DB压力 |\n|  缓存穿透  | 缓存查询不到Key | 缓存中查询不到Key，导致直接查询DB                            | 缓存空值+过期时间                                            |\n|  缓存击穿  |   热点Key失效   | 热点Key（被频繁访问的Key）突然失效，持续的高并发击穿缓存，直接请求DB，导致DB压力在瞬间暴增。 | 热点数据不过期互斥锁                                         |\n\n\n\n![图片](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/07/13572616913878461691387846896Em9vZA-061e2c04e0ebca3425dd75dd035b6b7b.png)\n\n## 缓存穿透\n\n### 是什么\n\n```\n缓存中无法缓存某个key值（数据库中不存在），但大量请求访问这个key值，导致这些请求绕过缓存系统，直接访问数据库\n比如请求 id < 0 的数据\n\n（与缓存击穿的区别是：缓存穿透中，这个key永远也不会存在）\n```\n\n### 出现场景\n\n```\n（1）查询不存在的数据：比如查询id<1的数据，或者数据库中不存在的数据\n```\n\n### 解决方案：\n\n```\n（1）非法请求的限制。判断求请求参数是否合理，请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。\n（2）缓存空值：如果一个查询返回的数据为空（不管是数据是否不存在），我们仍然把这个空结果（null）进行缓存，设置空结果的过期时间会很短，最长不超过五分钟。\n（3）布隆过滤器：使用布隆过滤器来过滤掉非法或无效的请求，如果请求数据不存在于布隆过滤器中，则直接拦截该请求，避免绕过缓存。\n```\n\n#### 实现：缓存空值\n\n```java\n @GetMapping(\"/penetrate\")\n    public String cachePenetrate(Integer id) {\n        String cacheKey = \"penetrate:\" + id;\n        long cacheTime = 30L;\n\n        //缓存查询\n        String cacheValue = (String) redisTemplate.opsForValue().get(cacheKey);\n        if (cacheValue == null) {\n            //缓存没有，查询数据库\n            Product product = productService.getById(id);\n            if (product == null) {\n                //数据库没有，设置空值或默认值\n                cacheValue = \"\";\n            } else {\n                cacheValue = product.getName();\n            }\n            redisTemplate.opsForValue().set(cacheKey, cacheValue, cacheTime, TimeUnit.SECONDS);\n        }\n\n        return cacheValue;\n    }\n```\n\n#### 缓存空值的时间如何设置\n\n```\n一般来说，空值缓存的时间可以设置为一个较短的时间，但也要根据业务的实际情况来调整。\n（1）较短时间。\n（2）与实际数据有效期相同\n（3）永久有效：这样做可以避免频繁地查询后端系统，但需要注意及时处理实际数据的更新，避免因为数据的变动而导致缓存的不一致。\n```\n\n#### 缓存空值明显比使用布隆过滤器要简单得多，所以为什么不都用缓存空值方法呢？\n\n```\n使用缓存空值来解决缓存穿透问题确实是一种简单有效的方法，但它并不适用于所有场景。下面是一些考虑因素：\n\n  1 缓存空值会占用一定的内存空间。如果缓存的键空间非常大或者频繁出现缓存穿透的情况，可能会导致大量的空值占用内存，从而浪费资源。\n  2 缓存空值可能引起数据不一致。如果在缓存中存储了空值，并且在数据库中实际上存在该数据，那么在缓存失效之前，应用程序仍然会获取到空值，从而导致数据不一致的问题。\n  3 缓存空值可能增加了开发和维护的复杂性。在实现缓存空值的处理逻辑时，需要特别注意维护缓存和数据库的一致性。如果在业务逻辑中存在复杂的查询和更新操作，可能需要更复杂的处理方式来保证数据的一致性。\n\n相比之下，布隆过滤器是一种更通用和可靠的解决方案，可以有效地过滤掉不存在于数据库中的数据，从而减轻数据库的压力。虽然布隆过滤器的实现和维护可能相对复杂一些，但它具有较低的内存占用和较高的查询效率，适用于大规模的数据集和高并发场景。\n\n选择使用缓存空值还是布隆过滤器，需要根据具体的业务需求和系统特点进行综合考虑。如果系统数据量较小，且缓存穿透问题较为频繁且明显，可以考虑使用缓存空值。如果系统数据量较大，或者需要更精确地控制缓存的一致性和效率，布隆过滤器是更好的选择。\n```\n\n#### 一般什么样的业务才需要考虑缓存穿透问题？\n\n```\n【答缓存穿透出现的场景，同上方】\n\n缓存穿透问题通常在以下情况下需要考虑：\n\n查询不存在的数据：当频繁查询一些不存在的数据时，如果每次都直接查询数据库，会对数据库造成无谓的压力，同时还会占用系统资源。例如，用户输入错误的ID进行查询、恶意攻击等。\n\n数据库中无效的数据：某些数据在数据库中被标记为无效或已删除状态，但仍然频繁查询这些数据，会浪费数据库资源。通过缓存来避免频繁查询无效数据，可以提高系统性能和资源利用率。\n\n高并发场景：在高并发场景下，如果大量请求同时查询同一份数据，而该数据不在缓存中，会导致这些请求都穿透到数据库，增加数据库的负载压力。在这种情况下，需要防止缓存穿透，避免对数据库造成过大压力。\n\n总之，当存在频繁查询不存在的数据、查询无效数据或高并发场景下，就需要考虑缓存穿透问题。通过合理的缓存策略和技术手段，如布隆过滤器、缓存空值等，可以有效地避免缓存穿透问题，提高系统性能和资源利用率。\n```\n\n\n\n\n\n\n\n\n\n\n\n## 缓存击穿 [*]\n\n### 是什么\n\n```\n缓存中存在某个热点数据，在过期时有大量并发请求访问这个key，发现过期后直接访问数据库，从而给数据源造成巨大压力，甚至导致数据源崩溃的情况。\n\n（与缓存穿透的区别是：缓存穿透中，这个key永远也不会存在）\n```\n\n### 出现场景\n\n```\n（1）热点数据：热点数据过期，大量并发请求访问\n（2）请求穿透：缓存不存在，大量并发请求访问\n```\n\n### 解决方案\n\n```\n可以认为缓存击穿是缓存雪崩的一个子集。\n\n防过期：\n（1）设置key永不过期（或者逻辑过期）。对于一些热点数据，可以将其缓存的过期时间设置为永不过期。这样即使缓存失效，也能够在下一次请求中重新加载到缓存中，减轻数据源的压力。\n（2）互斥锁。在缓存失效的时候，通过互斥锁来保证只有一个线程可以访问数据源并重新加载缓存。其他线程等待锁释放后，直接从缓存中获取数据。这种方式可以避免多个线程同时访问数据源，减少数据源的压力。\n\n防数据不存在：\n（1）提前预加载：可以在系统启动时或者低峰期预先加载一部分热门数据到缓存中，提前占位，避免大量请求同时访问缓存失效的情况。\n（2）校验接口：使用布隆过滤器，判断请求的数据是否存在于缓存中，从而避免对于不存在的数据频繁访问后端数据库。\n（3）限流\n```\n\n设置热点数据永不过期，为什么还会出现缓存失效?\n\n```\n当我们将热点数据的缓存设置为永不过期时，意味着该数据在缓存中将一直存在，不会因为过期时间而被自动删除。但是，仍然有可能出现缓存失效的情况，这可能是由于以下原因：\n\n1 服务器重启或缓存系统重启：当服务器或缓存系统重启时，缓存数据会被清空，包括热点数据。即使设置了永不过期，重启后仍然需要重新加载数据到缓存中。\n\n2 内存不足或缓存溢出：如果缓存系统的内存不足，可能会导致部分数据被淘汰或清除，包括热点数据。在这种情况下，即使数据设置为永不过期，仍然可能出现缓存失效的情况。\n\n3 数据变更或过期检查错误：有些缓存系统可能会对缓存数据进行过期检查，并在一定时间内重新加载数据。如果过期检查的逻辑有误，可能会错误地将热点数据标记为过期，并清除缓存。\n\n4 分布式缓存环境下的数据同步问题：在分布式缓存环境中，多个缓存节点可能存在数据不一致的情况。即使设置了永不过期，如果数据在某个节点上被删除或更新，其他节点可能无法感知，导致缓存失效。\n\n综上所述，尽管将热点数据设置为永不过期可以延长其在缓存中的存储时间，但仍然需要注意上述情况可能导致缓存失效的情况。因此，在实际应用中，除了设置永不过期外，还需要考虑缓存的持久性、容错性和一致性等因素，结合具体的业务场景和缓存系统的特点，制定合适的缓存策略和失效处理机制。\n```\n\n一般什么样的业务才需要考虑缓存击穿问题？\n\n```\n缓存击穿问题通常在以下情况下需要考虑：\n\n热点数据访问频繁：某些数据在系统中被频繁访问，例如热门商品、热门新闻等。由于大量并发请求同时访问该数据，可能导致缓存失效，从而导致数据库被频繁查询，增加数据库压力。\n\n数据库性能较低：如果数据库性能较低或存在较高的延迟，频繁查询数据库可能会导致系统响应变慢。在这种情况下，使用缓存可以显著提升系统的响应速度。\n\n大规模数据查询：当进行大规模数据查询时，如数据报表生成、数据分析等，如果每次都直接查询数据库，会对数据库造成较大压力。通过缓存可以减轻数据库的负载，提高查询性能。\n\n外部接口调用：如果系统依赖外部接口，而外部接口的响应时间较长，频繁调用可能会导致系统的响应变慢。通过缓存可以缓解对外部接口的频繁调用，提高系统的性能和可靠性。\n\n总之，任何访问频繁且对性能要求较高的业务都可能面临缓存击穿问题。在这些情况下，合理地使用缓存策略可以提高系统性能和可靠性，并降低数据库压力。\n```\n\n\n\n#### 逻辑过期：双缓存\n\n缓存标记：记录缓存数据是否过期，如果过期就去更新实际key的缓存；\n缓存数据：它的过期时间比缓存标记的时间延长1倍。这样，当缓存标记过期后，实际缓存还能把旧数据返回给调用端，直到新的key值更新完成后，才会返回新缓存\n\n```java\n    @GetMapping(\"/avalanche2\")\n    public String cacheAvalanche2(Integer id) {\n        String cacheKey = \"avalanche:\" + id;\n        String signKey = \"avalanche:sign\" + id;\n        long cacheTime = 60L;\n\n        //缓存查询\n        String cacheValue = (String) redisTemplate.opsForValue().get(cacheKey);\n        //缓存标记\n        String signValue = (String) redisTemplate.opsForValue().get(signKey);\n        if (signValue == null) {\n            //缓存标记过期\n            //设置成功的去查询数据库并更新缓存，其余的返回旧的缓存值(缓存值的时间是缓存标记的2倍)\n            if (redisTemplate.opsForValue().setIfAbsent(signKey, \"1\", cacheTime, TimeUnit.SECONDS)) {\n                //查询数据库\n                Product product = productService.getById(id);\n                cacheValue = product.getName();\n                redisTemplate.opsForValue().set(cacheKey, cacheValue, cacheTime * 2, TimeUnit.SECONDS);\n            }\n        }\n\n        return cacheValue;\n    }\n```\n\n参考\n\n-   [springboot：整合redis解决缓存击穿，缓存雪崩，缓存穿透](https://blog.csdn.net/weixin_43296313/article/details/125447527)\n\n\n\n#### 逻辑过期 + 互斥锁\n\n设置较长的过期时间替代永不过期，过期时通过加锁查询\n\n```java\n@GetMapping(\"/testRedisLock/{id}\")\npublic CommonResult<?> testRedisLock(@PathVariable int id) {\n    WtGame game = gameService.findById(id);\n    return CommonResult.success(game);\n}\n```\n\n```java\n  @Override\n    public WtGame findById(int gameId) {\n        WtGame game = null;\n        // 尝试从缓存中获取\n        String gameKey = RedisKeyUtil.getGameKey(gameId);\n        game = (WtGame) redisUtil.get(gameKey);\n        if(game != null) {\n            if(game.getId() == null) {\n                System.out.println(\"缓存为空\");\n                return null;\n            }\n            System.out.println(\"从缓存中获取\");\n            return game;\n        }\n\n        // 无缓存, 加锁查询\n        String requestId = String.valueOf(gameId + Thread.currentThread().getId());\n        String lockKey = LOCK_GAME_KEY + gameId;\n        boolean isLock = redisLock.tryLock(lockKey, requestId, Duration.ofSeconds(1));\n        try {\n            // 获取锁失败：休眠，重试\n            if(!isLock) {\n                Thread.sleep(100);\n                return findById(gameId);\n            }\n\n            // 获取成功, 查询数据库\n            game = gameDao.selectById(gameId);\n            System.out.println(\"从数据库中获取\" + game);\n            if(game == null) {\n                redisUtil.set(gameKey, new WtGame(), 30);\t\t// 存短期空值，避免其他阻塞请求查询数据库\n            } else {\n                redisUtil.set(gameKey, game);\n            }\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        } finally {\n            // 释放锁\n            redisLock.unlock(lockKey, requestId);\n        }\n\n        return game;\n    }\n```\n\n\n\n参考\n\n-   [Redis缓存击穿解决方案之互斥锁](https://juejin.cn/post/7096734273210122253)\n-   [高性能缓存实践-解决缓存击穿-单应用互斥锁](https://blog.csdn.net/qq_28817739/article/details/108973154)\n\n## 缓存雪崩\n\n### 是什么\n\n```\n缓存中大量数据失效，导致大量请求直接访问后端数据库，给数据库带来巨大压力，甚至崩溃\n\n跟缓存击穿不一样，雪崩是大量key集体过期\n```\n\n### 出现场景\n\n```\n（1）缓存集体失效\n（2）缓存服务器宕机\n```\n\n### 解决方案\n\n```\n缓存集体失效：\n（1）key不集体失效。在原有的失效时间基础上增加一个随机值，减少集体失效\n（2）互斥锁。如果发现访问的数据不在 Redis 里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存，当缓存构建完成后，再释放锁。未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。\n（3）缓存不过期，后台更新缓存值。缓存的更新交由后台线程定时更新。\n\n\nRedis 故障宕机\n（1）服务熔断或请求限流机制；\n（2）构建 Redis 缓存高可靠集群；\n```\n\n方案：实现加锁排队\n\n采用加锁排队有可能还要解决分布式锁的问题，线程还会被阻塞，用户体验很差\n\n```java\n@GetMapping(\"/avalanche\")\n    public String cacheAvalanche(Integer id) {\n        String cacheKey = \"avalanche:\" + id;\n        long cacheTime = 30L;\n\n        //缓存查询\n        String cacheValue = (String) redisTemplate.opsForValue().get(cacheKey);\n        if (cacheValue == null) {\n            //缓存没有，使用互斥锁查询数据库更新缓存，其余阻塞排队\n            synchronized (cacheKey) {\n                //此时可能有缓存数据了\n                cacheValue = (String) redisTemplate.opsForValue().get(cacheKey);\n                if (cacheValue == null) {\n                    //缓存还是没有，查询数据库\n                    Product product = productService.getById(id);\n                    cacheValue = product.getName();\n                    //回设缓存\n                    redisTemplate.opsForValue().set(cacheKey, cacheValue, cacheTime * 10, TimeUnit.SECONDS);\n                }\n            }\n        }\n\n        return cacheValue;\n    }\n```\n\n### 问题\n\n#### 缓存不过期，数据会一直存在内存中吗？\n\n```\n不过期并不意味值一直存在缓存中，当系统内存紧张时，有些缓存数据就会被淘汰。而在缓存被“淘汰”到下一次后台定时更新缓存的这段时间内，业务线程读取缓存失败就返回空值，业务的视角就以为是数据丢失了。\n\n存在的问题：\n混存淘汰到下一次加载期间是没有数据的，此时读取数据就是空值，会认为数据丢失了\n\n解决方案：\n（1）后台线程不仅负责定时更新缓存，而且也负责频繁地检测缓存是否有效，检测到缓存失效了，原因可能是系统紧张而被淘汰的，于是就要马上从数据库读取数据，并更新到缓存。\n\n这种方式的检测时间间隔不能太长，太长也导致用户获取的数据是一个空值而不是真正的数据，所以检测的间隔最好是毫秒级的，但是总归是有个间隔时间，用户体验一般。\n\n（2）在业务线程发现缓存数据失效后（缓存数据被淘汰），通过消息队列发送一条消息通知后台线程更新缓存，后台线程收到消息后，在更新缓存前可以判断缓存是否存在，存在就不执行更新缓存操作；不存在就读取数据库数据，并将数据加载到缓存。这种方式相比第一种方式缓存的更新会更及时，用户体验也比较好。\n\nhttps://xiaolincoding.com/redis/cluster/cache_problem.html#缓存雪崩\n```\n\n#### 服务熔断是什么？\n\n```\n服务熔断的目标是在服务发生故障或延迟时，快速地停止对该服务的请求，并返回一个预设的错误或默认响应，从而避免故障的扩大影响，保护整个系统的稳定性。熔断器在服务之间充当一个保护层，当服务出现故障或不可用时，熔断器会打开，并拒绝后续的请求，而不是继续发送请求给不可用的服务。\n```\n\n\n\n## 参考\n\n-   [Redis：缓存雪崩，缓存穿透，缓存击穿](https://mp.weixin.qq.com/s/T_AxoAwCbzKGhvjiluMxQw)\n-   [springboot：整合redis解决缓存击穿，缓存雪崩，缓存穿透](https://blog.csdn.net/weixin_43296313/article/details/125447527)\n-   [SpringBoot中如何解决Redis的缓存穿透、缓存击穿、缓存雪崩？](https://juejin.cn/post/7210212440670945335)","timestamp":1693737620936},{"name":"08-Caffeine+Redis多级缓存.md","path":"007-Redis/001-实践/08-Caffeine+Redis多级缓存.md","content":"https://mp.weixin.qq.com/s/_ysKYrzyRGebtotGyzQUIw","timestamp":1693737620936},{"name":"09-redis分布式限流器.md","path":"007-Redis/001-实践/09-redis分布式限流器.md","content":"https://mp.weixin.qq.com/s/kyFAWH3mVNJvurQDt4vchA","timestamp":1693737620936},{"name":"02-Redis.md","path":"007-Redis/02-Redis.md","content":"[Redis6视频笔记](https://zhangc233.github.io/2021/05/02/Redis/#Redis%E6%8C%81%E4%B9%85%E5%8C%96%E4%B9%8BRDB)\n\n[javaguide](https://javaguide.cn/database/redis/redis-questions-01.html#redis-除了做缓存-还能做什么)\n\nhttps://www.yuque.com/snailclimb/mf2z3k/ikf0l2\n\nc语言中文网http://c.biancheng.net/redis/slaveof.html\n\n小林coding：https://xiaolincoding.com/redis/\n\n## Redis基础\n\n### 什么是 Redis？[x]\n\n```\n是一个开源的高性能键值存储数据库。\n\n特点：\n（1）高性能：Redis数据存储在内存中，因此具有非常快速的读写性能。\n（2）数据结构丰富：Redis支持多种数据结构，可以满足不同类型的应用需求。\n（3）支持持久化：Redis提供了持久化机制，可以将数据持久化到磁盘上，以便在重启后恢复数据。\n（4）集群：Redis可以通过主从复制和分片等机制进行数据分布和高可用性的部署。\n（5）支持事务：Redis支持简单的事务功能，可以保证一系列操作的原子性。\n（6）支持发布订阅：Redis支持发布订阅模式，可以实现消息的发布和订阅机制。\n\nRedis常被用作缓存、消息队列、分布式锁等场景下的数据存储和处理。它被广泛应用于各种Web应用、移动应用和分布式系统中，以提供高性能的数据存储和访问能力。\n\nchatgpt\n```\n\n### 优缺点\n\n```\n（1）优点：同特点\n（2）缺点：\n\t\t- 数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。\n\t\t- 主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。\n```\n\n### Redis 为什么这么快？ TODO\n\n```\n（1）内存存储：数据存储在内存中，读写速度快\n（2）IO多路复用： Redis 基于 Reactor 模式设计开发了一套高效的事件处理模型，主要是单线程事件循环和 IO 多路复用\n（3）Redis 内置了多种优化过后的数据结构实现，性能非常高。\n\nhttps://javaguide.cn/database/redis/redis-questions-01.html#redis-为什么这么快\nRedis 为什么这么快，你知道 I/O 多路复用吗？：https://learnku.com/articles/73927\n```\n\n### 为什么要用 Redis/为什么要用缓存？\n\n```\n缓存的基本思想：\n空间换时间，常见的还有索引、数据库表的冗余字段、CDN\n\n（1）高性能。\n\t直接访问数据库，从磁盘中读取，速度较慢。redis基于内存，读写速度快。将高频且不经常改变的数据直接缓存，下次就可以直接从内存中读取，速度快\n（2）高并发\n\tredis能够承受的请求远大于直接访问mysql。单台设备的redis的QPS是mysql的10倍，redis单机的qps能轻松破10w，而mysql单机的qps很难破1w\n\nQPS（Query Per Second）：每秒钟处理完请求的次数\nhttps://javaguide.cn/database/redis/redis-questions-01.html#为什么要用-redis-为什么要用缓存\n```\n\n### 既然Redis那么快，为什么不用它做主数据库，只用它做缓存？\n\n```\n虽然Redis非常快，但它也有一些局限性，不能完全替代主数据库。有以下原因：\n（1）基于内存：内存昂贵，不适合做海量数据的存取\n（2）事务处理：Redis只支持简单的事务处理，对于复杂的事务无能为力，比如跨多个键的事务处理。\n（3）数据持久化：Redis是内存数据库，数据存储在内存中，如果服务器崩溃或断电，数据可能丢失。虽然Redis提供了数据持久化机制，但有一些限制。\n（4）数据处理：Redis只支持一些简单的数据结构，比如字符串、列表、哈希表等。如果需要处理复杂的数据结构，比如关系型数据库中的表，那么Redis可能不是一个好的选择。\n（5）数据安全：Redis没有提供像主数据库那样的安全机制，比如用户认证、访问控制等等。\n\n因此，虽然Redis非常快，但它还有一些限制，不能完全替代主数据库。所以，使用Redis作为缓存是一种很好的方式，可以提高应用程序的性能，并减少数据库的负载。\n```\n\n### Memcached和Redis的区别？\n\n```\n（1）速度：Redis 的速度比 Memcached 快很多。\n（2）数据结构：MemCached 数据结构单一，仅用来缓存数据，而 Redis 支持多种数据类型。\n（3）持久化：MemCached 不支持数据持久化，重启后数据会消失。Redis 支持数据持久化。\n（4）事务：Memcached不支持事务\n（4）集群：Redis 提供主从同步机制和 cluster 集群部署能力，能够提供高可用服务。Memcached 没有提供原生的集群模式，需要依靠客户端实现往集群中分片写入数据。\n（5）Redis 使用单线程的多路 IO 复用模型，Memcached使用多线程的非阻塞 IO 模型。（Redis6.0引入了多线程IO，用来处理网络数据的读写和协议解析，但是命令的执行仍然是单线程）\n（6）value 值大小不同：Redis 最大可以达到 512M；memcache 只有 1mb。\n\nhttps://mp.weixin.qq.com/s/CiFSsOx_g9g-0PUGXDuvcQ\n```\n\n\n\n\n\n### 缓存的分类\n\n```\n（1）本地缓存\n（2）分布式缓存\n```\n\n#### 什么是本地缓存\n\n```\n本地缓存就是将数据暂时存在应用程序的本地内存中，\n最大的优点就是速度非常快，不需要额外的网络开销\n缺点就是消耗一定的内存空间、可能会导致数据一致性问题\n```\n\n#### 本地缓存实现方案\n\n```\n（1）JDK自带的HashMap、ConcurrentHashMap：只提供了缓存功能，没有过期时间、淘汰机制等\n（2）Ehcache、Guava cache、spring cache。\n\t\t- Ehcache可以嵌入到hibernate和mybatis作为多级缓存，并且可以将缓存的数据持久化到本地磁盘\n\t\t- Guava cache提供api方便使用\n\t\t- spring cache：提供注解方式，代码干净，但容易出现缓存穿透、内存溢出等问题\n（3）Caffeine。比Guava更方面性能更优秀\n```\n\n#### 本地缓存优劣？\n\n```\n优势：低依赖、轻量、简单、成本低\n劣势：\n\t（1）与应用耦合，对分布式架构不友好。如同一个服务部署在多台机器，各服务之间的缓存无法共享。\n\t（2）内存受限：缓存容量受服务部署所在机器限制明显。当前系统服务所耗费的内存多，那本地缓存使用的容量就少\n```\n\n#### 什么是分布式缓存\n\n```\n是一种在分布式系统中使用的缓存技术，它将缓存数据分布在多个节点上，整体对外提供统一的访问接口，可以提高系统的性能、拓展性和可用性。\n```\n\n#### 分布式缓存优势\n\n```\n（1）高性能：分布式缓存通常使用高速的内存存储，能够快速响应数据请求，提供低延迟的数据访问。\n（2）可拓展性：数据分布在多个节点上，可以通过添加节点的方式实现水平拓展\n（3）高可用：通过复制和备份，即使某个节点发生故障，仍然可以从其他节点获取数据\n```\n\n#### 分布式缓存存在的问题\n\n```\n（1）系统复杂性增加：需要维护数据一致性、保证缓存服务的高可用\n（2）成本增加：内存成本贵\n```\n\n#### 分布式缓存方案\n\n```\n（1）Memcached\n（2）Redis\n```\n\n#### 多级缓存\n\n```\n本地缓存（第一级） + 分布式缓存（第二级），是最常用的多级缓存方式\n读取缓存时先到本地缓存中读，读不到再二级缓存。这样可以降低二级缓存的压力，如果二级缓存也没有，则去查数据库，\n查询成功后将数据写入一级、二级缓存中\n```\n\n#### 用了分布式缓存，为什么还要本地缓存？\n\n```\n本地缓存和分布式缓存都属于缓存，但本地缓存的速度远大于分布式缓存，因为不需要额外的网络开销\n一般情况下不建议使用，需要维护一级缓存 和 二级缓存的一致性\n\n适合多级缓存的场景\n（1）缓存的数据不会频繁修改，比较稳定\n（2）数据访问量特别大，比如秒杀场景\n\nhttps://www.yuque.com/snailclimb/mf2z3k/fg8lgc\n```\n\n\n\n## Redis数据结构\n\n### redis的数据结构有哪些\n\n```\n五种基础数据结构：\n（1）字符串String：存储一个字符串值，可以是文本、整数、或二进制数\n（2）哈希Hash：适用于存储对象的多个属性\n（3）列表List：按照插入顺序存储一组有序值，可以在列表的两端进行元素的插入、删除\n（4）集合Set：存储一组唯一的无序元素，支持集合的交集、并集、差集等操作\n（5）有序集合ZSet：在集合的基础上，添加一个分数score属性，根据这个分数进行排序，支持根据分数范围进行元素的检索和排名\n\n三种特殊结构：\n（1）位图（Bitmap 2.2新增）\n（2）HyperLogLogs（基数统计 2.8新增）：\n（3）地理空间索引（Geospatial 3.2新增）：存储地理位置信息的数据结构，支持地理位置的存储、距离计算和范围查询。\n（4）Stream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组形式消费数据。\n\nhttps://javaguide.cn/database/redis/redis-data-structures-01.html\nhttps://javaguide.cn/database/redis/redis-data-structures-02.html\n```\n\n### 数据结构的应用场景\n\n```\nString 类型的应用场景：缓存对象、常规计数、分布式锁、共享session 信息等。\nHash 类型：缓存对象、购物车等。\nSet 类型：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。\nZset 类型：排序场景，比如排行榜、电话和姓名排序等。\nBitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等；\nHyperLogLog（2.8 版新增）：海量数据基数统计的场景，比如百万级网页 UV 计数等；\nGEO（3.2 版新增）：存储地理位置信息的场景，比如滴滴叫车；\n```\n\n### 底层实现\n\n```\nhttps://xiaolincoding.com/redis/data_struct/data_struct.html\n```\n\n#### String TODO\n\n描述\n\n```\nString 是最基本的 key-value 结构，key是唯一标识，value可以是数字、数字。\n最多容纳的数据长度是512M\n```\n\n内部实现\n\n<img src=\"https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/03/15185116910471311691047131521d5hULY-sds.png\" alt=\"img\" style=\"zoom: 50%;\" />\n\n```\nredis使用「简单动态字符串SDS」来表示字符串。动态字符串是一种可以自动调整长度的字符串，根据实际存储的数据进行调整。这就使得字符串的修改（增、删等）操作非常高效，无需频繁的进行内存的申请和释放\n\nfree:还剩多少空间\nlen:字符串长度\nbuf:存放的字符数组\n```\n\n使用场景\n\n```\n（1）共享session\n（2）分布式锁\n（3）计数器\n（4）限流\n```\n\n\n\n#### Hash\n\n```\n底层由「压缩列表」或「哈希表」实现\n- 如果哈希类型元素小于512个，所有值小于64字节，使用压缩列表\n- 否则使用哈希表\n\nredis7.0中，压缩列表数据结构已经废弃，交由listpack数据结构来实现\n```\n\n\n\n#### List\n\n<img src=\"https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/27/191613169313497316931349731258ewDaz-f46cbe347f65ded522f1cc3fd8dba549.png\" alt=\"img\" style=\"zoom:67%;\" />\n\n```\n（redis3.2之前由「双向链表」或「压缩列表」实现\n- 如果列表的元素个数 < 512, 每个元素的值都小于64字节 => 使用压缩列表\n- 否则使用双向链表\nredis3.2之后，由quicklist实现。）\n\nredis是由quicklist实现\nquicklist是由「压缩列表」和「双向链表」组成的混合体，它将链表按段切分，每一段使用「压缩列表」来紧凑存储。\n每个压缩列表就是quicklist的一个节点，节点之间使用双向指针接起来\n\n默认的单个ziplist长度为8k字节\n```\n\n使用场景\n\n```\n消息队列（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等\n```\n\n\n\n#### Set\n\n介绍\n\n```\nSet 类型是一个无序并唯一的键值集合，它的存储顺序不会按照插入的先后顺序进行存储。\n一个集合最多可以存储 2^32-1 个元素\nSet 类型除了支持集合内的增删改查，同时还支持多个集合取交集、并集、差集。\n```\n\n内部实现\n\n```\n底层由「哈希表」或「整数集合」来实现\n- 如果集合中的元素都是整数，且元素个数小于512，则使用「整数集合」\n- 否则使用「哈希表」\n```\n\n应用场景\n\n```\n（1）存储的数据是「无序」并且「唯一」\n（2）多个集合的交集、并集、差集\n\n实际场景\n（1）点赞\n（2）共同好友、共同关注\n（3）抽奖\n```\n\n\n\n#### ZSet x\n\n介绍\n\n```\nZset 类型（有序集合类型）相比于 Set 类型多了一个排序属性 score（分值），\nZset每个存储元素相当于有两个值组成的，一个是有序集合的元素值，一个是排序值。\n```\n\n内部实现\n\n```\n由「压缩列表」或「跳表」实现\n- 如果有序集合元素小于128个，并且每个元素的值小于64字节，则使用压缩列表\n- 否则使用跳表\n\nredis7.0中，压缩列表数据结构已经废弃，交由listpack数据结构来实现\n```\n\n应用场景\n\n```\n需要展示最新列表、排行榜的场景\n（1）排行榜\n（2）电话、姓名排序\n```\n\n#### BitMap\n\n介绍\n\n```\n即位图，是一串连续的二进制数组（0和1），可以通过偏移量（offset）定位元素。\nBitMap通过最小的单位bit来进行0|1的设置，表示某个元素的值或者状态，时间复杂度为O(1)。\n\n由于 bit 是计算机中最小的单位，使用它进行储存将非常节省空间，特别适合一些数据量大且使用二值统计的场景。\n```\n\n![image-20230827112314072](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/27/11231416931065941693106594317B4mVJ8-image-20230827112314072.png)\n\n内部实现\n\n```\n\n```\n\n应用场景\n\n```\nBitmap 类型非常适合二值状态统计的场景，这里的二值状态就是指集合元素的取值就只有 0 和 1 两种，在记录海量数据时，Bitmap 能够有效地节省内存空间。\n\n（1）签到统计\n（2）判断用户登陆状态\n（3）连续签到用户总数\n```\n\n#### HyperLogLog\n\n应用场景\n\n```\n（1）百万级网页 UV 计数\n```\n\n### Quicklist\n\n是什么\n\n```\nredis是由quicklist实现\nquicklist是由「压缩列表」和「双向链表」组成的混合体，它将链表按段切分，每一段使用「压缩列表」来紧凑存储。\n每个压缩列表就是quicklist的一个节点，节点之间使用双向指针接起来\n\n默认的单个ziplist长度为8k字节\n```\n\n插入\n\n```\n插入元素时，不会像普通链表那样，直接新建一个节点。而是会检查插入位置的压缩列表是否能容纳该元素：\n- 如果能容纳就直接保存到quicklistNode结构里的压缩列表\n- 如果不能，就会新建一个quicklistNode结构\n\nquicklist 会控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来规避潜在的连锁更新的风险，但是这并没有完全解决连锁更新的问题。\n```\n\n为什么要有quicklist？\n\n```\nquicklist是「压缩列表」和「双向链表」的组合体\n压缩列表是通过紧凑型的内存布局节省了内存开销，但是因为它的结构设计，如果保存的元素数量增加，或者元素变大了，压缩列表会有「连锁更新」的风险，一旦发生，会造成性能下降。\n\nquicklist 解决办法，通过控制每个链表节点中的压缩列表的大小或者元素个数，来规避连锁更新的问题。因为压缩列表元素越少或越小，连锁更新带来的影响就越小，从而提供了更好的访问性能。\n```\n\n\n\n### 压缩列表\n\n#### 为什么数据量小的时候用压缩列表？\n\n[参考](https://mp.weixin.qq.com/s/7YcvtQOd6CUrPEx1sFhwVw)\n\n```\n因为压缩列表一种内存紧凑的数据结构，可以节约内存。\n压缩列表是 Redis 为了节约内存而开发的，它是由连续内存块组成的顺序型数据结构，有点类似于数组\n如果元素过多，查找复杂度就是O（n）\n```\n\n\n\n### 跳表\n\nhttps://xiaolincoding.com/redis/data_struct/data_struct.html#%E8%B7%B3%E8%A1%A8\n\n为什么要有跳表？\n\n```\n链表在查找元素的时候，因为需要逐一查找，所以查询效率非常低，时间复杂度是O(N)，于是就出现了跳表。\n跳表是在链表基础上改进过来的，实现了一种「多层」的有序链表，这样的好处是能快读定位数据。\n```\n\n是什么\n\n![img](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/27/19270816931356281693135628082nv8wiT-2ae0ed790c7e7403f215acb2bd82e884.png)\n\n查找过程\n\n```\n查找一个元素时，会从最高层开始，逐一遍历每一层。\n- 如果当前节点「小于」目标节点，跳表会访问该层的下一个节点，直到为null或者大于目标元素，然后回到上一个节点的下一层继续查找\n```\n\n更新、删除、插入 TODO\n\n```\n\n```\n\n跳跃表节点层数设置\n\n```\n相邻层节点数通常是2:1，查找复杂度就可以降低到lg(N)\n```\n\n为什么用跳表而不用平衡树？\n\n```\n(1) 从内存占用上来比较，跳表比平衡树更灵活一些。平衡树每个节点包含 2 个指针（分别指向左右子树），而跳表每个节点包含的指针数目平均为 1/(1-p)，具体取决于参数 p 的大小。如果像 Redis里的实现一样，取 p=1/4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。\n(2) 在做范围查找的时候，跳表比平衡树操作要简单。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在跳表上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现。\n(3) 从算法实现难度上来比较，跳表比平衡树要简单得多。平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而跳表的插入和删除只需要修改相邻节点的指针，操作简单又快速。\n```\n\n### 压缩列表和跳跃表的区别？TODO\n\n```\n（1）存储方式区别：压缩列表是一种紧凑的线性连续存储结构，通过将多个元素依次存储在一块连续的内存中，节省了内存空间。而跳跃表则是一种基于链表的数据结构，通过多层次的索引结构（跳跃层）来加速查找。\n（2）时间复杂度区别：在读取或修改操作方面，压缩列表的时间复杂度为O(n)，其中n是元素数量。因为压缩列表需要线性扫描来定位元素。而跳跃表的读取或修改操作的时间复杂度为O(log n)，通过跳跃层和链表的结构，可以快速定位到目标元素。\n（3）内存占用区别：压缩列表具有较小的内存占用，对于较小的有序集合，可以更节省内存空间。而跳跃表则需要更多的内存空间来存储索引结构，因此在空间占用方面相对较大。\n```\n\n\n\n### listpack TODO\n\n```\n\n```\n\n\n\n### set和list的区别\n\n```\n（1）List 可以存储重复元素，Set 只能存储非重复元素；\n（2）List 是按照元素的先后顺序存储元素的，而 Set 则是无序方式存储元素的。\n```\n\n\n\n### SortedSet和List异同点？\n\n```\n相同点：\n（1）都是有序的；\n（2）都可以获得某个范围内的元素。\n\n不同点：\n（1）实现\n\t\t- 列表基于链表实现，获取两端元素速度快，访问中间元素速度慢；\n\t\t- 有序集合基于散列表和跳跃表实现，访问中间元素时间复杂度是OlogN；\n（3）列表不能简单的调整某个元素的位置，有序列表可以（更改元素的分数）；\n（4）有序集合更耗内存。\n```\n\n\n\n### String 还是 Hash 存储对象数据更好呢？\n\n```\nString存储的是序列化后的对象数据，存放的是整个对象。\nHash是单独存储对象的每个字段，可以获取部分字段的信息，也可以修改或者添加部分字段，节省网络流量。\n\nString节省内存，约是Hash的一半\n如果对象中的某些字段需要经常变动，或者需要经常查询对象中的个别字段信息，Hash适合\n\n在绝大部分情况，我们建议使用 String 来存储对象数据即可\n```\n\n### 购物车信息用 String 还是 Hash 存储更好呢?\n\n```\n由于购物车中的商品频繁修改和变动，购物车信息建议使用 Hash 存储：\n\n用户 id 为 key\n商品 id 为 field，商品数量为 value\n```\n\n![Hash维护简单的购物车信息](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/02/10211516909428751690942875545HKxnFF-19015916893325191689332519632hGmU2k-hash-shopping-cart.png)\n\n那用户购物车信息的维护具体应该怎么操作呢？\n\n```\n\n用户添加商品就是往 Hash 里面增加新的 field 与 value；\n查询购物车信息就是遍历对应的 Hash；\n更改商品数量直接修改对应的 value 值（直接 set 或者做运算皆可）；\n删除商品就是删除 Hash 中对应的 field；\n清空购物车直接删除对应的 key 即可。\n\njavaGuide\n```\n\n### Set 的应用场景是什么？\n\n```\nRedis 中 Set 是一种无序集合，集合中的元素没有先后顺序但都唯一，有点类似于 Java 中的 HashSet\n\n常见应用场景：\n（1）存放的数据不能重复的场景：网站 UV 统计（数据量巨大的场景还是 HyperLogLog更适合一些）、文章点赞、动态点赞等等。\n（2）需要获取多个数据源交集、并集和差集的场景：共同好友(交集)、共同粉丝(交集)、共同关注(交集)、好友推荐（差集）、音乐推荐（差集）、订阅号推荐（差集+交集） 等等。\n（3）需要随机获取数据源中的元素的场景：抽奖系统、随机点名等等。\n```\n\n### 使用 Set 实现抽奖系统怎么做？\n\n```\n如果想要使用 Set 实现一个简单的抽奖系统的话，直接使用下面这几个命令就可以了：\nSADD key member1 member2 ...：向指定集合添加一个或多个元素。\nSPOP key count：随机移除并获取指定集合中一个或多个元素，适合不允许重复中奖的场景。\nSRANDMEMBER key count : 随机获取指定集合中指定数量的元素，适合允许重复中奖的场景。\n```\n\n### 使用 Bitmap 统计活跃用户怎么做？\n\n```\nBitmap 存储的是连续的二进制数字（0 和 1），通过 Bitmap, 只需要一个 bit 位来表示某个元素对应的值或者状态，key 就是对应元素本身 。我们知道 8 个 bit 可以组成一个 byte，所以 Bitmap 本身会极大的节省储存空间。\n你可以将 Bitmap 看作是一个存储二进制数字（0 和 1）的数组，数组中每个元素的下标叫做 offset（偏移量）。\n\n如果想要使用 Bitmap 统计活跃用户的话，可以使用日期（精确到天）作为 key，然后用户 ID 为 offset，如果当日活跃过就设置为 1。\nSETBIT 20210308 1 1\nSETBIT 20210308 2 1\nSETBIT 20210309 1 1\n```\n\n### 使用 HyperLogLog 统计页面 UV 怎么做？\n\n```\n\n```\n\n\n\n## Redis应用\n\n### [Redis的常用场景有哪些?](https://www.javalearn.cn/#/doc/Redis/面试题?id=_6-redis的常用场景有哪些)\n\n```\n（1）缓存\n（2）分布式锁\n（3）限流\n（4）消息队列\n（5）延时队列\n（6）分布式session\n（7）复杂业务场景：排行榜、计数器、点赞、关注\n\nhttps://javaguide.cn/database/redis/redis-questions-01.html#redis-除了做缓存-还能做什么\n```\n\n### Redis 可以做消息队列么？\n\n```\n可以做简单的消息队列，但不建议\n\n（1）功能有限：相对于专门的消息队列中间件，redis提供的消息队列功能相对简单。缺少一些高级特性，如消息持久化、消息顺序保证、消息重试机制\n（2）redis默认将数据存在内存中，如果故障或停机，可能会丢失数据\n（3）拓展性：redis在处理大量消息时，可能会收到性能限制。当消息数量增长时，redis的单线程模型可能会成为瓶颈，影响吞吐量。redis6之后引入多线程模型，即redis线程池，一定程度上可以缓解，但并没有完全并行化处理所有请求，仍然存在一些串行化操作，如数据结构的修改操作疼需要进行同步。\n\nchatgpt\n```\n\n\n\n### 分布式锁的实现方式有哪些？[*]\n\n```\n（1）基于数据库的分布式锁:\n\t\t- 通过在数据库中创建一个表，用于存放锁信息。当需要获取锁时，尝试在该表中插入一行数据，插入成功则获得锁，插入失败则等待或重试。\n\t\t- 也可以使用数据库的原生锁机制，例如MySQL的SELECT ... FOR UPDATE。\n（2）基于Redis的分布式锁:\n\t\t- 使用Redis的SETNX命令（set if not exists）或者SET命令的NX选项来尝试获取锁。Redis的EXPIRE命令可以设置锁的超时时间，防止死锁。\n\t\t- Redlock算法是一种基于Redis的分布式锁算法，用于提高锁的可靠性。\n```\n\n###  如何基于 Redis 实现分布式锁？\n\n```\n\n```\n\n\n\n\n\n## Redis持久化机制 *\n\n### [Redis持久化机制？](https://www.javalearn.cn/#/doc/Redis/面试题?id=_8-redis持久化机制？)\n\n```\nredis提供了三种不同形式的持久化机制\n（1）RDB（Redis DataBase）：快照\n（2）AOF（Append Only File）：只追加文件\n（3）混合持久化方式：Redis 4.0 新增的方式，集成了 AOF 和 RBD 的优点；\n```\n\n### RDB\n\n#### 是什么\n\n```\n是redis默认的持久化方式\n将某一时刻的所有数据以二进制的形式写入到文件中，恢复时将快照文件读到内存中\n```\n\n#### 优缺点\n\n```\n（1）优点：适合大规模的数据恢复，对数据的完整性和一致性要求不高\n（2）缺点：在一定间隔时间做一次备份，如果rdis意外down掉，会丢失最后一次快照后的所有修改\n```\n\n#### 备份是如何进行的\n\n```\nredis会单独创建fork一个子进程来持久化。首先将数据写入一个临时文件中，待持久化过程都结束了，再用这个文件替换上次持久化好的文件\n\nhttps://zhangc233.github.io/2021/05/02/Redis/#Redis%E6%8C%81%E4%B9%85%E5%8C%96%E4%B9%8BRDB\n```\n\n#### RDB 创建快照时会阻塞主线程吗？\n\n```\nRedis 提供了两个命令来生成 RDB 快照文件：\nsave : 在主线程生成rdb文件，会阻塞 Redis 主线程；\nbgsave : fork 出一个子进程，子进程执行，不会阻塞 Redis 主线程，默认选项。\n```\n\n#### RDB 在执行快照的时候，数据能修改吗？\n\n```\n可以。在执行bgsave过程中，运用了「写时复制技术」，redis仍然可以继续处理操作命令\n\n在执行bgsave过程中，会通过fork（）创建子进程创建快照。如果主进程执行写操作，被修改的数据会复制一份副本，然后bgsave子进程会把该副本数据写入RDB文件，在这个过程中，主线程仍然可以直接修改原来的数据\n```\n\n\n\n### AOF\n\n#### 是什么 / AOF 日志是如何实现的？\n\n```\n以日志的形式来记录每个写操作（增量保存），将redis执行过的所有数据更新指令记录下来（读操作不记录），追加到AOF文件中。redis启动之初会读取该文件逐一执行命令来进行数据恢复\n```\n\n#### 优缺点\n\n```\n（1）优点：\n\t\t- 备份机制更文件，丢失数据的概率更低\n（2）缺点\n\t\t- 比RDB更占空间\n\t\t- 恢复备份速度要慢\n\t\t- 每次读写都同步，会有一定的性能压力\n```\n\n#### AOF持久化流程 x\n\n```\n（1）命令追加：将所有写命令追加到AOF缓冲区中\n（2）通过write（）系统调用将aof缓冲区中的数据写到aof文件中，此时数据并没有写到磁盘中，而是拷贝到了内核缓冲区，等待内核将数据写入磁盘\n（3）根据写回策略，将数据写入硬盘中\n（4）文件重写（rewrite）：随着AOF文件越来越大，需要定期对AOF文件进行重写，达到压缩的目的\n（5）重启加载（load）:当redis重启时，会重新加载AOF文件中的写操作恢复数据\n\n```\n\n#### 持久化策略 / AOF 写回策略有哪些？\n\n![img](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/04/10593616911179761691117976340S2YpGq-98987d9417b2bab43087f45fc959d32a-20230309232253633.png)\n\n```\n（1）appendfsync always：始终同步，每次 Redis 的写入都会立刻记入日志；性能较差但数据完整性比较好。\n（2）appendfsync everysec：每秒同步，每秒记入日志一次，如果宕机，本秒的数据可能丢失。\n（3）appendfsync no：redis 不主动进行同步，把同步时机交给操作系统。\n```\n\n#### AOF 为什么是在执行完命令之后记录日志？\n\n```\n关系型数据库（如 MySQL）通常都是执行命令之前记录日志（方便故障恢复），而 Redis AOF 持久化机制是在执行完命令之后再记录日志\n\n为什么是在执行完命令之后记录日志呢？\n（1）避免额外的检查开销，AOF记录日志不会对命令进行语法检查；如果先写再执行，命令语法有错误就会把错误命令记录到aof中，恢复数据时就会出错\n（2）在命令执行完之后再记录，不会阻塞当前的命令执行。\n\n这样也带来了风险（我在前面介绍 AOF 持久化的时候也提到过）：\n（1）如果刚执行完命令 Redis 就宕机会导致对应的修改丢失；\n（2）可能会阻塞后续其他命令的执行（AOF 记录日志是在 Redis 主线程中进行的）。\n\njavaguide\n```\n\n#### AOF 日志过大，会触发什么机制？\n\n```\n如果当 AOF 日志文件过大就会带来性能问题，比如重启 Redis 后，需要读 AOF 文件的内容以恢复数据，如果文件过大，整个恢复的过程就会很慢。\n\nRedis 为了避免 AOF 文件越写越大，提供了「 AOF 重写机制」，当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。\n\n重写就是将多个键值对用一条命令记录\n```\n\n#### AOF 重写\n\n```\n当AOF变得太大时，redis会在后台的一个子进程中进行重写操作，避免对redis正常处理命令请求造成影响\nAOF重写期间，redis会维护一个「AOF重写缓冲区」，该缓冲区会在子进程创建新的AOF文件期间，记录服务器执行的所有写命令。\n当子进程创建完新的AOF文件后，服务器将重写缓冲区中的所有内容追加到新的AOF文件末尾。\n最后替换旧的AOF文件，完成重写\n\nhttps://javaguide.cn/database/redis/redis-persistence.html#aof-%E9%87%8D%E5%86%99%E4%BA%86%E8%A7%A3%E5%90%97\n```\n\n### AOF 和 RDB 同时开启，redis 听谁的？\n\n```\nAOF默认不开启，如果都开启，系统默认取AOF的数据\n```\n\n### AOF和RDB对比\n\n```\nRDB优势：\n（1）RDB文件存储的内容是经过压缩的二进制数据，保存着某个时间点的数据集，文件很小，适合做数据的备份，灾难恢复。\n（2）使用RDB恢复数据，直接解析还原数据即可，非常快。而AOF需要一条一条执行，非常慢\n（3）AOF需要选择合适的刷盘策略，如果刷盘策略选择不当的话，会影响Redis的正常运行。并且，根据所使用的刷盘策略，AOF的速度可能会慢于RDB\n\nAOF优势：\n（1）更安全。RDB会丢掉整个快照，而AOF可能只丢失一条命令或一秒钟内的数据\n\nhttps://javaguide.cn/database/redis/redis-persistence.html#redis-4-0-%E5%AF%B9%E4%BA%8E%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6%E5%81%9A%E4%BA%86%E4%BB%80%E4%B9%88%E4%BC%98%E5%8C%96\n```\n\n### 如何选用\n\n```\n（1）对数据不敏感，选择RDB\n（2）不建议单独使用AOF，因为是不是创建一个RDB快照可以进行数据库备份、更快的重启以及解决AOF引擎错误\n（3）如果只是做纯内存缓存，可以都不用。\n（4）安全性比较高，同时开启\n```\n\n### 混合持久化\n\n#### 为什么会有混合持久化？\n\n```\nRDB 优点是数据恢复速度快，但是快照的频率不好把握。频率太低，丢失的数据就会比较多，频率太高，就会影响性能。\nAOF 优点是丢失数据少，但是数据恢复不快。\n混合持久化集成了两个的优点\n```\n\n#### 是什么？\n\n```\n混合持久化工作是在AOF日志重写过程中，当开启了混合持久化时，在AOF重写日志时，fork出来的子进程会先将与主线程共享的内存数据以RDB方式写入到AOF文件，然后主线程处理的操作会记录在重写缓冲区中，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。\n\nAOF 文件的前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据。\n```\n\n#### 优点\n\n```\n混合持久化结合了 RDB 和 AOF 持久化的优点，开头为 RDB 的格式，使得 Redis 可以更快的启动，同时结合 AOF 的优点，有减低了大量数据丢失的风险。\n```\n\n#### 缺点\n\n```\n（1）AOF 文件中添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差；\n（2）兼容性差，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了\n```\n\n### 大key会有什么问题？ TODO\n\n```\nhttps://xiaolincoding.com/redis/storage/bigkey_aof_rdb.html#%E5%A4%A7-key-%E5%AF%B9-aof-%E6%97%A5%E5%BF%97%E7%9A%84%E5%BD%B1%E5%93%8D\n```\n\n\n\n\n\n## 线程模型 TODO\n\nhttps://mp.weixin.qq.com/s/oeOfsgF-9IOoT5eQt5ieyw\n\nhttps://xiaolincoding.com/redis/base/redis_interview.html#redis-线程模型\n\n### Redis 是单线程吗？\n\n```\nRedis 单线程指的是「接收客户端请求->解析 ->执行->内容返回」这个过程是由一个线程（主线程）来完成的，这也是我们常说 Redis 是单线程的原因。\n\nredis程序并不是单线程的，redis在启动时会启动后台线程（BIO）：\n处理关闭文件、AOF 刷盘、释放内存（lazyfree 线程）\n\n因为这些任务的操作都是很耗时的，如果把这些任务都放在主线程来处理，那么 Redis 主线程就很容易发生阻塞，这样就无法处理后续的请求了。\n```\n\n### Redis 单线程模式是怎样的？\n\n```\n\n```\n\n### 讲讲Redis的线程模型？\n\n```\nhttps://mp.weixin.qq.com/s/CiFSsOx_g9g-0PUGXDuvcQ\n\nhttps://javaguide.cn/database/redis/redis-questions-01.html#redis-%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B-%E9%87%8D%E8%A6%81\n```\n\n### Redis 采用单线程为什么还这么快？\n\n```\n单线程的 Redis 吞吐量可以达到 10W/每秒\n\nRedis 采用单线程（网络 I/O 和执行命令）那么快，有如下几个原因：\n（1）都在内存中完成，并且采用了高效的数据结构\n（2）Redis 采用单线程模型可以避免了多线程之间的竞争，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。\n（3）Redis 采用了 非阻塞的I/O 多路复用机制处理大量的客户端 Socket 请求。\nIO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。\n#\n```\n\n### Redis 6.0 之前为什么使用单线程？\n\n```\n（1）单线程编程容易并且更容易维护；\n（2）Redis 的性能瓶颈不在 CPU ，主要在内存和网络。CPU 并不是制约 Redis 性能表现的瓶颈所在，更多情况下是受到内存大小和网络I/O的限制，所以 Redis 核心网络模型使用单线程并没有什么问题\n（3）增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗。\n（4）多线程会带来线程不安全的情况；\n```\n\n### Redis 6.0 之后为什么引入了多线程？\n\n```\n（1）单线程无法利用多CPU\n（1）为了提高网络 IO 读写性能。因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上，所以为了提高网络 I/O 的并行度，Redis 6.0 对于网络 I/O 采用多线程来处理。但是对于命令的执行，Redis 仍然使用单线程来处理\n```\n\n\n\n## Redis事务\n\n### 什么是redis事务？\n\n```\nredis事务就是提供了一种将多个命令请求打包的功能，然后按顺序的去执行，执行过程被打断。\n与mysql不同的是，它不具备原子性\n```\n\n### 为什么不具备原子性\n\n```\n原子性：事务是最小的执行单位，它保证了事务中的操作要么都完成，要么都失败。\nredis事务中，如果某个命令失败了，并不会影响事务继续执行，除了失败的命令，其它命令都能正常执行。\n并且，redis事务是不支持回滚操作的。所以redis事务是不满足原子性的\n\nhttps://javaguide.cn/database/redis/redis-questions-02.html#redis-%E4%BA%8B%E5%8A%A1%E6%94%AF%E6%8C%81%E5%8E%9F%E5%AD%90%E6%80%A7%E5%90%97\n```\n\n### 为什么不支持回滚 x\n\n```\nredis官方的介绍是：redis开发者们觉得没有必要支持回滚，这样更简单便捷，性能也更好。\nredis开发者们觉得即使命令执行错误，也应该在开发过程中就发现而不是在生产过程中\n```\n\n### Redis 事务支持持久性吗？\n\n```\nredis支持持久化，但redis事务不支持持久性\nredis可以通过RDB、AOF或者两种方式混合进行持久化\nredis事务在执行过程中，并不会立即将数据写入磁盘，而是先缓存在内存中，当事务执行完毕并成功提交时，才会将数据写入磁盘进行持久化存储。\n\n这就以为着如果redis发生故障或意外宕机，事务中未提交的数据可能会丢失。只存在内存中，并没有持久化到磁盘中。\n\n因此redis事务不具备持久性。\n```\n\n### 如何使用Redis事务？x\n\n```\n流程\n（1）开始事务（Multi）\n（2）命令入队（FIFO）：输入的命令都会依次进入命令队列中，但不会执行\n（3）执行事务（Exec）：Redis 会将之前的命令队列中的命令依次执行\n（4）取消事务（discard）\n\nMULTI 命令用于标记事务的开始，\nEXEC 命令用于执行事务中的命令，\nWATCH 命令用于监视一个或多个键，如果被监视的键在事务执行期间被修改，则事务会被取消，\nDISCARD 命令用于取消事务。\n```\n\n### 如何解决Redis事务的缺陷？\n\n```\n主要处理的是redis事务在原子性、隔离性、错误回滚方面的问题\n可以使用lua脚本的方式解决。\n\n利用lua脚本，可以批量执行多条redis命令，这些命令会被提交到redis服务器一次性执行完成，大幅减少网络开销。\n一段lua脚本执行过程中不会有其他脚本或者redis命令执行，保证了操作不会被其他指令插入干扰。\n\n如果执行期间出错，出错后的命令不会继续执行，但是出错前的命令是不会回滚的，所以也并不能完全保证redis事务的原子性。\n```\n\n\n\n## Redis性能优化\n\n### 大量 key 集中过期问题 x\n\n```\n对于过期的key，redis使用定期删除 + 惰性删除两种策略\n（1）响应慢：定期删除过程中，如果遇到大量key失效的情况，客户端必须等待清理完成，因为定期任务线程是在redis主线程中进行。会导致客户端请求不能被及时处理，响应比较慢。\n（2）占内存：如果大量的key集中过期，但Redis没有及时清理它们，过期的key仍然会占用内存空间。这会导致Redis内存占用率上升，可能导致系统内存不足。\n```\n\n### 如何解决？\n\n```\n（1）给key设置随机过期时间。\n（2）惰性删除。\n```\n\n### redis如何清理这些过期key？\n\n```\n定期删除：\n（1）redis使用定时任务来主动查找并删除过期的键。默认每秒检查一定数量的过期键并删除。\n（2）主线程执行定期任务，可能会导致客户端请求不能及时响应。\n\n惰性删除：\n（1）Redis 在访问某个键时，会先检查该键是否过期。如果键已过期，则会立即删除该键并返回空值。这种方式避免了在每个键上定期检查的开销，只在访问时进行检查和删除。\n（2）采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程。\n（3）缺点：不能删除所有过期key\n```\n\n\n\n### Redis bigkey（大 Key）\n\n#### 什么是 bigkey？\n\n```\n一个key对应的value所占的内存比较大，这个key就可以看成是bigkey\n\n参考标准：\nstring类型的value超过10kb\n符合类型的value包含元素超过5000个\n```\n\n#### bigkey 有什么危害？\n\n```\nbigkey 除了会消耗更多的内存空间和带宽，还会对性能造成比较大的影响。因此，我们应该尽量避免 Redis 中存在 bigkey。\n```\n\n#### 如何发现 bigkey？\n\n```\n（1）使用 Redis 自带的 --bigkeys 参数来查找。\n（2）使用开源工具\n```\n\n#### 如何处理 bigkey？\n\n```\n（1）分割bigkey。分割成多个小的key，需要调整业务代码，不推荐\n（2）优化数据结构\n（3）持久化存储\n（4）数据压缩\n```\n\n\n\n### Redis hotkey（热 Key）\n\n#### 什么是 hotkey？\n\n```\n短时间内频繁访问的key\n```\n\n#### 有什么危害\n\n```\n（1）处理 hotkey 会占用大量的 CPU 和带宽，可能会影响 Redis 实例对其他请求的正常处理\n（2）如果突然访问 hotkey 的请求超出了 Redis 的处理能力，Redis 就会直接宕机。这种情况下，大量请求将落到后面的数据库上，可能会导致数据库崩溃。\n```\n\n#### 如何解决 hotkey？\n\n```\n（1）缓存预热：在系统启动或低峰期，提前加载热点数据到缓存中，避免热点数据在高峰期大量请求时才从后端存储加载。\n（2）分布式缓存：使用分布式缓存，将热点数据分散到不同的缓存节点上，减轻单个缓存节点的压力。\n（3）缓存穿透处理：使用布隆过滤器等技术，对查询请求进行预处理，判断请求的键是否存在于缓存中，不存在则直接拦截请求，避免穿透到后端存储。\n（4）限流和熔断：对于大量请求访问同一个热点键，可以使用限流和熔断机制，控制请求的并发数或拒绝一部分请求，避免对后端存储造成过大压力。\n（5）读写分离：主节点处理写请求，从节点处理读请求。\n```\n\n\n\n### 慢查询命令\n\n#### 是什么\n\n```\nRedis 命令的执行可以简化为以下 4 步：\n（1）发送命令\n（2）命令排队\n（3）命令执行\n（4）返回结果\n\nredis慢查询统计的是【命令执行】这一步骤的耗时，慢查询命令也就是那些命令执行时间较长的命令\n```\n\n#### 为什么会有慢查询命令 x\n\n```\nredis中的大部分命令都是O（1）时间复杂度，但也会有部分O（n）时间复杂度的命令，例如：\nKEYS *：会返回所有符合规则的 key。\nHGETALL：会返回一个 Hash 中所有的键值对。\nLRANGE：会返回 List 中指定范围内的元素。\nSMEMBERS：返回 Set 中的所有元素。\nSINTER/SUNION/SDIFF：计算多个 Set 的交集/并集/差集。\n\n随着n的增大，执行的耗时也越长。\n\n另外还有一些时间复杂度在O（N）之上的命令，例如：\n（1）ZRANGE/ZREVRANGE：返回指定 Sorted Set 中指定排名范围内的所有元素。时间复杂度为 O(log(n)+m)，n 为所有元素的数量， m 为返回的元素数量，当 m 和 n 相当大时，O(n) 的时间复杂度更小。\n（2）ZREMRANGEBYRANK/ZREMRANGEBYSCORE：移除 Sorted Set 中指定排名范围/指定 score 范围内的所有元素。时间复杂度为 O(log(n)+m)，n 为所有元素的数量， m 被删除元素的数量，当 m 和 n 相当大时，O(n) 的时间复杂度更小。\n\n```\n\n### Redis内存碎片\n\n#### 是什么\n\n```\n已经分配的内存空间中存在未被使用的小块内存，这些小块内容无法被充分利用，导致整体内存利用率降低\n随着内存碎片的不断积累，会导致内存碎片问题进一步加剧，导致「内存分配」和「回收」的性能下降\nRedis内存碎片虽然不会影响 Redis 性能，但是会增加内存消耗。\n```\n\n#### 为什么会导致内存分配性能下降？x\n\n```\n因为系统需要寻找连续的内存块来满足分配请求，而内存碎片造成了空洞，增加了查找的复杂度\n```\n\n#### 为什么会有redis内存碎片？x\n\n```\n（1）内部原因：内存分配器无法做到按需分配，是按固定大小来分配内存空间。\n\t\tRedis 可以使用多种内存分配器来分配内存（ libc、jemalloc、tcmalloc），默认使用 jemalloc，而 jemalloc 按照一系列固定的大小（8 字节、16 字节、32 字节......）来分配内存的\n\n（2）频繁修改和删除Redis中的数据会产生内存碎片。\n```\n\n#### 详细说说为什么频繁修改 Redis 中的数据会产生内存碎片\n\n```\n修改时采用写时复制技术，修改流程：\n（1）申请一块新的内存空间，大小与修改后的键值对大小相同（实际上可能会略大于）\n（2）将原始键值对中的数据拷贝到新的内存空间中\n（3）将新的内存空间作为键值对的值，替换原始的内存空间。\n\n写时复制的优点在于：修改数据时保护了原始的内存空间，保证了读操作的并发安全性\n\n频繁修改会导致问题：\n写时复制需要申请新的内存空间，而旧的内存不会立即释放（只有当没有任何引用指向它时，它才会被垃圾回收释放掉），频繁写就会导致出现大量不连续的小块空闲内存\n```\n\n\n\n## RedLock TODO\n\n\n\n## Redis集群\n\n### 主从复制\n\n#### 什么是主从复制\n\n```\n主从复制是一种数据同步机制，用于将一台redis主节点的数据，复制到其他redis从节点中，尽可能保证数据的一致性。\n```\n\n#### 作用\n\n```\n（1）读写分离，性能拓展。Master以写为主，Slave以读为主\n（2）容灾快速恢复：主服务器故障时，可以快速切换到从服务器继续提供服务，提高了系统的容灾能力。\n（3）拓展性。通过添加更多的从服务器，可以水平拓展系统的读取性能和容量。\n```\n\n#### 主从复制工作原理\n\n```\n（1）一个redis作为主服务器Master，负责处理所有的写操作和部分读操作\n（2）其他多个redis服务器作为从服务器Slave，只负责读操作，并通过连接与主服务器建立连接，定期从主服务器同步数据，保持与主服务器数据的一致性。\n```\n\n#### 复制原理 x *\n\nhttps://developer.baidu.com/article/detail.html?id=294748\n\n[小林coding](https://xiaolincoding.com/redis/cluster/master_slave_replication.html#第一次同步)\n\n```\n（1）建立连接：slave向master发生一个psync命令来建立与主服务器的连接。\n\t\t- 主服务器的 runID 和复制进度 offset\n（2）快照传输：master收到命令后，会将当前的数据状态创建为一个rdb快照，并将快照发送给从服务器。在传输过程中，主服务器继续处理写入操作，但会将写入操作的数据缓存到内存缓冲区中\n\t\t- 用bgsave产生一个子进程生成rdb，不阻塞主进程\n（3）命令传播：当快照传输完成后，主服务器会将内存缓冲区中缓存的写操作的数据（命令）发送给从服务器。从服务器接收到命令后，会按照接收到的顺序逐个执行，使得自己的数据状态与主服务器的数据状态一致\n（4）增量同步：建立连接后，双方之间就维护了一个TCP链接，从服务器会持续接收主服务器的增加数据，并执行相应的操作，保证与主服务器数据的一致性。\n```\n\n#### 读取从节点会读取到过期的数据吗\n\n```\n有可能\n（1）情况1: 主节点的写操作（设置为过期），还没来得及通知从节点，此时读取从节点的数据就可能读取到过期数据。\n（2）采用EXPIRE或者PEXPIRE设置过期时间到话，表示的是从执行这个命令开始往后TTL时间过期。所以从节点的过期时间会比主节点稍晚一些，在这期间读取从节点数据，则可能读到过期数据。（T3 - T4之间是过期）\n可以使用ExpireAt 或者 PExpireAt, 注意主从节点的时钟要保持一致\n```\n\n<img src=\"https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/07/25/15223816902697581690269758998zYU9bf-image-20230725152238667.png\" alt=\"image-20230725152238667\" style=\"zoom:50%;\" />\n\n#### 为什么全量复制用RDB而不用AOF？\n\n```\n本质在对比RDB和AOF\n```\n\n#### 主从复制方案有什么痛点？\n\n```\n主从复制方案下，master发生宕机，需要手动将一台slave升级为master，同时需要修改应用方的主节点地址，还需要命令所有从节点去复制新的主节点，整个过程需要人工干预。人工干预会大大增加问题的处理时间以及出错的可能性。\n\n可以使用redis哨兵来解决\n\nhttps://www.yuque.com/snailclimb/mf2z3k/ks9olb19hc9wse5k#4193d6d4\n```\n\n#### Redis主从节点是长连接还是短连接？\n\n```\n长连接\n主从服务器在完成第一次同步后，双方之间就会维护一个 TCP 连接。\n```\n\n#### 怎么判断 Redis 某个节点是否正常工作？\n\n```\n通过相互ping-pong心跳检测机制，如果一半以上的节点去ping一个节点时没有pong回应，集群就会认为这个节点挂掉了，就会断开连接\n\n有两种心跳间隔：\n（1）主节点默认每10s发一次ping，判断从节点的存活性和连接状态\n（2）从节点每1s发送replconf ack{offset} 命令，给主节点上报自身当前的复制偏移量，目的是为了：\n\t- 实时监测主从节点网络状态；\n\t- 上报自身复制偏移量， 检查复制数据是否丢失， 如果从节点数据丢失， 再从主节点的复制缓冲区中拉取丢失数据。\n```\n\n#### 主从复制架构中，过期key如何处理？\n\n```\n主节点处理了一个key或者通过淘汰算法淘汰了一个key，这个时间主节点模拟一条del命令发送给从节点，从节点收到该命令后，就进行删除key的操作。\n```\n\n#### Redis 是同步复制还是异步复制？\n\n```\nRedis 主节点每次收到写命令之后，先写到内部的缓冲区，然后异步发送给从节点。\n```\n\n#### 为什么会出现主从数据不一致？\n\n```\n主从数据不一致，就是指客户端从从节点中读取到的值和主节点中的最新值并不一致。\n因为主从节点间的命令复制是异步进行的\n\n具体来说：\n主节点在收到新的写命令后，就会返回结果，并不是等从节点执行完之后再返回。\n如果从节点还没有执行主节点同步过来的命令，主从节点间的数据就不一致了\n```\n\n#### 如何应对主从数据不一致？\n\n```\n（1）第一种方法，尽量保证主从节点间的网络连接状况良好，避免主从节点在不同的机房。\n（2）第二种方法，可以开发一个外部程序来监控主从节点间的复制进度。\nRedis 的 INFO replication 命令可以查看「主节点接收写命令的进度信息」和「从节点复制写命令的进度信息」，所以，我们就可以开发一个监控程序，先用 INFO replication 命令查到主、从节点的进度。\n进度差值大于设定的阈值，就不让客户端从这个从节点读取数据\n```\n\n#### 主从切换如何减少数据丢失？TODO\n\n```\n\n```\n\n#### 主从如何做到故障自动切换？\n\n```\n哨兵模式\n```\n\n\n\n### 哨兵模式 Sentinel\n\n#### 是什么\n\n```\n是redis的一种运行模式，这种模式下，提供一个或多个哨兵运行在独立的服务器上，它会定期监控redis主从节点的状态。当主节点发生故障时，哨兵会通过【选举机制】自动从从节点中选出一个新的主节点，并将其他节点切换为新主节点的从节点，从而实现自动故障转移。\n```\n\n#### 为什么要有哨兵机制？\n\n```\n主从架构中，是读写分离的，如果主节点挂掉，那么就没法响应写操作，也就没法给从节点同步数据。\n如果要恢复服务的话，需要人工介入，选择一个「从节点」切换为「主节点」，然后让其他从节点指向新的主节点\n哨兵机制的作用就是实现「主从节点故障转移」\n```\n\n#### 有什么用\n\n```\n（1）高可用性：监控redis实例状态，主节点宕机自动故障\n（2）配置管理：可以对redis实例的配置进行管理，包括增删改实例的配置，无需手动修改配置文件。\n（3）统一的访问地址：哨兵会提供一个统一的访问地址，客户端可以通过这个地址访问redis实例，而不用关心实际的主节点地址，主从切换时，客户端无需重新配置。\n```\n\n#### 哨兵如何检测节点是否下线？\n\n```\n主观下线（SDOWN）: sentinel节点认为某个redis下线，但不确定，需要其他哨兵节点的投票\n客观下线（ODOWN）：法定数量（通过为过半）的哨兵节点认为redis主节点已经下线，那就是真的下线。【只适用于主节点】\n\n检测流程：\n每个哨兵节点以每秒一次的频率向整个集群中的master、slave以及其他sentinel节点发送一个PING命令，规定时间没有进行有效回复则认为主观下线。\n\n如果是slave节点下线，则无操作，因为对集群影响不大；如果是master，则会向其他哨兵发起命令，其他哨兵进一步确认。通常为半数的哨兵认定master下线，才判定为客观下线。\n```\n\n#### 哨兵如何选出新的master？\n\n```\nslave必须是在线状态才能参加新的master选举\n\n筛选规则（优先级依次降低）：\n（1）slave优先级。数值越小优先级越大，0表示没有参选资格\n（2）复制进度。数据完整度与旧master越接近的\n（3）runid。选runid最小的\n```\n\n#### 如何从哨兵集群中选出leader，进行主从故障转移？\n\n```\n哨兵集群确认有master客观下线之后，会开始故障转移流程，流程的第一步就是要在哨兵集群中选择一个leader，让leader来负责完成故障转移。\n```\n\n那谁来作为候选者呢？\n\n```\nleader的候选人就是那些判断主节点「客观下线」的哨兵\n```\n\n候选者如何选举成为 Leader？\n\n```\n候选者会向其他哨兵发送命令，表明希望成为 Leader 来执行主从切换，并让所有其他哨兵对它进行投票。\n每个哨兵只有一次投票机会，如果用完后就不能参与投票了，可以投给自己或投给别人，但是只有候选者才能把票投给自己。\n那么在投票过程中，任何一个「候选者」，要满足两个条件：\n（1）拿到「半数以上」的赞成票\n（2）票数 > 哨兵配置文件中的quorum值\n```\n\n如果有多个候选者，怎么选？\n\n```\n如果某个时间点，刚好有两个哨兵节点判断到主节点为客观下线，那这时就有两个候选者\n\n每位候选者都会先给自己投一票，然后向其他哨兵发起投票请求。\n如果投票者先收到「候选者 A」的投票请求，就会先投票给它，如果投票者用完投票机会后，收到「候选者 B」的投票请求后，就会拒绝投票。这时，候选者 A 先满足了上面的那两个条件，所以「候选者 A」就会被选举为 Leader。\n```\n\n#### 如何选择哨兵个数？\n\n```\n配置成单数，且大于等于3\nquorum 的值建议设置为哨兵个数的二分之一加1\n\n如果两个哨兵，拿不到半数以上的票，即两票，选不出leader\n避免平票\n```\n\n#### 主从故障转移的过程是怎样的？\n\n```\n第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点。\n第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；\n第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端；\n第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；\n```\n\n\n\n### Redis集群（Cluster模式） TODO\n\nhttps://www.yuque.com/snailclimb/mf2z3k/ikf0l2\n\n#### 是什么？\n\n```\n是一种去中心集群的集群，至少由三个master，每个master至少一个slave节点，它将数据分散存储在多个节点上，每个节点负责管理一部分数据，从而实现数据的水平分片和负载均衡。\n\nslave不对外提供服务，主要是用来保障master的高可用，当master故障时替代它\n```\n\n#### 为什么需要redis cluster？\n\n```\n现有方式存在的问题：\n（1）高并发下，缓存数量可能很大，并发量要求很大\n（2）主从复制和哨兵模式两种方案本质上都是通过增加master的副本slave数量来提高redis服务的整体可用性和读吞吐量，都不支持横向拓展来缓解压力以及解决缓存数据量过大的问题。\n```\n\n#### 什么是slots？\n\n```\n一个redis集群包含16384个插槽，数据库中每个键都属于一个插槽。\n要计算某个key应该分布到哪个哈希槽中，需要先对key计算CRC-16校验码，然后对16384取模\n```\n\n#### 为什么是16384个插槽？ TODO\n\n```\ncrc16算法产生的校验码有16位，理论上可以产生65536个值，\n（1）哈希槽太大会导致心跳包太大，消耗太多带宽\n（2）哈希槽总数越少，对存储哈希槽信息的bitmap压缩效果越好\n（3）redis cluster的主节点通常不会拓展太多，16384个查希槽已经足够用了\n```\n\n#### redis cluster是如何分片的？ TODO\n\n```\n\n```\n\n\n\n## 功能篇 TODO\n\n\n\n## 面试篇 TODO\n\n\n\n## Redis缓存 TODO\n\n### 什么是缓存穿透、缓存击穿、缓存雪崩？\n\n### 数据库和缓存一致性\n","timestamp":1693737620936},{"name":"03-过期删除&内存淘汰.md","path":"007-Redis/03-过期删除&内存淘汰.md","content":"## 过期删除策略\n\n### 如何设置过期时间？\n\n```\n- expire <key> <n>：设置 key 在 n 秒后过期\n- pexpire <key> <n>：设置 key 在 n 毫秒后过期\n- expireat <key> <n>：设置 key 在某个时间戳（精确到秒）之后过期\n- pexpireat <key> <n>：设置 key 在某个时间戳（精确到毫秒）之后过期\n```\n\n设置字符串时，也可以同时对 key 设置过期时间，共有 3 种命令\n\n```\n- set <key> <value> ex <n> ：设置键值对的时候，同时指定过期时间（精确到秒）；\n- set <key> <value> px <n> ：设置键值对的时候，同时指定过期时间（精确到毫秒）；\n- setex <key> <n> <valule> ：设置键值对的时候，同时指定过期时间（精确到秒）。\n```\n\n### 如何判定 key 已过期了？\n\n```\n每当我们对一个 key 设置了过期时间时，Redis 会把该 key 带上过期时间存储到一个过期字典（expires dict）中，也就是说「过期字典」保存了数据库中所有 key 的过期时间。\n```\n\n查询key的流程\n\n```\n当我们查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中：\n- 如果不在，则正常读取键值；\n- 如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期\n```\n\n### 过期删除策略有哪些？\n\n```\n（1）定时删除；\n（2）惰性删除；\n（3）定期删除；\n```\n\n#### 定时删除\n\n```\n在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作。\n```\n\n优缺点\n\n```\n（1）优点：\n\t\t- 内存友好：可以保证过期 key 会被尽快删除，也就是内存可以被尽快地释放。因此，定时删除对内存是最友好的。\n（2）缺点：\n\t\t- CPU不友好：在过期 key 比较多的情况下，删除过期 key 可能会占用相当一部分 CPU 时间，在内存不紧张但 CPU 时间紧张的情况下，将 CPU 时间用于删除和当前任务无关的过期键上，无疑会对服务器的响应时间和吞吐量造成影响。所以，定时删除策略对 CPU 不友好。\n```\n\n#### 惰性删除\n\n```\n不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。\n```\n\n优缺点\n\n```\n（1）优点：\n\t\t- 因为每次访问时，才会检查 key 是否过期，所以此策略只会使用很少的系统资源，因此，惰性删除策略对 CPU 时间最友好。\n（2）缺点：\n\t\t- 一直没有被访问，就会一直占内存\n```\n\n#### 定期删除\n\n```\n每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。\n```\n\n优缺点\n\n```\n（1）优点\n\t\t- 通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。\n（2）缺点\n\t\t- 内存清理方面没有定时删除效果好，同时没有惰性删除使用的系统资源少。\n\t\t- 频率不好确定：难以确定删除操作执行的时长和频率。如果执行的太频繁，定期删除策略变得和定时删除策略一样，对CPU不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放。\n```\n\n### Redis 过期删除策略是什么？\n\n```\nRedis 选择「惰性删除+定期删除」这两种策略配和使用，以求在合理使用 CPU 时间和避免内存浪费之间取得平衡。\n\n定期时间：每秒10次过期检查\n抽查数量：20\n如果每次抽查，过期数量1/4，则再取20个\n```\n\n## 内存淘汰策略\n\n### 是什么\n\n```\nRedis 的运行内存已经超过 Redis 设置的最大内存之后，则会使用内存淘汰策略删除符合条件的 key，以此来保障 Redis 高效的运行。\n```\n\n### Redis 内存淘汰策略有哪些？\n\n```\n不淘汰：\n（1）no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。\n\n过期数据中淘汰：\n（1）volatile-random：随机淘汰设置了过期时间的「任意键值」；\n（2）volatile-ttl：优先淘汰「更早过期」的键值。\n（3）volatile-lru（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，「最久未使用」的键值；\n（4）volatile-lfu（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，「最少使用」的键值；\n\n所有范围内淘汰：\n（1）allkeys-random：「随机」淘汰任意键值;\n（2）allkeys-lru：淘汰整个键值中「最久未使用」的键值；\n（3）allkeys-lfu（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中「最少使用」的键值。\n```\n\n参考\n\n-   https://xiaolincoding.com/redis/module/strategy.html#redis-内存淘汰策略有哪些\n-   https://javaguide.cn/database/redis/redis-questions-01.html#redis-内存淘汰机制了解么\n\n","timestamp":1693737620936}]