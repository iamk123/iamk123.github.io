if(typeof AWPageMounts=='undefined'){AWPageMounts={}};AWPageMounts['m005']=[{"name":"00-系统功能.md","path":"005-项目/001-民用航空发动机健康管理系统/00-系统功能.md","content":"## 项目介绍\n\n```\n\n```\n\n\n\n## 基本概念\n\n### 数据源\n\n```\n是什么？\n数据的来源，mysql、hbase、mongodb、minio桶\n\n为什么？\n数据采集时，和数据处理时需要从指定数据源中获取数据进行分析、存储或其他操作。\n```\n\n### 数据集\n\n```\n数据集就是实体的集合，表示一类实体\n```\n\n### 实体模型\n\n```\n定义了数据的各位维度的信息。比如一张表的结构就是一个实体，我们需要定义它的列名，类型等\n```\n\n### 实体\n\n```\n实体就是实体模型的实例化，就跟java中类和对象的关系一样\n```\n\n## 工作流引擎\n\n### 节点\n\n#### 任务节点\n\n```\n设置任务的标题、执行类型、算法分组、算法名称、处理节点\n需要配置算法模型中定义的参数配置\n```\n\n#### 数据对象节点\n\n```\n任务节点的输入、输出配置\n类型：实体、数据集、minio_file\n```\n\n#### 事件类节点\n\n```\n（1）定时事件：\n（2）周期事件：\n```\n\n#### 逻辑类节点\n\n```\n（1）IF节点\n（2）分支节点\n（3）合并节点\n```\n\n#### 连线&线上条件\n\n```\n\n```\n\n### 流程构建器\n\n```\n负责流程的构建，通过gojs实现的一种可拖拽式的流程绘制模式，绘制的流程通过json的格式保存。\n```\n\n### 解析器\n\n```\n前端绘制完后返回一个json数据，解析器的作用就是去解析这个json文件，根据不同类型的节点，调用不同的解析器来解析并创建对应的类对象，并初始化到状态池中。\n\n解析器采用了「工厂模式」+「策略模式」进行了优化，通过节点的type属性，来找到对应的解析器\n```\n\n### 执行器\n\n```\n负责工作流程的执行。实现时通过「令牌 + 事件驱动」的模式来实现。令牌保障了消息丢失时能够去主动检测任务状态进行更新或重启；事件驱动则保证了任务能够异步执行，并且完成时能够向前推进。\n```\n\n### 表达式解析器\n\n```\n一些逻辑类节点（if、switch）会有一些表达式，前期我是自己实现了一个解析工具，递归的从左到右进行解析；后期的话在浏览一些项目的时候发现了一个很好用的开源工具，叫huTool工具。\n```\n\n### 监视器\n\n```\n在流程启动时会去开启，通过mqtt来实现，去监听指定的话题，包含三部分：\n（1）控制台指令：在前端界面点击按钮传输的指令。比如暂停、恢复、停止\n（2）节点状态更新：celery worker执行完某一个算法后，会发送状态更新指令，监视器接收到后去更新对应节点的状态。\n（3）状态上报：前端是要实时监控引擎的执行过程，节点状态更新、引擎发送异常等需要往前端推送状态。\n```\n\n### 节点状态池\n\n```\n节点状态池包含了整个工作流中所有节点信息 & 一些api，包括节点名称、表示符、配置，以及它的执行状态等。\n解析器解析json时会向状态池中初始化各节点的信息以及初始状态。\n\n底层通过HashMap来实现，后来用concurrentMap优化了一下，防止在并发过程中出现问题\n```\n\n\n\n## 设备管理\n\n```\n分类：零部件，整机/核心机，成熟机型\n```\n\n## 实验管理\n\n```\n零部件实验：包含多个起停实验\n整机/核心机实验：包含多个起停实验\n成熟机型运行记录\n```\n\n\n\n## 数据管理\n\n问题：数据模型管理怎么添加？？\n\n### 内容\n\n```\n数据模型管理\n实验数据管理：零部件实验数据、整机/核心机实验数据、整机实验数据\n业务数据管理：标签管理、标签匹配规则管理、故障管理、异常告警管理\n```\n\n### 数据模型管理\n\n```\n数据模型，就是对数据各个维度定义，比如类型，长度等，数据库表中各个字段的定义\n\n数据导入过程中，可以按照数据模型进行提取并存入数据库\n多次实验时，可以使用上一次实验定义的数据模型，也可以继承上一次数据模型并进行修改，定义一个新的数据模型。\n```\n\n### 结构化时序试验数据管理\n\n功能描述\n\n```\n结构化时序试验数据存储功能，支持将结构化时序试验数据存储至 指定数据集数据表当中\n支持txt、 csv、mat、xls、xlsx 常用数据文本格式数据\n\n接入方式包含「离线文件导入」、「MQTT实时数据流接入」\n```\n\n离线文件导入\n\n```\n其中离线文件导入支持将离线文件导入至系统，文件格式为 CSV、TXT、PDF， 其中 CSV 和 TXT 文件都为 UTF-8 编码，文件内容均由表头和数据 组成。\n```\n\nMQTT实时数据流接入\n\n```\n结构化时序数据来源于「数采系统以」及「快速存取记录器」 QAR 和 ACARS。\n数采系统包括稳态（低频）和动态（高频）数采系统，支持接入方式为离线文件导入和 MQTT 实时数据流接入的方式。\n\n稳态数采系统：\n采集的数据时，使用 MQTT 实时数据流接入 的方式，\n\n动态数采系统：\n采集的数据时，需要用户先把这些数据保存为 UTF-8 编码的 CSV 格式，再采用离线文件导入的方式接入系统。\n\n快速存取记录器 QAR 和 ACARS：\n数据接入方式为离线文件导入的方式，其中 QAR 数据为 CSV 文件格式的， ACARS 数据为 TXT 文件格式的。对于 ACARS 数据，系统只提取模版匹配的数据，模版 由甲方提供。\n```\n\n什么是稳态数据？？？\n\n```\n\n```\n\n结构化时序试验数据查看功能\n\n```\n支持筛选数据维度采用表格分页形式展示试验数据；\n支持选择数据维度分别以折线图的方式展示各维度试验数据；\n支持试验数据同一参数不同测点参数的周向分布图作图功能。\n```\n\n结构化时序试验数据的导出功能\n\n```\n支持对时序试验数据进行导出，导出时可指定数据的维度以及时间段，导出格式为 CSV。\n```\n\n### 非结构化数据管理功能 minio\n\n描述\n\n```\n非结构化数据存储功能，支持将非结构化数据存储至对象存储数据库中。非结构化数据包括「试验日志数据」以及表 3 的其他文本、图片、 音频、视频文件。\n```\n\n非结构化数据上传\n\n```\n\n```\n\n非结构化数据下载\n\n```\n\n```\n\n## 业务流程管理\n\n```\n业务流程图是由任务节点和连接线构成的有 向无环图，其中任务节点类型包括数据源接入节点、数据保存入库节 点、可视化节点、算法模型节点\n```\n\n## 算法模型管理\n\n```\n算法模型就是一个个基础算法，定义了它的名称、类型、算法配置以及运行环境。\n算法开发的过程是在notebook完成的，算法模型定义完后就可以在「单算法任务」和「工作流」里使用\n\n算法配置包含输入、输出、参数\n- 输入输出包含了三类：数据集、实体、minio文件\n- 参数就是算法的形参，包含参数名、类型、默认值\n```\n\n## 状态监视功能\n\n```\n状态监视功能，支持选定指定台份启停试验，并将实时 数据接入的采集量参数和计算量展示在实时监控界面，用户可在展示 界面配置添加或删除展示数据的图表模块，通过选择数据集数据模型 中的维度参数创建生成图表模块，并以折线图的形式展示各个维度数 据，支持设置刷新频率、时间跨度和缩放，其中维度参数包括排气温 度、高低压转子振动、滑油温度、燃油流量、EGT 指示、N1 振动、 EGT 超限、滑油消耗、燃油（温度和压力）、N2 转速、总温、滑 油压力、高压涡轮叶片温度，并可以根据甲方需求进行维度参数的新 增或修改，如果传感器的采样率过高可按需对试验数据进行降采样。\n```\n\n\n\n## MINIO文件管理\n\n### 数据库设计\n\n```java\n分片上传-分片任务记录表 sys_upload_task\nid \nupload_id\t\t\t\t\t\t\t// 分片上传的uploadId，需要根据该id来生成每个分片上传的地址\nfile_identifier\t\t\t\t// 文件唯一标识（md5）\nfile_name\t\t\t\t\t\t\t// 文件名\nbucket_name\t\t\t\t\t\t// 所属桶名\nobject_key\t\t\t\t\t\t// 文件的key\ntotal_size\t\t\t\t\t\t// 文件大小（byte）\nchunk_size\t\t\t\t\t\t// 每个分片大小（byte）\nchunk_num\t\t\t\t\t\t\t// 分片数量\n```\n\n### 功能\n\n#### 文件秒传\n\n```\n上传文件时会去计算文件的md5、文件大小、分片大小，将这些信息存储到数据库，再次上传时，根据md5值就能知道文件是否上传，\n如果相同的路径下存在文件，则直接返回文件的uri；\n如果路径不同，则调用拷贝接口，拷贝成功后返回。\n```\n\n#### 分片上传\n\n```\n将大文件拆分成小文件，将小文件上传\\下载，最后再将小文件组装成大文件\n```\n\n<img src=\"https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/09/03/14144416937216841693721684124s5B5JY-20055016910643501691064350082DqOU1Q-640.png\" alt=\"图片\" style=\"zoom:50%;\" />\n\n```\n流程：\n（1）前端计算文件的md5值、文件大小、分片大小、文件名，调用文件上传接口\n（2）根据md5值查询是否上传过，\n\t\t- 如果上传完成则直接返回；【文件秒传】\n\t\t- 如果有上传过但为上传完成，则返回已经上传的分片；【断点续传的内容】\n\t\t- 如果未上传，则调用minio接口开启一个上传任务获取uploadId，将文件上传信息插入上传记录表中\n（3）根据md5去获取每个分片上传的地址【通过md5去查uploadId，根据uploadId和分片号查询上传地址】\n（4）异步将每个分片上传到指定地址\n（5）合并分片完成上传【监听进度，最后一个分片上传完就调合并接口】\n```\n\n#### 断点续传\n\n```\n指在传输过程中发生中断，或者传输失败，可以从断点处继续传输，而不需要从头开始传输整个文件\n```\n\n#### 分段下载\n\n```\n断点续传下载将需要下载的文件分成若干个分片分别下载，所有分片都下载完成后，将所有分片合并成完整的文件。\n```\n\n<img src=\"https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/04/213943169115638316911563833938akdFF-image-20220724211002451.png\" alt=\"image-20220724211002451\" style=\"zoom:50%;\" />\n\n```java\nGetObjectResponse stream = minioClient.getObject(\n  GetObjectArgs.builder()\n  .bucket(statObjectResponse.bucket())\n  .object(statObjectResponse.object())\n  .offset(startByte)\n  .length(contentLength)\n  .build()\n); \n```\n\n参考\n\n-   [minio断点下载](https://java.isture.com/arch/minio/minio-breakpoint-downloading.html#_3-%E6%96%AD%E7%82%B9%E4%B8%8B%E8%BD%BD)\n-   [springboot使用minio实现分段下载](https://www.bilibili.com/read/cv21016230/)\n\n\n\n#### 文件预览\n\n```\nopenoffice\n```\n\n#### 文件夹重命名\n\n```\n加锁-复制-删除\n```\n\n\n\n## 问题\n\n### 文件管理\n\n#### 文件上传一半不上传了，怎么清理碎片分片？\n\n```\n（1）定时任务：可以考虑在sys_upload_task表中新加一个status字段，表示是否合并分片，默认为false，merge请求结束后变更为true，通过一个定时任务定期清理为status为false的记录。\n（2）另外MinIO自身对于临时上传的分片，会实施定时清理\n```\n\n#### 如何知道哪些分片已经上传成功？\n\n```\n（1）方式1: 通过redis记录，md5:uploadId  -> 分片号\n（2）方式2：直接调minio接口，获取已经上传的分片\n```\n\n#### 多个用户上传同一个文件怎么处理？\n\n```\n（1）文件上传锁：可以引入文件上传锁，确保同一时刻只有一个用户可以进行上传操作。当一个用户开始上传文件时，其他用户需要等待上传锁释放后才能开始上传。\n（2）版本控制：可以为每个文件引入版本控制，确保每个上传的文件都有唯一的版本号。用户上传同名文件时，系统会自动为其分配一个新的版本号，以保证数据的唯一性。\n```\n\n#### 优化：多用户上传同一个文件\n\n```\n对分片加锁\n```\n\n### 什么选minio？不用fastDFS\n\n什么是minio？\n\n```\n（1）MinIO是专门为海量数据存储、人工智能、大数据分析而设计的对象存储系统\n（2）单个对象最大可达5TB。非常适合储海量图片、视频、日志文件、备份数据和容器/虚拟机镜像等\n（3）MinIO主要采用Golang语言实现，整个系统都运行在操作系统的用户态空间，客户端与存储服务器之间采用HTTP/HTTPs通信协议。\n```\n\n为什么要用？\n\n```\n（1）安装部署简单，支持云容器化部署\n（2）操作简单，自带ui管理界面。fastDFS默认没有\n（3）性能优秀，可以达到每秒GB级别的读写速度\n（4）提供了多语言SDK的支持，参考文档非常全面\n（5）兼容亚马逊S3 API\n\t\t- 亚马逊云的 S3 API（接口协议） 是在全球范围内达到共识的对象存储的协议，是全世界认可的对象存储标准。而MinIO是第一个采用S3兼容协议的产品之一\n\t\t- 兼容S3 API有什么好处呢？相当于目前为了节约服务器成本，选择用MinIO自主开发对象存储系统，等企业壮大之后，不想再运维基础设施，可以直接将程序平移到云厂商，不需要重新开发。\n```\n\n[参考](https://juejin.cn/post/7115313166703132709)\n\n\n\n### 为什么用celery？\n\n```\nCelery 是一个分布式任务队列系统，它可以用于执行长时间运行或定期任务\n\n（1）异步处理：当应用需要执行一个可能会耗时的操作时，如发送电子邮件或处理大量数据，可以使用 Celery 将这些操作作为一个后台任务进行，从而不会阻塞用户的请求。\n（2）分布式执行：Celery 允许在多个机器、虚拟机或容器中分布式地执行任务。这对于需要大量计算资源或并行处理的应用程序非常有用。\n（3）可靠性：如果一个工作者（worker）或任务失败，Celery 可以配置为重试任务，从而提供更高的可靠性。\n（4）监控和管理：通过工具如 Flower，开发者和运维人员可以实时监控和管理 Celery 的任务和工作者状态。可以通过taskId终止任务\n```\n\n\n\n### 为什么选择Mqtt？\n\n```\n（1）轻量级协议：MQTT是一个轻量级的发布/订阅协议，特别适合于低带宽、高延迟或不稳定的网络环境。这使其成为物联网(IoT)设备间通讯的理想选择，在我们的系统中，需要对实验过程中产生的数据进行采集，所以mqtt比较适合。\n（2）MQTT支持三个不同的消息交付级别：0 (至多一次)，1 (至少一次)，2 (只有一次)。这为不同的应用场景提供了灵活性。\n（3）持久会话：MQTT可以配置为持久会话，即当客户端掉线后，它可以再次上线并接收它错过的所有消息。\n（4）集成和兼容性：许多IoT平台和设备已经内置了对MQTT的支持，这意味着在整合时可能会更加容易。\n\n为什么不选kafka？\n（1）Kafka的用途：虽然Kafka也是一个消息传递系统，但它主要用于大数据流处理和实时数据处理。它的设计目标是高吞吐量、持久性和分布式数据流。而MQTT更注重设备到设备或设备到服务器的通讯。\n```\n\nmqtt\n\n```\nMQTT（Message Queuing Telemetry Transport，消 是一种基于发布/订阅（publish/subscribe）模式的“轻量级”通讯协议。\n最 大优点在于，用极少的代码和有限的带宽，为连接远程设备提供实时可靠的消息服务。\n作为一种低开销、低带宽占用的即时通讯协议，使其在 物联网、小型设备、移动应用等方面有较广泛的应用。\n```\n\nkafka\n\n```\nKafka 是一种高吞吐量的分布式发布订阅消息系统，\n优势包括：\n（1）高 吞吐量、低延迟：每秒可以处理几十万条消息，它的延迟最低只有几毫 秒；\n（2）可扩展性：集群支持热扩展；\n（3）持久性、可靠性：消息被 持久化到本地磁盘，并且支持数据备份防止数据丢失；\n（4）容错性：允 许集群中节点故障（若副本数量为 n，允许 n-1 个节点故障）；\n（5）高并发：支持数千个客户端同时读写。\n```\n\n\n\n### 为什么要自己实现工作流引擎\n\n```\n（1）开源重量级：现有的成熟的工作流引擎都功能都比较完善、可靠性比较高。我了解到像activity这样的工作流引擎，它们其实是很复杂的很庞大的，依赖于很多张数据库表，这就对我们集成进来有很大的影响、成本也比较大。\n\t- 很多功能是不需要的\n\t- 需要去了解每张数据库表的具体含义\n\t- 想要去拓展的话还需要去了解它的实现过程\n\t- 开源的项目如果生产过程中出了问题不可控\n（2）自研轻量级：每一个功能都是为需求而生，对架构了解也很容易进行拓展和优化，出了问题也比较容易把控，容易排查和解决。\n（3）特定的需求开源的工作流引擎无法实现\n\t\t我们开发的这套系统有一套自己的概念（数据源、数据集模型、数据集、实体模型、实体），用这些开源的工作流引擎很难和我们的设计融合在一起，或者说融合的成本很大。\n（4）优点：能够支持任务的分布式执行，我们是一个数据分析平台，需要跑很多长时间的算法，分布式执行能够很好的利用计算资源，提高效率。\n（5）技术挑战与成长：对于开发团队来说，自行设计和实现东西可以是一次很好的技术挑战和成长机会。也可以形成我们自己的知识产权，不能说一个实验室没有自己沉淀的东西，什么都是拿来主义，那这样就会没有竞争力，容易被替代，这也使得我们实验室能够持续的有很多大项目合作的机会。\n```\n\n### 设计这个架构时如何考虑到系统的扩展性和稳定性？\n\n```\n拓展性\n（1）设计和实现的时候进行了模块化，主要的模块包括：流程构建器（任务节点、逻辑类节点、事件类节点等）、解析器、执行器、表达式解析器、监视器。\n\t- 流程构建器：负责流程的构建，通过gojs实现的一种可拖拽式的流程绘制模式，绘制的流程通过json的格式保存。\n\t- 解析器：负责json格式的流程解析，运用了「工厂+策略」的设计模式，去调用不同节点的解析器，生成对应的类对象，然后初始化到工作流引擎的节点状态池中。\n\t- 执行器：负责工作流程的执行。实现时通过「令牌 + 事件驱动」的模式来实现。令牌保障了消息丢失时能够去主动检测任务状态进行更新或重启；事件驱动则保证了任务能够异步执行，并且完成时能够向前推进。\n\t- 表达式解析器：一些逻辑类节点（if、switch）会有一些表达式，前期我是自己实现了一个解析工具，递归的从左到右进行解析；后期的话在浏览一些项目的时候发现了一个很好用的开源工具，叫huTool工具。\n\t- 监视器：通过mqtt来实现，去监听指定的话题，包含控制台指令、状态更新指令、状态上报\n```\n\n### 如何保证算法模型的质量和准确性的？\n\n```\n（1）遵循统一的规范：输入、输出、参数列表\n（2）校验\n（3）实体数据查看：如数据导入\n```\n\n### 如何优化大文件上传过程？\n\n```\n（1）分片上传：将大文件分割成多个小片段分别上传\n（2）多个分片同时上传\n（3）断点续传\n（4）错误重试\n（5）文件秒传\n```\n\n### 如何通过分布式锁解决文件夹的重命名、复制和删除问题？\n\n```\n问题描述：\nminio是一种key、value的存储形式，没有提供文件夹的重命名功能，需要我们自己去实现这部分逻辑。重命名文件夹时，文件夹里面的文件也需要重命名，所以需要考虑原子性、一致性、隔离性问题。\n\n（1）获取分布式锁：保证重命名过程中没有其他进程可以修改目标文件夹\n（2）创建新的文件夹\n（3）文件迁移：遍历文件夹下的所有文件，复制到新的目录上去\n（4）删除原文件夹\n（5）释放锁\n\n考虑的问题：\n（1）原子性：整个重命名操作是原子的，这意味着要么全部成功，要么全部失败。\n（2）一致性：通过锁机制，我们确保在重命名过程中系统保持一致性，不会出现因并发操作而导致的数据不一致问题。\n（3）隔离性：分布式锁可以保证在重命名操作期间，其他进程或线程无法访问被锁定的资源，从而实现操作的隔离性。\n```\n\n### 修改过程中是否允许其他用户上传文件？\n\n```\n我们希望避免在重命名过程中有其他用户上传文件到原文件夹中，因为这样可能会导致数据不一致或丢失。\n\n我们考虑了两种策略：\n（1）禁止上传\n（2）队列上传请求：另一种策略是，在重命名过程中，将其他用户的上传请求放入一个队列中。一旦重命名完成并释放了锁，队列中的上传请求可以被处理。这样可以确保即使在重命名过程中，上传请求也不会被丢失，但这可能会增加系统的复杂性。\n\n如何选择？\n保证数据一致性选第一种\n可以容忍短暂的上传延迟，就第二种。\n```\n\n\n\n### 有什么难点\n\n#### 难点1: 可拓展性\n\n```\n我们的系统是一个数据分析平台，需要集成很多算法，如果对于每个算法，我们都从头开始写编写，添加新的接口，写死在系统中，那么我们就会和甲方一直的绑定在一起，很被动，无法脱身，只有他们有算法需求，我们就需要派人去给他们集成。\n我们的想法是“能让他们自己玩，但又不能让他们脱离我们自己玩”，所以设计了这套分布式任务执行过程\n\n我们运用了python的模块动态加载功能，结合celery写了一个统一的入口，叫run操作，\n每一个算法都需要编写一个run方法，在执行过程中，通过文件名找到对应的算法，然后执行run方法，然后发布到worker中执行\n每个算法的输入、输出有一套统一的规范，大家都遵循这个规范来开发，这样就能保证整个流程正常的运转\n```\n\n#### 难点2: 大文件的处理\n\n```\n包括大文件的上传、使用：\n（1）上传\n实验过程中，会产生一些大文件非结构化数据，我们需要导入到系统中，来进行后面的处理分析流程\n大文件上传就会存在很多问题，如果上传过程中因为网络等原因中断，那么我们就得重新来过，前面的操作就白费了\n\n所以在文件的上传过程中进行了优化，通过文件分片上传、断点续传、文件秒传来优化上传过程\n\n（2）使用\n这部分主要是算法开发中会进行处理\n```\n\n#### 难点3: 结构化数据的维度很多，难以复用\n\n```\n实验过程中产生的一些结构化数据维度很多，可能会有几百上千列，我们需要设计一种机制来管理好这些维度定义，并且能够复用、衍生、及溯源\n\n我们就设计了实体模型（数据模型）这个概念，实体模型就是对数据列维度的定义，包括名称、类型等信息\n多次实验列维度可能有所不同，就可以新建一个实体模型，集成原来的实体模型，然后进行修改\n```\n\n\n\n## 优化\n\n### 串行接口改并行接口\n\n```\n对于一些不存在依赖关系的业务，需要在同一个接口中查询时，串行的处理就会导致后面的逻辑需要等待前面的业务查询处理完成之后才能开始。\n比如查询坎贝尔图数据的时候，需要查询数据、辅助线，主题数据需要进行一些缺失值处理和排序，辅助线需要进行格式化，而这两个业务是不存在先后关系的，可以并行完成。\n\n目前是通过「countDownLatch + 线程池」来完成\n```\n\n实现方式\n\n```\n方式1: join\n方式2: countDownLatch + 线程池\n方式3: CompletableFuture\n```\n\n参考\n\n-   [串行处理的优化方式有哪些？](https://blog.csdn.net/WODESHENNI/article/details/125051287)\n-   [如何写好代码：手把手教你写一个并行调用模板](https://articles.zsxq.com/id_051qnbm2cw68.html)\n-   [JAVA使用CompletableFuture实现流水线并行处理，加速你的接口响应](https://heapdump.cn/article/4456384)\n\n\n\n### SQL优化\n\n如何分析\n\n```\n使用explain可以得到sql的查询计划\n重点关注type、\n```\n\n怎么优化\n\n```\n（1）增删索引。\n\t- 删除一些不必要的索引\n\t- 一些查询频繁但修改少的字段添加索引，尽量添加联合索引。\n（2）避免返回不必要的数据。返回需要的字段，比如工作流任务中，包含了一个text类型的字段，查询会消耗大量的网络和io带宽。在查询列表时是用不到这个字段信息的，只有在编辑流程时才需要查该字段。\n（3）优化limit大分页问题。先查询limit后的id，再进行\n（4）索引失效问题\n\t\t- 最左匹配\n\t\t- 操作索引列\n\t\t- where字段 %like、not in、is not null\n\t\t- 隐式转换\n```\n\n\n\n### 项目中是怎么使用分布式锁的?\n\n```\n\n```\n\n","timestamp":1694014972243},{"name":"03-设计图.md","path":"005-项目/001-民用航空发动机健康管理系统/03-设计图.md","content":"软件逻辑架构图\n\n![image-20230817231059358](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/17/23105916922850591692285059511P1Gvac-image-20230817231059358.png)\n\n物理结构图\n\n![image-20230817231132354](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/08/17/231132169228509216922850924542RaPbD-image-20230817231132354.png)\n\n\n\n```\n商用发动机健康管理平台\n\n项目描述:\n项目是与中国航发商发合作项目,旨在实时监控航空发动机试验,并能收集数据进行处理,分析及诊断,协助试验推进,实现数据分析全流程。包含实验管理功能,状态监视功能,异常自动检测功能,故障诊断功能,数据可视化功能等\n\n技术栈:\nSpringboot+Mybatis+MySQL+Redis+Mqtt;Python+Celery+HBase+MongoDB\n\n主要工作\n（1）参与系统设计,包括数据源,数据集,实体模型,实体等设计,解决多类型结构数据存储,衍生,溯源等问题\n（2）设计工作流引擎基础架构,包含流程构建器(任务节点,逻辑类节点,事件类节点等)解析器,执行器,表达式解析器、监视器等。使用线程池,mqtt,celery实现分布式工作流执行引擎\n（3）负责算法模型的设计,实现算法模型管理,分布式单算法任务管理;并参与部分算法模型的开发,如实体指定维度排序算法,缺失值处理,行平均算法,列平均算法等\n（4）通过minio实现非结构化数据管理,并通过文件分片上传,断点续传,文件秒传等优化大文件上传过程;通过分布式锁解决文件夹重命名,复制,删除问题\n（5）使用mqtt构建异步消息系统,实现发送通知,异常告警,任务状态同步,工作流任务推进等\n\n项目优化：\n（1）通过将业务流程从串行改为并行处理,提高接口响应速度,使耗时减少超过一半\n（2）通过优化数据库索引,sql语句等优化慢sql问题,如limit大分页问题,索引失效问题等\n```\n\n","timestamp":1694014972243},{"name":"01-系统功能.md","path":"005-项目/002-weTeam校园/01-系统功能.md","content":"```\n\n```\n\n","timestamp":1694014972243},{"name":"01-场景题.md","path":"005-项目/01-场景题.md","content":"海量日志数据，访问最频繁的IP地址怎么找出来？只给你一个内存有限的机器 \n\n```\n\n```\n\n","timestamp":1694014972243},{"name":"02-接口幂等性问题.md","path":"005-项目/02-接口幂等性问题.md","content":"参考\n\n-   [面试：如何保证接口的幂等性？常见的实现方案有哪些？](https://cloud.tencent.com/developer/article/1809887)\n-   [如何保证接口的幂等性？](https://juejin.cn/post/7001667579991293989)\n-   [高并发下如何保证接口的幂等性？](https://segmentfault.com/a/1190000039737646)\n\n\n\n\n# [高并发下如何保证接口的幂等性？](https://segmentfault.com/a/1190000039737646)\n\n## 为什么会产生接口幂等性问题\n\n在计算机应用中，可能遇到网络抖动，临时故障，或者服务调用失败，尤其是分布式系统中，接口调用失败更为常见。为了保证服务的完整性，我们可能会发起接口的重试调用，如果接口不处理幂等，可能对系统造成很大的影响，因此接口的幂等设计尤其更为重要。\n\n对于业务中需要考虑幂等性的地方一般都是接口的重复请求，重复请求是指同一个请求因为某些原因被多次提交。导致这种情况的发生有以下几种常见的场景：\n\n1.  **前端重复提交：** 用户在提交表单的时候，可能会因网络波动没有及时做出提交成功响应，致使用户认为没有成功提交，然后一直点提交按钮，这时就会发生重复提交表单请求。\n2.  **接口超时重试：** 第三方调用接口时候，为了超时等异常情况造成的请求失败，都会添加重试机制，导致一个请求提交多次。\n3.  **消息重复消费：** 当使用 MQ 消息中间件时候，如果发生消息中间件出现错误未及时提交消费信息，导致发生重复消费。\n\n## **幂等性问题**\n\n-   如何防止接口的重复无效请求。\n\n-   每次请求的结果一样\n\n#### 防重设计 vs 幂等设计？\n\n```\n防重设计 和 幂等设计，其实是有区别的。\n防重设计主要为了避免产生重复数据，对接口返回没有太多要求。\n而幂等设计除了避免产生重复数据之外，还要求每次请求都返回一样的结果。\n```\n\n\n\n## 幂等性解决方案\n\n### 1 前端\n\n#### **方案一：前端控制**\n\n在前端做拦截，比如按钮点击一次之后就置灰或者隐藏。但是往往前端并不可靠，还是得后端处理才更放心。\n\n#### **方案二：Token机制**\n\n1.  第一次请求获取`token`\n\n2.  第二次请求带着这个`token`，完成业务操作。\n\n    \n\n用户进入表单页面首先调用后台接口获取 token 并存入 redis，当用户提交表单时将 token 也作为入参，后端先删除 redis 中的 token，删除成功则保存表单数据，失败则提示用户重复提交。\n\n![img](https://cdn.jsdelivr.net/gh/iamk123/typora@main/uPic/2023/03/14/23523816788091581678809158980IWA1pN-cc03edc216354a1b8b9923f47b51fc80~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp)\n\n为什么不先判断 redis 是否存在这个 token 再删除？\n\n```\n是因为要保证操作的原子性，极端情况下，第一个请求查询到 redis 中存在这个 token，还没来得及删除，第二个请求进来，也查询到 redis 中存在这个 token，那么还是会造成重复提交的问题。\n```\n\n问题\n\n```\ntoken 机制需要先请求获取 token 的接口，在有些情况下很明显并不合适。我们大部分请求都是要落到数据库的，所以我们可以从数据库着手。\n```\n\n能不能改为“判断token是否存在来判断是不是第一次请求”？\n\n```\nhttps://segmentfault.com/a/1190000039737646\n```\n\n### 2 数据库\n\n#### **方案一、唯一索引**\n\n这种方案就比较好理解了，使用唯一索引可以避免脏数据的添加，当插入重复数据时数据库会抛异常，保证了数据的唯一性。唯一索引可以支持插入、更新、删除业务操作。\n\n#### **方案二、悲观锁**\n\n这里所说的悲观锁是基于数据库层面的，在获取数据时进行加锁，当同时有多个重复请求时，其他请求都无法进行操作。悲观锁只适用于更新操作。\n\n```mysql\n// 例如\nselect name from t_goods where id=1 for update;\n\n注意： id 字段一定要是主键或者唯一索引，不然会锁住整张表，这是会死人的。悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，根据实际情况选用。\n```\n\n问： 悲观锁怎么能防止重复数据提交，多个请求只有一个请求能进行操作，其他请求在等待，那么这个请求结束后，其他请求不还是进行了更新操作吗？\n\n```\nbegin transaction\n1.select * from order_info where id = \"20201020\" for update 加record lock\n2.Java代码判断status == \'初始\' 执行3，否则返回\n3.update order_info set status = \'成功\' where id = \'20201020\'并且发货\ncommit\n```\n\n[参考：**重复支付问题如何解决（悲观锁和乐观锁）**](https://blog.51cto.com/u_15127700/4540810)\n\n-   https://mp.weixin.qq.com/s/UN0T80ygxnyCgnmrkpwtPg\n\n**问题**\n\n-   不适合高并发\n-   只适用于更新操作\n\n#### **方案三、乐观锁**\n\n可以通过**版本号**实现，为表增加一个 version 字段，当数据需要更新时，先去数据库里获取此时的version版本号。\n\n```mysql\nselect version from t_goods where id=1\n复制代码\n```\n\n更新数据时首先要对比版本号，如果不相等说明已经有其他的请求去更新数据了，提示更新失败。\n\n```mysql\nupdate t_goods set count=count+1,version=version+1 where version=#{version}\n```\n\n**问题**\n\n-   只适用于更新\n\n#### 方案四 状态机\n\n其实也是乐观锁的原理。这种方法适合在有状态流转的情况下，比如订单的创建和付款，订单的创建肯定是在付款之前，这时我们可以通过在设计状态字段时，使用 int 类型，并且通过值类型的大小来实现幂等性。\n\n```mysql\nupdate t_goods set status=#{status} where id=1 and status<#{status}\n```\n\n[更具体参考](https://segmentfault.com/a/1190000039737646)\n\n###  3 分布式锁\n\n有时候我们的业务不仅仅是操作数据库，也可能是发送短信、消息等等，那数据库层面的锁就不适合了。这种情况下就要考虑代码层面的锁了，而 java 的自带的锁在分布式集群部署的场景下并不适用，那么就可以采用分布式锁来实现（Redis 或 Zookeeper）。\n\n拿 Redis 分布式锁举例，比如一个订单发起支付请求，支付系统会去 Redis 缓存中查询是否存在该订单号的 Key，如果不存在，则以 Key 为订单号向 Redis 插入。查询订单是否已经支付，如果没有则进行支付，支付完成后删除该订单号的Key。通过 Redis 做到了分布式锁，只有这次订单支付请求完成，下次请求才能进来。当然这里需要设置一个Key 的过期时间，在发生异常的时候还要注意删除 Redis 的 Key。\n\nhttps://juejin.cn/post/7127667756693979173\n\n```\nRedisson提供了一套功能丰富的分布式对象和服务，包括分布式锁、分布式集合、分布式队列等，可以更方便地实现分布式锁的功能。\n```\n\n\n\n### weTeam校园\n\n```\n主要作用：汇集校内外所有竞赛/活动，提供一个组队的平台\n\n- 用户管理\n    - 注册\n    - 删除\n    - 添加管理员\n    - 关注用户/取关\n- 竞赛管理\n    - 发布竞赛\n    - 编辑竞赛\n    - 删除\n    - 修改\n    - 收藏/取消\n    - 条件查询查询竞赛列表\n    - 评论\n - 组队管理\n     - 创建队伍\n     - 删除队伍\n     - 编辑队伍\n     - 查询队伍列表\n     - 查询指定队伍信息\n     - 组队申请\n     - 同意申请\n     - 拒绝申请\n     - 删除成员\n     - 退出队伍\n  - 登录\n  - 退出登录\n  - 消息通知\n  \n```\n\n","timestamp":1694014972243},{"name":"03-简历投递.md","path":"005-项目/03-简历投递.md","content":"\n\n```\nlinkuan_npu@mail.nwpu.edu.cn\n```\n\n\n\n```\n商用发动机健康管理平台\n\n项目描述：\n项目是与中国航发商发合作项目，旨在实时监控航空发动机试验，并能收集试验数据进行处理、分析及诊断，协助试验推进，实现数据分析全流程。开发了一个包含试验管理、状态监视、异常自动检测、故障诊断和数据可视化等功能的平台。\n\n技术栈：\nSpringboot + Mybatis + MySQL + Redis + Mqtt; Python + Celery + HBase + MongoDB;\n\n主要工作：\n（1）参与系统设计，设计了数据源、数据集、实体模型、实体等，解决多类型结构数据存储、衍生和溯源问题。\n（2）设计工作流引擎基础架构，包含流程构建器（任务节点、逻辑类节点、事件类节点等）、解析器、执行器、表达式解析器、监视器等。使用线程池、MQTT、Celery实现了一个分布式工作流执行引擎。\n（3）负责算法模型的设计，实现了算法模型管理、分布式单算法任务管理；并参与部分算法模型的开发，包括指定维度排序、缺失值处理、台阶计算等算法。\n（4）通过minio实现非结构化数据管理，并通过文件分片上传、断点续传、文件秒传等优化大文件上传过程；通过分布式锁解决文件夹重命名、复制、删除问题\n（5）使用mqtt构建异步消息系统，实现发送通知、异常告警、任务状态同步和工作流任务推进。\n\n项目优化：\n（1）通过将业务流程从串行改为并行处理，提高接口响应速度，将耗时减少超过一半。\n（2）通过优化数据库索引、SQL语句等优化慢SQL问题，如limit大分页问题、索引失效问题。\n```\n\n\n\n```\nweTeam校园\n\n项目描述：\n项目是一个校园活动交流平台，旨在解决疫情期间活动查找难、宣传难及组队难等问题。实现了注册登录、活动管理、组队管理、点赞评论、消息提醒和网站数据统计等功能。项目获中国高校计算机大赛西北赛区一等奖、全国三等奖，成功申报国家级创新创业项目，并以该项目作为创业项目基石继续发展。线上地址:微信小程序\"团团小文体\"\n\n技术栈：\nSpringBoot + MyBatis + MySQL + Redis + Kafka\n\n工作内容： \n（1）实现了活动管理、组队管理、评论管理等模块。\n（2）使用JWT+Redis实现登录功能，解决分布式Session问题，采用双令牌认证的方式实现用户无感知登录刷新。\n（3）使用Redis实现热门榜单、点赞关注收藏，统计系统UV、DAU等信息，并解决数据库与缓存双写一致性问题、缓存穿透、缓存雪崩、缓存击穿问题。\n（4）使用Kafka构建异步消息系统，发送评论、点赞、关注和活动更新等通知，起到对系统削峰、解耦和异步调用的作用。\n（5）使用AOP记录系统日志、权限检查，对项目进行解耦，增加重用性和和可维护性。\n\n项目收获：\n（1）以竞赛为驱动，短期内学习Springboot、mybatis、redis等技术，完成一个完整的前后端分离的项目。通过项目了解Redis、kafka在项目中的具体应用。\n（2）学习了docker基本用法，通过容器来部署项目前后端。\n```\n\n\n\n```\n“深度扶贫地区青春行”社会实践 2019.08\n\n（1）实践以“异地扶贫”为主旨，走进国家级贫困县广西融水，深入了解异地扶贫搬迁工作的现状。实践以实地采 访的形式开展，并形成调研报告，最终获“校级一等奖”优秀实践队表彰。 \n（2）前期负责与当地相关负责人沟通协调，参与日程计划安排。实践过程中参与留守儿童的趣味暑期课堂活动及深 入基层进行实地采访交流。\n```\n\n\n\n```\n2022年学业二等奖学金\n2021年学业二等奖学金\n2020年国家励志奖学金\n2020年西工大校优秀奖学金\n2020年中国高校计算机大赛全国三等奖（西北赛区一等奖）\n2020年微信小程序应用开发赛二等奖\n2020年西工大小程序设计大赛一等奖                                       \n2020年美国大学生数学建模大赛三等奖\n2019年全国高校计算机大赛全国三等奖\n2018年西工大五一数模校赛三等奖\n```\n\n\n\n```\n（1）参与多个前后端分离项目的开发和维护，熟悉angular + springboot的开发流程，能够独立完成前后端项目的开发。\n（2）具有较强的执行力、分析解决问题的能力，对编程充满热爱，自学过多种编程语言并开发项目，如Golang、python、vue、angular等。\n```\n\n","timestamp":1694014972243}]